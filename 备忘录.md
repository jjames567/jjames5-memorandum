# 备忘录

## 计算机网络

### http 1.0 1.1 2.0的区别？

http1.0有一个很大的问题：就是**每次**http请求都需要进行三次握手和四次挥手，非常耗费资源。

http1.1增加了**长连接**特性，在经过一次三次握手后就能保持长连接，在保持连接的时间段内并不需要经过三次握手即可通信。

除此之外，http1.1还支持管道传输，即客户端可以一次发送多次请求到服务端。但这又造成了一个问题：服务端只能处理完一个请求才能处理下一个请求（请求应答模式），假如第一个请求处理时间非常长，就会导致服务端一直不能处理后面的请求，这就是**队头阻塞**。同时还存在其他其他问题：**请求头未经压缩**、**服务端只能被动响应**、**请求只能顺序处理**。（**总共4个问题**）

http2.0为了解决队头阻塞的问题，引入了**多路复用**，HTTP/2是基于二进制“帧”的协议，HTTP/1.1是基于“文本分割”解析的协议。

由于 HTTP 1.X 是基于文本的，因为是文本，就导致了它必须是个整体，在传输是不可切割的，只能整体去传。
但 **HTTP 2.0 是基于二进制流的**。有两个非常重要的概念，分别是帧（frame）和流（stream）

- 帧代表着最小的数据单位，每个帧会标识出该帧属于哪个流。
- 流就是多个帧组成的数据流。

将 HTTP 消息分解为独立的帧，交错发送，然后在另一端重新组装。

- 并行交错地发送多个请求，请求之间互不影响。
- 并行交错地发送多个响应，响应之间互不干扰。
- 使用一个连接并行发送多个请求和响应。

http2.0还支持请求头压缩 **HPACK算法**，服务端和客户端同时维护一张索引表，针对相同的头信息只需通过索引号就能代表该字段。

在http2.0中服务端可以在客户端第一次请求时就能向客户端 **主动推送** 静态资源，提高效率。

http2.0对 **数据流**（每次请求或响应的数据包）进行编号标记，客户端为奇数，服务端为偶数，可以以此来设置请求处理的顺序。

http2.0使用 **二进制格式** 传输，对计算机友好，省去了转换的过程。

### https 原理？

https处于应用层和传输层之间（SSL/TLS协议），采取**非对称加密**、**对称加密**实现数据**机密性**，使用**摘要算法**实现数据**完整性**，通过**数字证书**验证服务器公钥实现服务器**真实性**。

大致流程：

1. 客户端发送SSL/TLS协议版本、**随机数**、密码套件列表(如RSA加密算法)到服务端。
2. 服务端确认SSL/TLS协议版本，发送**随机数**、确认的密码套件列表、服务器发送**数字证书**到客户端。
3. 客户端通过CA公钥确认服务器**数字证书**真实性，取出证书中的公钥对接下来的信息加密，内容为：**随机数**、使用**会话密钥**加密通知、握手结束通知。
4. 服务端使用私钥解密信息，再利用**三个随机数**使用之前协商好的**密码套件列表**计算出**会话密钥**，返回握手结束等相关通知。

解释：

数字证书包含了服务器公钥和CA数字签名。

摘要算法是MD5这些，是不可逆的，下面的流程能够体现。

在之后的通信中：

客户端会先对明文信息使用**摘要算法**计算出**指纹**，再使用**会话密钥**加密处理进行传输（明文+指纹）。

服务端使用**会话密钥**进行解密，得到明文和指纹后，也是用**摘要算法**处理明文，对比指纹是否一样，确认信息完整性。



### TCP头部格式

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210528220556838.png" alt="image-20210528220556838" style="zoom: 33%;" />

### UDP头部格式

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210528220703572.png" alt="image-20210528220703572" style="zoom:33%;" />

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210528221258789.png" alt="image-20210528221258789" style="zoom: 33%;" />

TCP 的数据⼤⼩如果⼤于 MSS ⼤⼩，则会在传输层进⾏分⽚，⽬标主机收到后，也同样在传输层组装 TCP

数据包，如果中途丢失了⼀个分⽚，只需要传输丢失的这个分⽚。

UDP 的数据⼤⼩如果⼤于 MTU ⼤⼩，则会在 IP 层进⾏分⽚，⽬标主机收到后，在 IP 层组装完数据，接着

再传给传输层，但是如果中途丢了⼀个分⽚，在实现可靠传输的 UDP 时则就需要重传所有的数据包，这样

传输效率⾮常差，所以通常 UDP 的报⽂应该⼩于 MTU。

MTU ：⼀个⽹络包的最⼤⻓度，以太⽹中⼀般为 1500 字节；

MSS ：除去 IP 和 TCP 头部之后，⼀个⽹络包所能容纳的 TCP 数据的最⼤⻓度；

总结：当IP层有数据超过MTU时就要进行IP分组，而IP分组是效率很低的，因为IP层没有TCP超时重传，当其中一个IP分组丢失时所有的分组都要进行重传。因此在经过传输层时当超过MSS时就会进行分片，自然交到网络层时就不会超过MTU了。

### 三次握手

为什么？

TCP 是⾯向连接的协议，所以使⽤ TCP 前必须先建⽴连接，⽽建⽴连接是通过三次握⼿来进⾏的。

握手流程：

开始客户端、服务端都为CLOSE状态

1. 客户端初始化随机序列号，同时SYN标志位置为1，状态改为SYN-SENT，发送给服务端。
2. 服务端初始化随机序列号，确认应答号为客户端序列号+1，ACK标志位和SYN标志位都置为1，状态改为SYN-RCVD，发送到客户端。
3. 客户端ACK标志位置为1，确认应答号为服务端序列号+1，本次发送可以携带应用层数据，最后状态改为ESTABLISHED。

为什么是三次？

1. 通过随机序列号可以有足够的时间判断是否是历史连接（有可能旧SYN报文比新SYN报文先到达），如果是历史连接则发送RST置为1的报文。
2. 同步双方的序列号。
3. 两次握手情况下服务端不知道客户端是否已收到确认ACK。

### 四次挥手

1. 客户端发送FIN标志位置为1的报文，从ESTABLISHED状态改为FIN_WAIT_1状态。
2. 服务端响应ACK标志位置为1的报文，从ESTABLISHED状态改为CLOSE_WAIT状态。
3. 客户端收到ACK响应报文后进入FIN_WAIT_2状态。
4. 服务端处理完自己的其他响应后，发送FIN标志位置为1的报文，进入LAST_ACK状态。
5. 客户端收到响应报文后，返回ACK标志位置为1的报文，进入TIME_WAIT状态。
6. 服务端收到ACK应答后，进入CLOSE状态。
7. 客户端经过2MSL时间后，进入CLOSE状态。

注意：主动关闭连接的一方才会有TIME_WAIT状态。

为什么最后等待时间是2MSL？

MSL是报文的最大生存时间，2MSL是为了防止服务端收不到第5步中的ACK报文而导致服务端重发FIN报文，当再次收到服务端的FIN报文时，2MSL会重新计时。

**等待时间过短**：服务端没有收到最后的ACK报文，就会一直处于LAST_ACK状态，此时客户端请求的新连接SYN报文会直接被RST终止，所以**会影响新连接**。

**等待时间过长**：客户端会造成**内存资源占用**，**端口资源占用**。当65536个资源被占满时就无法创建新连接了。

### TCP重传

#### 超时重传

设置一个定时器，通过测试**报文往返时间**(RTT)，把**超时重传时间**RTO设置为略大于**RTT**的值。

RTO较短则会导致即使报文没丢但也会触发重传，导致网络拥塞。

RTO较长则会导致报文丢失后效率低。

#### 快速重传

返回ACK的时候会带上ACK确认号，当收到三个相同的ACK报文时就会直接触发重传，不以时间为驱动。这时会有个问题，假如已经发送了编号为123456的数据，返回3个编号为3的ACK，那是应该重传3，还是重传3456呢？

##### SACK（选择性确认）

在TCP头部的**选项**中加上SACK字段，会有一个缓冲区记录哪些报文段已经接收到，哪些还没接收，重传时则重传丢失那一部分即可。

![image-20210529142946164](https://raw.githubusercontent.com/jjames567/picture/main/image-20210529142946164.png)

##### D-SACK

感觉跟SACK区别不大，就是通过SACK和ACK判断重传原因是因为ACK丢失还是发送方因为网络原因延时。

##### 滑动窗口

窗口实际上是操作系统的一个缓存空间，假如滑动窗口为3，那么发送方可以一次发送3个报文。

![image-20210529150303772](https://raw.githubusercontent.com/jjames567/picture/main/image-20210529150303772.png)

返回ACK 700时，说明接收方700之前的报文已经收到了，因此发送方不用重发700之前的数据，这也叫累计确认或累计应答。

结论：接收方窗口大小约等于发送方窗口大小（网络存在时延，不一定能够及时通知发送方改变窗口大小，同时也受接收方的进程处理速度影响），通过TCP报文中的Windows字段来告诉发送方。

### 流量控制

接收方通过上面所说的Windows字段告诉发送方目前缓冲区还有多少空间，也就是接收窗口的大小。

![image-20210529151326198](https://raw.githubusercontent.com/jjames567/picture/main/image-20210529151326198.png)

接收窗口为0：

1. 接收方会在缓冲区>0时通知发送方。

2. 发送方会在收到win=0时启动计时器，每隔一段时间去询问接收方是否有空间接收数据，假如还是0则重新计时。

### 拥塞控制

发送窗口实际上应该是=min(拥塞窗口, 接收窗口)，也就是说发送窗口受拥塞窗口和接收窗口的影响，取它们的最小值。

拥塞控制有以下控制算法：

#### 慢启动

发送方每接收一个ACK，拥塞窗口会遵循下面的增长规则：

cwnd初始值为1。

1. 收到第一个ACK，cwnd+=cwnd（1+1）。
2. 收到第二个ACK，cwnd+=cwnd（2+2）。
3. （4+4）
4. ......
5. ......

当达到**慢启动门限ssthresh**时，增长规则改为cwnd+=1。

到达ssthress后的增长规则其实是cwnd=cwnd+1/cwnd，但因为这里是以每一轮应答来看的，也就是8个ACK到达之后，拥塞窗口+1。

![image-20210529152605852](https://raw.githubusercontent.com/jjames567/picture/main/image-20210529152605852.png)

在使用**超时重传**时，ssthresh会重置为发生超时重传时的cwnd/2，cwnd重置为1，重新进行慢启动。

![image-20210529153255524](https://raw.githubusercontent.com/jjames567/picture/main/image-20210529153255524.png)

所以上面是**慢启动** + **超时重传** 的方案。

下面介绍 **快速重传** + **快恢复**：

关键点在于快恢复，前面还是先进行慢启动，当在拥塞避免阶段收到3个相同的ACK时，会触发快速重传，然后把拥塞窗口改成cwnd/2+3，这里的3可以理解为接收方能容纳这3个重复ACK报文。而ssthresh门限也是跟之前那样重置为发生重传时的cwnd/2。

![image-20210529154701049](https://raw.githubusercontent.com/jjames567/picture/main/image-20210529154701049.png)

总结：先进行慢启动，到达门限后使用拥塞避免算法，再根据两种不同的重传机制进行不同的处理。若是使用超时重传则重新进行慢开始，若是使用快速重传则进行快恢复。

相同点：门限值在重传后都是重置为发生重传时拥塞窗口的一半。

不同点：快速重传在发生重传后拥塞窗口重置为门限值+3。

### 面试题

TCP 是如何实现数据的可靠性？

通过`校验和`、`序列号`、`确认应答`、`超时重传`、`连接管理`、`流量控制`、`拥塞控制`等机制来保证可靠性。

**（1）校验和**

在数据传输过程中，将发送的数据段都当做一个16位的整数，将这些整数加起来，并且前面的进位不能丢弃，补在最后，然后取反，得到校验和。

发送方：在发送数据之前计算校验和，并进行校验和的填充。接收方：收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方进行比较。

具体方法有奇偶校验法、CRC循环冗余校验法、海明码校验。前两个都属于检错，最后一个属于纠错。

**（2）序列号**

TCP 传输时将每个字节的数据都进行了编号，这就是序列号。序列号的作用不仅仅是应答作用，有了序列号能够将接收到的数据根据序列号进行排序，并且去掉重复的数据。

**（3）确认应答**

TCP 传输过程中，每次接收方接收到数据后，都会对传输方进行确认应答，也就是发送 ACK 报文，这个 ACK 报文中带有对应的确认序列号，告诉发送方，接收了哪些数据，下一次数据从哪里传。

**（4）超时重传**

在进行 TCP 传输时，由于存在确认应答与序列号机制，也就是说发送方发送一部分数据后，都会等待接收方发送的 ACK 报文，并解析 ACK  报文，判断数据是否传输成功。如果发送方发送完数据后，迟迟都没有接收到接收方传来的 ACK 报文，那么就对刚刚发送的数据进行重发。

**（5）连接管理**

就是指三次握手、四次挥手的过程。

**（6）流量控制**

如果发送方的发送速度太快，会导致接收方的接收缓冲区填充满了，这时候继续传输数据，就会造成大量丢包，进而引起丢包重传等等一系列问题。TCP 支持根据接收端的处理能力来决定发送端的发送速度，这就是流量控制机制。

具体实现方式：接收端将自己的接收缓冲区大小放入 TCP 首部的『窗口大小』字段中，通过 ACK 通知发送端。

**（7）拥塞控制**

TCP 传输过程中一开始就发送大量数据，如果当时网络非常拥堵，可能会造成拥堵加剧。所以 TCP 引入了`慢启动机制`，在开始发送数据的时候，先发少量的数据探探路。

说说 TCP 协议如何提高传输效率？

TCP 协议提高效率的方式有`滑动窗口`、`快重传`、`延迟应答`、`捎带应答`等。

**（1）滑动窗口**

如果每一个发送的数据段，都要收到 ACK 应答之后再发送下一个数据段，这样的话我们效率很低，大部分时间都用在了等待 ACK 应答上了。

为了提高效率我们可以一次发送多条数据，这样就能使等待时间大大减少，从而提高性能。窗口大小指的是无需等待确认应答而可以继续发送数据的最大值。

**（2）快重传**

`快重传`也叫`高速重发控制`。

那么如果出现了丢包，需要进行重传。一般分为两种情况：

情况一：数据包已经抵达，ACK被丢了。这种情况下，部分ACK丢了并不影响，因为可以通过后续的ACK进行确认；

情况二：数据包直接丢了。发送端会连续收到多个相同的 ACK 确认，发送端立即将对应丢失的数据重传。

**（3）延迟应答**

如果接收数据的主机立刻返回ACK应答，这时候返回的窗口大小可能比较小。

- 假设接收端缓冲区为1M，一次收到了512K的数据；如果立刻应答，返回的窗口就是512K；
- 但实际上可能处理端处理速度很快，10ms之内就把512K的数据从缓存区消费掉了；
- 在这种情况下，接收端处理还远没有达到自己的极限，即使窗口再放大一些，也能处理过来；
- 如果接收端稍微等一会在应答，比如等待200ms再应答，那么这个时候返回的窗口大小就是1M；

窗口越大，网络吞吐量就越大，传输效率就越高；我们的目标是在保证网络不拥塞的情况下尽量提高传输效率。

**（4）捎带应答**

在延迟应答的基础上，很多情况下，客户端服务器在应用层也是一发一收的。这时候常常采用捎带应答的方式来提高效率，而ACK响应常常伴随着数据报文共同传输。如：三次握手。

> 5、你知道 TCP 如何处理拥塞吗？

网络拥塞现象是指到达通信网络中某一部分的分

组数量过多，使得该部分网络来不及处理，以致引起这部分乃至整个网络性能下降的现象，严重时甚至会导致网络通信业务陷入停顿，即出现死锁现象。拥塞控制是处理网络拥塞现象的一种机制。

拥塞控制的四个阶段:

- 慢启动
- 拥塞避免
- 快速重传
- 快速恢复





### 多路复用

我们常常用 socket 来进行网络通信，因为其记录了 ip + 端口，而端口又可以给我们找到对应的进程，自然就能在不同机器上的应用层实现通信了。

但一台机器上有多个进程，分别绑定了不同的端口，难道要给他们分别创建一个线程来运行吗？显然是不可以的，因此就出现了 **多路复用模型** 。

网卡接收数据的过程（recv函数）：

1. 网卡收到网线传来的数据，DMA控制器 向 CPU 获取总线控制权。
2. DMA 把数据写入内存。
3. 网卡向 CPU 发送中断信号。
4. CPU 将内存中的数据写入对应 socket 的缓冲区。
5. 唤醒 socket 对应的进程。

#### select

我们都知道 Linux 一切皆文件， socket 文件记录了每一个 tcp 连接信息，同时把他们存在了文件列表 fd。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210602173454221.png" alt="image-20210602173454221" style="zoom:50%; margin-left:-10px" />

进程在监听 socket 的时候通常会有以下的操作：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210602173643810.png" alt="image-20210602173643810" style="zoom:50%; margin-left:-10px" />

当执行到 recv 函数时，进程A会被连接到对应 socket 中的 **等待列表** ，同时进程A阻塞等待返回。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210602174651910.png" alt="image-20210602174651910" style="zoom:50%; margin-left:-10px" />

那 select 做了什么呢？

回顾刚刚监听 socket 的操作，最后一步是调用 recv ，而这只能监听一个 socket ，那假如要监听多个 socket 呢？下面的代码给 select 传入 socket 文件列表（切换到内核空间）

```c
int s = socket(AF_INET, SOCK_STREAM, 0);  
bind(s, ...)
listen(s, ...)

int fds[] =  存放需要监听的socket

while(1){
    int n = select(..., fds, ...)
    for(int i=0; i < fds.count; i++){
        if(FD_ISSET(fds[i], ...)){
            //fds[i]的数据处理
        }
    }
}
```

通过一个死循环不断判断监听中的 socket 缓冲区是否有数据，若有则返回。 （select 的返回值可能 **大于1** ，因为可能多个 socket 同时有数据）

返回以后，需要 ① **遍历一次** fds ，找到 socket 对应的 **进程** ，然后 ② **再遍历一次** fds ，**断开** 与 socket 关联等待队列 。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210602181847053.png" alt="image-20210602181847053" style="zoom:50%; margin-left:-10px" />

进程被唤醒后，③ **再遍历一次** fds，读取对应 socket 缓冲数据。

#### epoll

先创建一个 epoll 对象 eventpoll ，再通过 epoll_ctl 将需要监视的 socket 添加到 eventpoll 中，最后调用 epoll_wait 等待数据。

```c
int s = socket(AF_INET, SOCK_STREAM, 0);   
bind(s, ...)
listen(s, ...)

int eventpoll = epoll_create(...);
epoll_ctl(eventpoll, ...); //将所有需要监听的socket添加到eventpoll中

while(1){
    int n = epoll_wait(...)
    for(接收到数据的socket){
        //处理
    }
}
```

有没有发现，select 给 socket **设置等待队列** 这个过程是放在 **死循环** 里的，这意味着每次循环都会重新设置一遍，但是我们程序已经写好代码在跑了，不是特殊情况不会发生改变的。

因此有了下面的优化对比：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210602201410848.png" alt="image-20210602201410848" style="zoom:50%; margin-left:-10px" />

之前 select 是把 socket 的等待队列设置成 **自己的进程** ，而 epoll 是把等待队列设置成刚刚创建的 **eventpoll** 对象。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210602201639500.png" alt="image-20210602201639500" style="zoom:50%; margin-left:-10px" />

同时，socket 收到数据后会发送中断信号，使得 eventpool 中的 **rdlist** 添加有数据的 socket 引用，rdlist 也叫 **就绪列表** 。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210602202821465.png" alt="image-20210602202821465" style="zoom:50%; margin-left:-10px" />

同时执行在 epoll_wait 函数时，会把本进程添加到 eventpool 的等待队列中，跟 select 一样，假如 socket 没有数据，会一直阻塞。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210602203537911.png" alt="image-20210602203537911" style="zoom:50%; margin-left:-10px" />

所以整个流程是这样的：

1. socket 接收到数据，中断程序把 socket 添加进 **就绪队列rdlist** 。
2. **唤醒** 等待队列中的进程。
3. 进程 **移出等待队列** ，读取 socket 缓冲数据，进入 **运行状态** 。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210602204022900.png" alt="image-20210602204022900" style="zoom:50%; margin-left:-10px" />

select 在唤醒进程后，进程还得 **重新遍历一次** fds 列表找到对应的 socket，因此 epoll 对比起 select 有很大的改进。



本来是只能一对一的Socket进行网络通信的，意味着一个Socket就要有一个线程来处理，而服务端调用accept()或者read()时是阻塞的，因此后面有了**多进程**的模型，就是由父进程来监听Socket，当成功连接后，就把该连接加入到已连接列表中，当有读写事件发生时，通过fork一个子进程来对其进行处理。但是这样处理会导致上下文切换开销十分大，因此就有了**多线程**模型。首先也是由一个进程负责处理连接请求，连接成功后将对应Socket放入到Socket队列中，当有事件发生时，由线程池中的线程来获取任务，进而对读写事件进行处理，但这样做存在线程安全问题。然后就有了i/o多路复用模型，select是将 **已连接** 的Socket放入到文件描述符列表，再将其传入到内核态，由内核态通过遍历的方式来检测是否有事件发生，有则将其标记为可读/可写状态，再将整个列表拷贝到用户态，用户态通过检测可读可写事件处理对应的Socket。这样在Socket数量很多的情况下性能低下，因为每次都要拷贝整个文件描述符列表，而且select有个限制只能监听1024个文件描述符，后面的poll通过动态数组解决了该问题。随后有了epoll，通过 epoll_ctl(fd) 传入已连接的文件描述符列表，注意不是传入整个列表，而是一个添加的操作，因为里面使用的是红黑树来维护监听列表的，因此即使数量很大，增删所导致的开销远比前两者要小。当监听到有事件发生时，会将存在事件的Socket加入到就绪列表中，这样就不需要整个Socket列表都拷贝回用户态了。epoll 支持边缘触发和水平触发的方式，而 select/poll 只支持水平触发，一般而言，边缘触发的方式会比水平触发的效率高。边缘触发就是只通知一次，需要确保把有事件发生的Socket处理完，水平触发就是只要有事件就会不断地通知。

### 单点登录

前端：https://mp.weixin.qq.com/s/zEzpMaLZK1XrJdvZxNjSow

后端：https://www.cnblogs.com/ZhuChangwu/p/11997499.html



## 操作系统

### 是什么？

是一个运行在计算机上的程序，用于管理**硬件**和**软件**的交互，比如应用程序通过操作系统写入数据到硬盘。同时因为操作系统的存在，屏蔽了硬件层的复杂性。操作系统的内核负责**内存管理**，**硬件设备管理**，**文件系统管理**，**应用程序管理**。

**用户态**：能访问应用程序上可以直接读取的数据。

**内核态**：能访问计算机的任何资源。

因此在进行一些敏感操作时需要进行系统调用，把用户态转换成内核态。

敏感操作：

1. 内存管理：完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。
2. 进程控制：完成进程的创建、撤销、阻塞及唤醒等功能。
3. 进程通信：完成进程之间的消息传递或信号传递等功能。
4. 文件管理：完成文件的读、写、创建及删除等功能。
5. 设备管理：完成设备的请求或释放，以及设备启动等功能。

### 进程和线程的区别

**进程**：是指系统中正在运行的一个应用程序，是系统进行资源分配的基本单位。

**线程**：是进程的子任务，是CPU调度的基本单位，线程共享进程的内存资源。

### 进程状态

1. 创建状态：进程正在被创建。
2. 就绪状态：准备运行，进程获得了除CPU时间片之外的资源。
3. 运行状态：进程正在处理器中的一个核心上运行。
4. 阻塞状态：进程正等待某一事件而暂不运行。如：等待资源可用、等待IO操作完成。
5. 结束状态：进程正在被销毁。

### 进程间的通信

1. 匿名管道：父子进程之间的通信，数据缓存在内核中。

   <img src="https://raw.githubusercontent.com/jjames567/picture/main/640.png" alt="640" style="zoom: 33%; margin-left:-5px" />

   shell 执行 A | B 时是 fork shell 进程来实现匿名管道通信的

   <img src="https://raw.githubusercontent.com/jjames567/picture/main/641.webp" alt="641" style="zoom:33%; margin-left:-5px" />

2. 命名管道：允许 **任意** 两个进程通信，**创建了一个类型为管道的设备文件**，在进程里只要使用这个设备文件，就可以相互通信。跟匿名管道一样，数据是 **缓存在内核中的** ，并且遵循先进先出。**生命周期随进程销毁而销毁**。在未读取时，**写入的那一方会命令不会返回**。要双向通信必须建立两个管道。数据只能是 **无格式的字节流**。

3. 消息队列：**写入后能直接返回**，遵循先进先出，是存放在内核中的消息链表，**消息体是用户自定义的数据类型**，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。当重启系统或显式删除一个消息队列时才会真正删除。不一定要以先进先出的次序读取，同时支持随机查询，也可以按消息类型读取。**消息队列不适合比较大数据的传输**，通信过程涉及 **用户态和内核态之间的拷贝**，因此也 **不适合实时性较强的场景** 。

4. 共享内存：**解决了拷贝造成的实时性**，多个进程可以访问同一块内存空间，但会有 **线程安全问题** 。

5. 信号量：是一个计数器，用于进程间的同步，**可以解决线程安全问题**。

6. 信号：**唯一异步通信机制**，**对于异常情况下的工作模式，就需要用「信号」的方式来通知进程**。比如 ctrl+c 终止进程，kill -9 来杀死进程。

7. 套接字：通过 IP + 端口号 完成网络通信。

### 线程间的同步方式 (线程安全) 

这里要注意一下同步和互斥的区别，同步是指线程之间 **协同、协助、互相配合** ，也就是说互斥是同步的一种方式。常用的同步方式有下面3种：

1. 互斥量：使用互斥对象，等同于信号量中 n=1 的情况，synchronized(object)。
2. 信号量：允许n个线程访问同一资源new Semaphore(3)，可以引用抢车位的例子，或者使不同线程顺序执行，**用于线程调度**。
3. 事件对象：通过wait/notify实现。

### 进程调度算法

当一个进程获取到CPU时，会因为阻塞而主动放弃占用。

1. 先来先服务：从**就绪队列**根据先进先出选择一个进程**分配资源**，直到该进程放弃占用。
2. 短作业优先：从**就绪队列**中选择一个估计运行时间最短的进程**分配资源**，直到该进程放弃占用。
3. 优先级调度：根据优先级选择进程**分配资源**。
4. 多级反馈队列：利用优先级保证重要作业先执行的同时，也保证短作业优先。
5. 时间片轮转：每个进程都分配相同的时间段去运行。

### 磁盘调度算法

1. 先来先服务：**按先后次序服务**，简单，公平。但可能会因为两次请求导致从最内到最外的柱面寻道，使磁头反复移动。
2. 最短寻找时间优先：优先选择离磁头移动 **距离最短** 的请求进行服务。但不能保证平均寻道时间最短，也会导致 **饥饿现象**。
3. 扫描算法（电梯算法）：磁头按一个方向移动，并为对应的请求服务，移动过程中会判断该方向是否还有请求，没有则改变方向。但这样会导致另一端的请求出现饥饿。
4. 循环扫描算法：在扫描算法的基础上，处理完最后一个请求时返回起点（而不是往另一方向移动），避免另一端请求的饥饿。

### 原码、反码、补码

比如是8位二进制：

​	1的原码为 0000 0001

​	-1的原码为 1000 0001

因此第一位是符号位，所以8位二进制数的取值范围为[-128,127]

也就是[1000 0000,0111 1111]

**正数的反码是其本身，负数的反码为除符号位以外各个位取反。**

[00000001]原 = [00000001]反

[10000001]原 = [11111110]反

**正数的补码是其本身，负数的补码为除符号位以外各个位取反再+1。**其实就是负数的补码=负数的反码+1。

要得到一个负数在计算机如何表示，比如-5，设位数为8，那-5的原码就是10000101

但是计算机不是存这个，而是需要转换成补码来存，除符号位外取反，得到11111010。

然后再加一，得到11111011，就是-5的二进制值。



Java的非运算符 ~ （不会。。意思是取反，但是步骤有点多理解不了）



### 死锁

必要条件：

1. 互斥：一个资源只有一个进程可以访问。
2. 占有并等待：一个进程占有一个以上的资源的同时，等待另一个进程所占用的资源。
3. 非抢占：资源不能被抢占。
4. 循环等待：你等着我的资源，我等着你的资源。

最经典的一个死锁模拟，A占用B的锁，B占用A的锁，我们只要破坏了他们的循环等待这个条件就不会产生死锁了，因为死锁需要4个条件同时成立。

### 内存管理

1. 块式管理：将内存切成固定大小的块，将这些块分配给进程，会产生内碎片。
2. 页式管理：将内存分成页，通过页表对应逻辑地址和物理地址，页比块更小，因此内碎片更小。
3. 段式管理：由程序规定段的大小，每一段有逻辑信息，通过段表对应逻辑地址和物理地址，但内存有可能放不下刚好比它大一点的程序，因此会有外碎片。

4. 段页式管理：先将内存分成若干段，每个段分成若干页，结合了两者的优点。

### 虚拟地址

CPU的寻址是按照虚拟地址来寻址的，再通过**MMU**(内存管理单元)将虚拟地址转换为物理地址。

作用：

1. 防止用户程序直接操作物理地址，破坏系统。
2. 防止不同的程序同时操作同一物理地址。

优势：

1. 程序使用相邻虚拟地址来访问不相邻的物理地址。
2. 程序可以使用大于当前物理可用内存来运行。
3. 不同进程虚拟地址彼此隔离，进程之间无法同时修改同一物理地址。

### 虚拟内存

将一部分的硬盘空间当内存来使用，这部分就是虚拟内存。使得程序可以拥有超过当前可用物理内存的空间。

实现：

1. **请求分页存储管理**：利用页面置换算法，将程序当前所需要的页调入内存中，把不需要的页置换到外存。

   ![微信图片_20210531181619](https://raw.githubusercontent.com/jjames567/picture/main/微信图片_20210531181619-1622456466609.jpg)

   通过页号、页内位移先查快表，若有对应缓存数据则直接返回（少了一次io）。

   没缓存则先通过寄存器判断页号是否超出长度，符合则查快表得到物理地址。

2. **请求分段存储管理**：与请求分页性质差不多。

   ![微信图片_20210531181628](https://raw.githubusercontent.com/jjames567/picture/main/微信图片_20210531181628.jpg)

3. **请求段页式存储管理**：段号查段表 -> 找到页表 -> 找到物理地址

   ![微信图片_20210531181632](https://raw.githubusercontent.com/jjames567/picture/main/微信图片_20210531181632.jpg)

为什么说上面三个是虚拟内存的实现呢？

因为虚拟内存的本质是时间换空间，通过调入调出来以更小的空间来运行程序，而上面三种方法正是在分页、分段、段页的基础上虚拟内存的实现。

### 页面置换算法

在程序运行的过程中，当要访问的页不在内存中时，就会发生**缺页中断**，需要操作系统将其调入主存。

1. **最佳页面置换算法OPT** ：预知未来，把未来最长时间不再访问的页淘汰。
2. **先进先出页面置换算法FIFO**：淘汰最先进入内存的页面。
3. **最近最久未使用页面置换算法LRU**：对每个页面加个字段，记录上次访问经过的时间T，淘汰T最大的页面。(时间局部性)，Java可以通过 哈希+自定义双向链表实现。
4. **最少使用页面置换算法LFU**：淘汰一定时间内使用次数最少的页。



### 同步/异步/阻塞/非阻塞

**同步**：只有一条道路。

**异步**：有多条道路。

**阻塞**：车子停了。

**非阻塞**：车子在走。

**同步阻塞**：只有一条道路，但有一辆车子停了。

**同步非阻塞**：有一条道路，并且道路流畅。

**异步阻塞**：有多条道路，车子都停了。

**异步非阻塞**：有多条道路，车子都在正常运行。

那什么是 IO 呢？IO 就是数据的读写过程，针对上面的概念，可以与 IO 相对应。

**同步阻塞 IO**

比如 read 方法，就是同步阻塞 IO，因为阻塞 IO 的意思是 CPU 把数据从内核缓冲区拷贝到用户缓冲区的过程（或者相反），那为什么叫同步呢？因为下面的代码需要用到这个数据，因此只有一个线程在运行，也就是只有一条道路。

**同步非阻塞 IO**（不存在）

这个只是在数据没有准备好时，read 方法立刻返回，然后接着往下运行的情况。但其实是错误的理解，它实际上是不断地轮询缓冲区是否有数据（数据是否准备好），拷贝的过程还是阻塞的，因此同步和非阻塞本身就是悖论。

**异步阻塞 IO**

read 方法其实有两个过程，一个是等待数据，另一个是拷贝数据。异步阻塞 IO 就是用户线程不需要等待数据，也就是不需要监听缓冲区是否有数据，当有数据时，用户线程就会去拷贝数据到用户缓冲区。

**异步非阻塞 IO**

就是上面的两个过程都不需要用户线程去处理数据，数据来到时直接操作数据就行了。

有没有发现同步和异步的区别，其实就是单线程和多线程的区别，怎么把同步io变成异步io呢？是不是只要有另一个线程帮忙等待数据就行了？阻塞和非阻塞就更简单了，其实就是是否需要用户线程来拷贝数据。

### NIO

Java NIO 和 IO 之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 JavaIO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。Java NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。

#### 阻塞 IO

1. 服务器 ServerSocketChannel 去绑定一个端口进行监听。
2. 调用 accept 方法返回 SocketChannel ，并传给一个线程去调用 read 方法等待数据准备好，再执行接下来的逻辑。

服务端代码：

```java
public static void main(String[] args) throws IOException {

    ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();

    // 监听 8080 端口进来的 TCP 链接
    serverSocketChannel.socket().bind(new InetSocketAddress(8080));

    while (true) {

        // 这里会阻塞，直到有一个请求的连接进来
        SocketChannel socketChannel = serverSocketChannel.accept();

        // 开启一个新的线程来处理这个请求，然后在 while 循环中继续监听 8080 端口
        SocketHandler handler = new SocketHandler(socketChannel);
        new Thread(handler).start();
    }
}
```

子线程 SocketHandler：

```java
public class SocketHandler implements Runnable {

    private SocketChannel socketChannel;

    public SocketHandler(SocketChannel socketChannel) {
        this.socketChannel = socketChannel;
    }

    @SneakyThrows
    @Override
    public void run() {

        ByteBuffer buffer = ByteBuffer.allocate(1024);
        try {
            // 将请求数据读入 Buffer 中
            int num;
            while ((num = socketChannel.read(buffer)) > 0) {
                // 读取 Buffer 内容之前先 flip 一下
                buffer.flip();

                // 提取 Buffer 中的数据
                byte[] bytes = new byte[num];
                buffer.get(bytes);

                String re = new String(bytes, "UTF-8");
                System.out.println("收到请求：" + re);

                // 回应客户端
                ByteBuffer writeBuffer = ByteBuffer.wrap(("我已经收到你的请求，你的请求内容是：" + re).getBytes());
                socketChannel.write(writeBuffer);

                buffer.clear();
            }
        } catch (IOException e) {
            System.out.println(e.toString());
        } finally {
            socketChannel.close();
        }
    }
}
```

有两个问题，第一个是线程数量会随着连接数上升，第二个是主线程 accpet 方法会阻塞，子线程 read 方法也会阻塞，导致线程资源浪费。

#### 非阻塞模式

IO 多路复用

使用一个 Selector 来管理多个通道，可以是 SocketChannel，也可以是 ServerSocketChannel，将各个通道注册到 Selector 上，指定监听的事件。

Selector 其实是操作系统中多路复用的抽象，分别有 select、poll、epoll 等。之前也说过了，当有数据准备好时，就会返回给。那为什么说它是非阻塞的呢？之前说了，阻不阻塞要看用户线程是否参与数据拷贝。

它的过程大概是这样的：

1. 服务器 ServerSocketChannel 去绑定一个端口进行监听。
2. 将其 channel 注册到 Selector 中，注册事件为连接事件。
3. 调用 selector.select() 会返回接收到请求的 channel。
4. 判断该 channel 是否是第一次连接，是则创建连接，并注册读取事件进行监听，否则判断是否是读取事件，是则进行读取。

先看看下面的非阻塞代码：

```java
public static void main(String[] args) throws IOException {
    Selector selector = Selector.open();

    ServerSocketChannel server = ServerSocketChannel.open();
    server.socket().bind(new InetSocketAddress(8080));

    // 将其注册到 Selector 中，监听 OP_ACCEPT 事件
    server.configureBlocking(false);
    server.register(selector, SelectionKey.OP_ACCEPT);

    while (true) {
        int readyChannels = selector.select();
        if (readyChannels == 0) {
            continue;
        }
        Set<SelectionKey> readyKeys = selector.selectedKeys();
        // 遍历
        Iterator<SelectionKey> iterator = readyKeys.iterator();
        while (iterator.hasNext()) {
            SelectionKey key = iterator.next();
            iterator.remove();

            if (key.isAcceptable()) {
                // 有已经接受的新的到服务端的连接
                SocketChannel socketChannel = server.accept();

                // 有新的连接并不代表这个通道就有数据，
                // 这里将这个新的 SocketChannel 注册到 Selector，监听 OP_READ 事件，等待数据
                socketChannel.configureBlocking(false);
                socketChannel.register(selector, SelectionKey.OP_READ);
            } else if (key.isReadable()) {
                // 有数据可读
                // 上面一个 if 分支中注册了监听 OP_READ 事件的 SocketChannel
                SocketChannel socketChannel = (SocketChannel) key.channel();
                ByteBuffer readBuffer = ByteBuffer.allocate(1024);
                int num = socketChannel.read(readBuffer);
                if (num > 0) {
                    // 处理进来的数据...
                    System.out.println("收到数据：" + new String(readBuffer.array()).trim());
                    ByteBuffer buffer = ByteBuffer.wrap("返回给客户端的数据...".getBytes());
                    socketChannel.write(buffer);
                } else if (num == -1) {
                    // -1 代表连接已经关闭
                    socketChannel.close();
                }
            }
        }
    }
}
```

**注意这个并不是非阻塞 IO，而只是非阻塞模式**，非阻塞体现在：

1. 线程在处理请求时这个过程是非阻塞的，会直接注册相关事件，注册完可以立即处理下一个请求，假如是可读事件的话，则会交给工作线程（worker）来处理，对于boss线程来说都是不阻塞的。
2. 调用 accept、read 方法时会立刻返回，无论是否有数据，当然这也是上面提到的同步非阻塞的问题，通过轮询的方式来执行，实际也是阻塞io。

### 字符流和字节流

实际上字节流在操作时本身不会用到缓冲区（内存），是文件本身直接操作的，而字符流在操作时使用了缓冲区，通过缓冲区再操作文件。

使用字节流不关闭OutputStream：

```java
// 第1步：使用File类找到一个文件    
     File f = new File("d:" + File.separator + "test.txt"); // 声明File  对象    
// 第2步：通过子类实例化父类对象    
     OutputStream out = null;            
// 准备好一个输出的对象    
     out = new FileOutputStream(f);      
// 通过对象多态性进行实例化    
// 第3步：进行写操作    
     String str = "Hello World!!!";      
// 准备一个字符串    
     byte b[] = str.getBytes();          
// 字符串转byte数组    
     out.write(b);                      
// 将内容输出    
 // 第4步：关闭输出流    
    // out.close();                  
// 此时没有关闭  
```

此时文件已经写入数据。

使用字符流不关闭Writer：

```java
// 第1步：使用File类找到一个文件    
        File f = new File("d:" + File.separator + "test.txt");// 声明File 对象    
// 第2步：通过子类实例化父类对象    
        Writer out = null;                 
// 准备好一个输出的对象    
        out = new FileWriter(f);            
// 通过对象多态性进行实例化    
// 第3步：进行写操作    
        String str = "Hello World!!!";      
// 准备一个字符串    
        out.write(str);                    
// 将内容输出    
// 第4步：关闭输出流    
		// out.close();                   
// 此时没有关闭 
```

最后文件并没有写入数据。

这是因为字符流是使用到了缓冲区的，但字节流是直接操作数据的。

针对字符流，我们可以调用 out.flush() 来将缓冲区的数据写入文件。

```java
Writer out = null;                   
// 准备好一个输出的对象    
out = new FileWriter(f);             
// 通过对象多态性进行实例化    
// 第3步：进行写操作    
String str = "Hello World!!!";      
// 准备一个字符串    
out.write(str);                    
// 将内容输出    
out.flush(); 
```

那实际开发使用哪个更好呢？

字节流可以处理一切文件，而字符流只能处理纯文本文件。





## 数据结构与算法

纯靠刷题可能效率相对来说比较低，为了快速复习这里把刷过的题分门别类地记录下来。

### 链表

#### K个一组翻转链表

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711095339335.png" alt="image-20210711095339335" style="zoom:50%; margin-left:-5px" />

```java
public static ListNode reverseKGroup(ListNode head, int k) {
    int num = 0;
    ListNode cur = head;
    ListNode pre = null;
    ListNode preLast = null;
    boolean flag = true;
    while (num < k){
        // 保存下一个结点
        ListNode next = cur.next;
        // 当前结点指向前一个结点，前一个结点指向null
        cur.next = pre;
        // 更新cur和pre
        pre = cur;
        cur = next;
        num++;
        // 判断是否是范围内的最后一个结点
        if (num == k){
            if (flag){
                // 保存首结点
                head = pre;
                flag = false;
            }
            // 前一个范围的最后一个结点连接当前范围内的第一个结点
            if (preLast != null)
                preLast.next = pre;
            // 指针移动到当前范围内的最后一个结点
            for (int i = 0; i < k-1; i++) {
                pre = pre.next;
            }
            // 指向下一个范围的第一个结点
            pre.next = cur;
            preLast = pre;
            pre = null;
            // 重置范围计数
            num = 0;
            // 判断后面的结点范围是否达到k
            ListNode temp = preLast;
            while (num < k){
                temp = temp.next;
                if (temp == null)
                    return head;
                num++;
            }
            num = 0;
        }
    }
    return head;
}
```

#### 反转链表

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711095547737.png" alt="image-20210711095547737" style="zoom:50%; margin-left:-5px" />

```java
public static ListNode reverseList(ListNode head) {
    if (head == null || head.next == null){
        return head;
    }
    ListNode last = reverseList(head.next);
    head.next.next = head;
    head.next = null;
    return last;
}
```

#### 合并两个有序链表

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711095938700.png" alt="image-20210711095938700" style="zoom:50%; margin-left:-5px" />

```java
public static ListNode mergeTwoLists(ListNode l1, ListNode l2) {
    if (l1 == null) return l2;
    else if (l2 == null) return l1;
    // 对比两个结点的值
    else if (l1.val > l2.val){
        l1.next = mergeTwoLists(l1, l2);
        return l1;
    }else {
        l2.next = mergeTwoLists(l1, l2);
        return l2;
    }
}
```

#### 排序链表

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711100052125.png" alt="image-20210711100052125" style="zoom:50%; margin-left:-5px" />

```java
public ListNode sortList(ListNode head) {

    if (head == null || head.next == null){
        return head;
    }

    // 利用快慢指针找到中点（不一定是中点）
    ListNode slow = head;
    ListNode fast = head;
    while (fast.next != null && fast.next.next != null && slow.next != null){
        fast = fast.next.next;
        slow = slow.next;
    }

    // 中点为slow，先断开，再进行二分
    ListNode right = slow.next;
    slow.next = null;

    ListNode left = sortList(head);
    right = sortList(right);

    // 将子节点归并，h为辅助节点
    ListNode h = new ListNode(0);
    ListNode result = h;
    while (left != null && right != null){
        if (left.val > right.val){
            h.next = left;
            left = left.next;
        }else {
            h.next = right;
            right = right.next;
        }
        h = h.next;
    }

    // 接上剩下的节点
    h.next = left == null ? right : left;

    return result.next;
}
```

#### 环形链表

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711100142248.png" alt="image-20210711100142248" style="zoom:50%; margin-left:-5px" />

```java
public static boolean hasCycle(ListNode head) {
    ListNode slow = head;
    if (head.next == null || head == null)
        return false;
    ListNode quick = head.next.next;
    while (quick != null){
        if (slow == quick){
            return true;
        }else {
            slow = slow.next;
            quick = quick.next.next;
        }
    }
    return false;
}
```

#### 相交链表

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711100257919.png" alt="image-20210711100257919" style="zoom:50%; margin-left:-5px" />

```java
public static ListNode getIntersectionNode(ListNode headA, ListNode headB) {
    Set<ListNode> set = new HashSet<>();
    while (headA != null){
        set.add(headA);
        headA = headA.next;
    }
    while (headB != null){
        if (!set.add(headB))
            return headB;
        else headB = headB.next;
    }
    return null;
}
```

#### 复杂链表的复制

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711100434793.png" alt="image-20210711100434793" style="zoom:50%; margin-left:-5px" />

```java
public Node copyRandomList(Node head) {
    if (head == null) return null;
    Map<Node, Node> map = new HashMap<>();
    Node headTemp = head;
    while (headTemp != null){
        map.put(headTemp, new Node(headTemp.val));
        headTemp = headTemp.next;
    }

    Node result = head;

    while (head != null){
        Node cur = map.get(head);
        cur.next = map.get(head.next);
        cur.random = map.get(head.random);
        head = head.next;
    }

    return map.get(result);
}
```



### 数组

#### 两数之和

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711100651326.png" alt="image-20210711100651326" style="zoom:50%; margin-left:-5px" />

```java
public int[] twoSum(int[] nums, int target) {
    int result[] = new int[2];
    int temp = 0;
    for (int i = 0; i < nums.length; i++) {
        temp = target - nums[i];
        result[0] = i;
        for (int j = 0; j < nums.length; j++) {
            if (j==i) continue;
            if (temp-nums[j] == 0){
                result[1] = j;
                return result;
            }
        }
    }
    return result;
}
```

#### 三数之和

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711100746514.png" alt="image-20210711100746514" style="zoom:50%; margin-left:-5px" />

```java
public List<List<Integer>> threeSum(int[] nums) {
    List<List<Integer>> result = new ArrayList<>();
    List<Integer> list;
    // 排序数组
    Arrays.sort(nums);
    for (int i = 0; i < nums.length-1; i++) {
        // 确定第一个数
        int temp = nums[i];
        // 假如与上一个数相同则跳过
        if (i >= 1 && ( temp > 0 || temp == nums[i-1] )) continue;
        for (int j = i+1; j < nums.length-1; j++) {
            // 确定第二个数
            int left = nums[j];
            // 假如与上一个数相同则跳过
            if (j > i+1 && left == nums[j-1]) continue;
            int k = nums.length-1;
            while (nums[k] + nums[j] > -temp && k != j){
                k--;
            }
            while (k != j){
                if (k < nums.length-1 && nums[k] == nums[k+1]){
                    k--;
                    continue;
                }
                int right = nums[k];
                if (temp+left+right == 0){
                    list = new ArrayList<>();
                    list.add(temp);
                    list.add(left);
                    list.add(right);
                    result.add(list);
                }
                k--;
            }
        }
    }
    return result;
}
```

#### 买卖股票的最佳时机

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711100909370.png" alt="image-20210711100909370" style="zoom:50%; margin-left:-5px" />

```java
public static int maxProfit(int[] prices) {
    int length = prices.length;
    int max = 0,min = prices[0];
    for (int i = 1; i < length; i++) {
        max = Math.max(prices[i] - min,max);
        min = Math.min(prices[i], min);
    }
    return max;
}
```

#### 二分查找

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711101016654.png" alt="image-20210711101016654" style="zoom:50%; margin-left:-5px" />

````java
public static int search(int[] nums, int target) {
    int left = 0, right = nums.length-1;
    while (left<=right){
        int index = (left+right)/2;
        if (target == nums[index]) return index;
        else if (target > nums[index]) left = index+1;
        else right = index-1;
    }
    return -1;
}
````

#### 合并两个有序数组

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711101116987.png" alt="image-20210711101116987" style="zoom:50%; margin-left:-5px" />

```java
// 从后往前遍历
class Solution {
    public void merge(int[] nums1, int m, int[] nums2, int n) {
        int p1 = m - 1, p2 = n - 1;
        int tail = m + n - 1;
        int cur;
        while (p1 >= 0 || p2 >= 0) {
            if (p1 == -1) {
                cur = nums2[p2--];
            } else if (p2 == -1) {
                cur = nums1[p1--];
            } else if (nums1[p1] > nums2[p2]) {
                cur = nums1[p1--];
            } else {
                cur = nums2[p2--];
            }
            nums1[tail--] = cur;
        }
    }
}
```

#### 雨接水

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711101223777.png" alt="image-20210711101223777" style="zoom:50%; margin-left:-5px" />

```java
public int trap(int[] height) {
    int totalArea = 0;
    int i = 0;
    label: while (i < height.length) {
        int area = 0;
        int left = height[i]; // 左侧
        if (left == 0){
            i++;
            continue; // 为0时不能作为两侧
        }
        for (int j = i+1; j < height.length; j++) {
            if (height[j] < height[i]) continue; // 右边至少高于等于左边
            int right = height[j]; // 右侧
            // 以左右侧为边界，计算中间面积
            // 先计算总面积
            int minHeight = 0;
            if (left > right) minHeight = right;
            else minHeight = left;
            area = minHeight * (j-i-1);
            // 再计算中间阴影
            for (int k = i+1; k < j; k++) {
                if (height[k] != 0){
                    area -= height[k];
                }
            }
            totalArea += area;
            i = j; // 把左侧挪到右侧
            continue label;
        }
        if (area == 0){
            height[i]--;
            continue;
        }
    }
    return totalArea;
}
```

#### 搜索旋转排序数组

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711101357652.png" alt="image-20210711101357652" style="zoom:50%; margin-left:-5px" />

```java
public static int search(int[] nums, int target) {
    int left = 0;
    int right = nums.length - 1;
    if (right == 0) return target == nums[0]?0:-1;
    while (left <= right){
        int index = (left+right)/2;
        if (target == nums[index]) return index;
        else {
            // 定位在左侧
            if (nums[index] >= nums[0]){
                // 第二个条件是防止目标数在右侧
                if (nums[index] > target && target >= nums[0]){
                    right = index - 1;
                }else left = index + 1;
            }else {
                // 定位在右侧，第二个条件是防止目标数在左侧（要注意这两个条件是要都符合才left = index + 1）
                if (nums[index] < target && target <= nums[nums.length-1]){
                    left = index + 1;
                }else right = index - 1;
            }
        }
    }
    return -1;
}
```

#### 数组中的第k个最大元素-堆排

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711101536961.png" alt="image-20210711101536961" style="zoom:50%; margin-left:-5px" />

```java
public static int adjustHead(int nums[], int index, int length, int k){
    int left = index*2+1, right = index*2+2;
    int target = nums[index];
    if (left < length){
        boolean flag = false;
        if (nums[left] > target){
            target = nums[left];
            flag = true;
        }
        if (right < length){
            if (nums[right] > target) {
                target = nums[right];
                left = right;
                flag = true;
            }
        }
        if (flag){
            nums[left] = nums[index];
            nums[index] = target;
        }
    }
    // 已经到达根位置，与最后一个叶子交换位置8
    if (index == 0){
        int temp = nums[0];
        nums[0] = nums[length-1];
        nums[length-1] = temp;

        // 处理剩余元素
        length-=1;

        if (nums.length - length == k){
            return nums[length];
        }

        return adjustHead(nums, length > 1 ? length/2-1 : 1, length, k);
    }else {
        // 调整上一个非叶子结点
        return adjustHead(nums, index-1, length > 0 ? length : 1, k);
    }
}
```

#### 数组中的第k个最大元素-快排

```java
public static int findKthLargest(int[] nums, int k) {
    if (nums.length <=1)
        return nums[0];
    Random random = new Random();
    // 随机下标，以这个下标找到目标数
    int ranIndex = random.nextInt(nums.length);
    int left = 0;
    int right = nums.length-1;
    return adjust(nums, left, right, ranIndex, k, random);
}
public static int adjust(int[] nums, int left, int right, int ranIndex, int k, Random random){
    int temp,start = left,end = right;
    if (ranIndex == right || ranIndex < left)
        ranIndex = left;
    // 把目标数放在首位
    int target = nums[ranIndex];
    nums[ranIndex] = nums[left];
    nums[left] = target;
    while (left < right){
        // 要把比目标数小的放左边，大的放右边，注意从右边开始找
        while (right > left && nums[right] >= target){
            right--;
        }
        while (left < right && nums[left] <= target){
            left++;
        }
        temp = nums[left];
        nums[left] = nums[right];
        nums[right] = temp;
    }
    // 与lr相遇位置交换
    temp = nums[start]; // left和right一样
    nums[start] = nums[left];
    nums[left] = temp;

    // 判断是否刚好是第k个最大元素
    if (left == nums.length-k){
        return nums[left];
    }else {
        if (left > nums.length-k){
            ranIndex = random.nextInt(left);
            return adjust(nums, start, --left, ranIndex, k, random);
        }
        else {
            ranIndex = random.nextInt(end-left)+left+1;
            return adjust(nums, ++left, end, ranIndex, k, random);
        }
    }
}
```

#### 斐波那契数列

```java
public static int fib(int n) {
    if (n == 0)
        return 0;
    if (n == 1 || n == 2)
        return 1;
    return fib(n-1) + fib(n-2);
}
```

#### 最大字序和

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711101811540.png" alt="image-20210711101811540" style="zoom:50%; margin-left:-5px" />

```java
public static int maxSubArray(int[] nums) {
    if (nums.length == 1) return nums[0];
    int max = nums[0];
    int pre = 0;
    for (int i = 0; i < nums.length; i++) {
        pre = Math.max(nums[i], nums[i] + pre);
        max = Math.max(max, pre);
    }
    return max;
}
```

#### 盛最多水的容器

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711101922248.png" alt="image-20210711101922248" style="zoom:50%; margin-left:-5px" />

```java
public int maxArea(int[] height) {
    int maxArea = 0;
    int i = 0,j = height.length-1;
    while (i<j) {
        int left = height[i];
        int right = height[j];
        int minHeight = 0;
        if (left>right){
            minHeight = right;
            int area = minHeight * (j-i);
            if (area > maxArea) maxArea = area;
            j--;
        }
        else{
            minHeight = left;
            int area = minHeight * (j-i);
            if (area > maxArea) maxArea = area;
            i++;
        }
    }
    return maxArea;
}
```

#### 螺旋矩阵

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711102032763.png" alt="image-20210711102032763" style="zoom:50%; margin-left:-5px" />

```java
public static List<Integer> spiralOrder(int[][] matrix) {
    List<Integer> result = new ArrayList<>();
    int right = matrix[0].length-1, bottom = matrix.length - 1, left = 0, top = 0;
    while (left <= right && top <= bottom){
        for (int column = left; column <= right; column++) {
            result.add(matrix[top][column]);
        }
        for (int row = top+1; row <= bottom; row++) {
            result.add(matrix[row][right]);
        }
        // 为了防止“倒流”，通常出现在最后一行或者最后一列
        if (left < right && top < bottom) {
            for (int column = right - 1; column >= left; column--) {
                result.add(matrix[bottom][column]);
            }
            for (int row = bottom - 1; row > top; row--) {
                result.add(matrix[row][left]);
            }
        }
        left++;
        right--;
        top++;
        bottom--;
    }
    return result;
}
```

#### 二维数组中的查找

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711102153844.png" alt="image-20210711102153844" style="zoom:50%; margin-left:-5px" />

```java
// 先从右上角开始，较大则移动到下一行，较小则移动到前一列
class Solution {
    public boolean findNumberIn2DArray(int[][] matrix, int target) {
        if (matrix == null || matrix.length == 0 || matrix[0].length == 0) {
            return false;
        }
        int rows = matrix.length, columns = matrix[0].length;
        int row = 0, column = columns - 1;
        while (row < rows && column >= 0) {
            int num = matrix[row][column];
            if (num == target) {
                return true;
            } else if (num > target) {
                column--;
            } else {
                row++;
            }
        }
        return false;
    }
}
```

#### 数组中重复的数字

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711102309114.png" alt="image-20210711102309114" style="zoom:50%; margin-left:-5px" />

```java
public int findRepeatNumber(int[] nums) {
    Set<Integer> set = new HashSet<>();
    for (int i = 0; i < nums.length; i++) {
        if (set.add(nums[i])){
            continue;
        }else return nums[i];
    }
    return -1;
}
```

#### 旋转数组的最小数字

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711102358398.png" alt="image-20210711102358398" style="zoom:50%; margin-left:-5px" />

```java
public static int minArray(int[] numbers) {
    int low = 0, high = numbers.length - 1;
    int mid;
    while (low < high) {
        mid = (low + high) / 2;
        if (numbers[mid] > numbers[high]) {
            low = mid + 1;
        }else if (numbers[mid] < numbers[high]){
            high = mid;
        }else high--;
    }
    return numbers[low];
}
```

#### 调整数组顺序使得奇数位于偶数前

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711102508933.png" alt="image-20210711102508933" style="zoom:50%; margin-left:-5px" />

```java
public int[] exchange(int[] nums) {
    int[] result = new int[nums.length];
    int preIndex = 0;
    int lastIndex = result.length - 1;
    for (int i = 0; i < nums.length; i++) {
        if (nums[i] % 2 != 0){
            result[preIndex] = nums[i];
            preIndex++;
        }else {
            result[lastIndex] = nums[i];
            lastIndex--;
        }
    }
    return result;
}
```

#### 矩阵中的路径(dfs)

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711102658746.png" alt="image-20210711102658746" style="zoom:50%; margin-left:-5px" />

```java
public boolean exist(char[][] board, String word) {
    char[] chars = word.toCharArray();
    for (int i = 0; i < board.length; i++) {
        for (int j = 0; j < board[0].length; j++) {
            if (dfs(board, i, j, chars, 0)) return true;
        }
    }
    return false;
}

private boolean dfs(char[][] board, int i, int j, char[] chars, int index) {
    if (i < 0 || j < 0 || i > board.length-1 || j > board[i].length-1 || chars[index] != board[i][j])
        return false;
    if (index == chars.length-1) return true;
    board[i][j] = '?';
    boolean result = dfs(board, i-1, j, chars, index+1) ||
        dfs(board, i, j+1, chars, index+1) ||
        dfs(board, i+1, j, chars, index+1) ||
        dfs(board, i, j-1, chars, index+1);
    board[i][j] = chars[index];
    return result;
}
```

#### 全排列

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711102954976.png" alt="image-20210711102954976" style="zoom:50%; margin-left:-5px" />

```java
public static List<List<Integer>> permute(int[] nums) {
    List<List<Integer>> result = new ArrayList<>();
    List<Integer> cur = new ArrayList<>();
    handle(result, cur, nums, 0);
    return result;
}

private static void handle(List<List<Integer>> result, List<Integer> cur, int nums[], int index) {
    // 满了则保存
    if (cur.size() == nums.length){
        result.add(new ArrayList<>(cur));
        return;
    }
    // 注意这里的i只能是0
    for (int i = 0; i < nums.length; i++) {
        Integer num = nums[i];
        if (cur.contains(num)){
            continue;
        }else {
            cur.add(num);
            handle(result, cur, nums, index+1);
            cur.remove(num);
        }
    }
}
```

#### 岛屿数量(dfs)

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711103139685.png" alt="image-20210711103139685" style="zoom:50%; margin-left:-5px" />

```java
public static int numIslands(char[][] grid) {
    // 遍历数组
    for (int i = 0; i < grid.length; i++) {
        for (int j = 0; j < grid[0].length; j++) {
            if (grid[i][j] == '1'){
                num++;
                handle(grid, i, j);
            }
        }
    }
    return num;
}

public static void handle(char[][] grid, int i, int j){
    grid[i][j] = '0';
    // 把最近为1的格子均设为0
    if (i > 0 && grid[i-1][j] == '1')
        handle(grid, i-1, j);
    if (j > 0 && grid[i][j-1] == '1')
        handle(grid, i, j-1);
    if (i < grid.length-1 && grid[i+1][j] == '1')
        handle(grid, i+1, j);
    if (j < grid[0].length-1 && grid[i][j+1] == '1')
        handle(grid, i, j+1);
}
```



### 树

#### 中序遍历

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711103259051.png" alt="image-20210711103259051" style="zoom:50%; margin-left:-5px" />

```java
public static List<Integer> inorderTraversal(TreeNode root) {
    handle(root);
    return result;
}

// 左中右
private static void handle(TreeNode root){
    if (root == null) return ;
    handle(root.left);
    result.add(root.val);
    handle(root.right);
}
```

#### 层序遍历(bfs)

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711103434577.png" alt="image-20210711103434577" style="zoom:50%; margin-left:-5px" />

```java
// 就是树的广度优先遍历，不需要使用递归
public static List<List<Integer>> levelOrder(TreeNode root) {
    List<List<Integer>> result = new ArrayList<>();
    // 当前结点
    TreeNode cur = root;
    if (cur == null) return result;
    Queue<TreeNode> queue = new LinkedList<>();
    // 将其入队
    queue.offer(cur);
    while (!queue.isEmpty()) {
        // 记录当前队列长度
        int currentLen = queue.size();
        // 记录当前层级的结点数据
        List<Integer> data = new ArrayList<>();
        for (int i = 0; i < currentLen; i++) {
            // 出队并记录
            cur = queue.poll();
            data.add(cur.val);
            if (cur.left != null){
                queue.offer(cur.left);
            }
            if (cur.right != null){
                queue.offer(cur.right);
            }
        }
        // 出了循环说明已经遍历完一层了
        result.add(data);
    }
    return result;
}
```

#### 最近公共祖先

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711103540127.png" alt="image-20210711103540127" style="zoom:50%;margin-left:-5px" />

```java
public static TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) {
    if (root == null) return null;
    result = root;
    handle(root, p, q);
    return result;
}

public static boolean handle(TreeNode root, TreeNode p, TreeNode q){
    if (root == null) return false;
    // 左子节点
    boolean isLeft = handle(root.left, p, q);
    // 右子结点
    boolean isRight = handle(root.right, p, q);

    // 是否同时符合左子节点和右子节点 || 节点本身就是当前root && 存在左右子节点
    if ((isLeft && isRight) || (root.val == p.val || root.val == q.val) && (isLeft || isRight)){
        result = root;
    }
    // 假如左子节点右子节点都返回true本结点才是true，||后面的意思是有其中一个节点是root，也是返回true，否则会因为第一行的null而返回false
    return ((isLeft && isRight) || root.val == p.val || root.val == q.val);
}
```

#### 锯齿形层序遍历

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711103636273.png" alt="image-20210711103636273" style="zoom:50%;margin-left:-5px" />

```java
public static List<List<Integer>> levelOrder(TreeNode root) {
    List<List<Integer>> result = new ArrayList<>();
    // 当前结点
    TreeNode cur = root;
    if (cur == null) return result;
    Queue<TreeNode> queue = new LinkedList<>();
    // 将其入队
    queue.offer(cur);
    while (!queue.isEmpty()) {
        // 记录当前队列长度
        int currentLen = queue.size();
        // 记录当前层级的结点数据
        List<Integer> data = new ArrayList<>();
        for (int i = 0; i < currentLen; i++) {
            // 出队并记录
            cur = queue.poll();
            data.add(cur.val);
            if (cur.left != null){
                queue.offer(cur.left);
            }
            if (cur.right != null){
                queue.offer(cur.right);
            }
        }
        // 出了循环说明已经遍历完一层了

        result.add(data);
    }
    return result;
}
```

#### 二叉树的镜像

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711103812923.png" alt="image-20210711103812923" style="zoom:50%; margin-left:-5px" />

```java
public TreeNode mirrorTree(TreeNode root) {
    handle(root);
    return root;
}

private void handle(TreeNode root) {
    if (root == null) return;
    TreeNode left = root.left;
    TreeNode right = root.right;
    if (left != null && right != null){
        root.right = left;
        root.left = right;
    }else {
        if (left == null && right != null){
            root.left = right;
            root.right = null;
        }else if (right == null && left != null){
            root.right = left;
            root.left = null;
        }
    }
    handle(root.left);
    handle(root.right);
}
```

#### 对称的二叉树

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711103916696.png" alt="image-20210711103916696" style="zoom:50%;margin-left:-5px" />

```java
public boolean isSymmetric(TreeNode root) {
    if (root == null) return false;
    return handle(root);
}

private boolean handle(TreeNode root) {
    TreeNode left = root.left;
    TreeNode right = root.right;
    return handle2(left, right);
}

private boolean handle2(TreeNode left, TreeNode right){
    if (left != null && right != null){
        if (left.val == right.val){
            return handle2(left.left, right.right) && handle2(left.right, right.left);
        }else return false;
    }
    if (left == null && right == null)
        return true;
    return false;
}
```

#### 树的子结构

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711104047311.png" alt="image-20210711104047311" style="zoom:50%;margin-left:-5px" />

```java
public boolean isSubStructure(TreeNode A, TreeNode B) {
    if (A == null || B == null) return false;
    if (A.val == B.val && helper(A.left, B.left) && helper(A.right, B.right)){
        return true;
    }
    return isSubStructure(A.left, B) || isSubStructure(A.right, B);
}

private boolean helper(TreeNode root1, TreeNode root2) {
    if (root2 == null) {
        return true;
    }
    if (root1 == null) {
        return false;
    }
    if (root1.val == root2.val) {
        return helper(root1.left, root2.left) && helper(root1.right, root2.right);
    } else {
        return false;
    }
}
```

#### 重建二叉树

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711104134278.png" alt="image-20210711104134278" style="zoom:50%;margin-left:-5px" />

```java
Map<Integer,Integer> map = new HashMap<>();
int[] preorder;

public TreeNode buildTree(int[] preorder, int[] inorder) {
    this.preorder = preorder;
    for (int i = 0; i < inorder.length; i++) {
        map.put(inorder[i], i);
    }
    return handle(0,0,preorder.length-1);
}

// 参数意思为preorder数组下标，inorder左右范围
private TreeNode handle(int curIndex, int left, int right) {
    if (left > right) return null;
    TreeNode node = new TreeNode(preorder[curIndex]);
    int index = map.get(preorder[curIndex]);
    node.left = handle(curIndex+1, left, index - 1);
    // 当前preorder下标 + inorder对应下标左边的子树数量 + 1
    node.right = handle(curIndex + (index - left) + 1, index + 1, right);
    return node;
}
```



### 字符串

#### 无重复字符的最长字串

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711105114741.png" alt="image-20210711105114741" style="zoom:50%;margin-left:-5px" />

```java
public static int lengthOfLongestSubstring(String s) {
    // 记录字符上一次出现的位置
    int[] last = new int[128];
    for(int i = 0; i < 128; i++) {
        last[i] = -1;
    }
    int n = s.length();

    int res = 0;
    int start = 0; // 窗口开始位置
    for(int i = 0; i < n; i++) {
        int index = s.charAt(i);
        start = Math.max(start, last[index] + 1);
        res   = Math.max(res, i - start + 1);
        last[index] = i;
    }

    return res;
}
```

#### 最长公共前缀

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711105304665.png" alt="image-20210711105304665" style="zoom:50%;margin-left:-5px" />

```java
class Solution {
    public String longestCommonPrefix(String[] strs) {
        if (strs == null || strs.length == 0) {
            return "";
        }
        // 以第一个数为参考
        int length = strs[0].length();
        int count = strs.length;
        for (int i = 0; i < length; i++) {
            // 对应下标的字符
            char c = strs[0].charAt(i);
            // 往右移动
            for (int j = 1; j < count; j++) {
                // 与目标数比较
                if (i == strs[j].length() || strs[j].charAt(i) != c) {
                    return strs[0].substring(0, i);
                }
            }
        }
        return strs[0];
    }
}
```



#### 有效的括号

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210711105727278.png" alt="image-20210711105727278" style="zoom:50%;margin-left:-5px" />

```java
public static boolean isValid(String s) {
    String[] arr = s.split("");
    if (arr.length <= 1) return false;
    Stack<String> stack = new Stack<>();
    for (int i = 0; i < arr.length; i++) {
        if (arr[i].equals("(") || arr[i].equals("{") || arr[i].equals("[")){
            stack.push(arr[i]);
        }else {
            if (stack.isEmpty()) return false;
            String pop = stack.pop();
            String target = "";
            switch (pop){
                case "(": target = ")"; break;
                case "{": target = "}"; break;
                case "[": target = "]";
            }
            if (!arr[i].equals(target))
                return false;
        }
    }
    return stack.empty();
}
```





### bfs



### dfs





## MySQL

### 整体结构

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210531131730886.png" alt="image-20210531131730886" style="zoom: 50%;" />

### 存储引擎

#### InnoDB

1. 是MySQL默认的存储引擎。
2. 使用MVCC支持高并发，实现了四个隔离级别，支持事务，支持行级锁，支持外键。
3. 支持数据热备份。

#### MyISAM

1. 不支持事务。
2. 不支持行锁，只支持表锁。
3. 不支持外键。

两者的详细区别：https://www.jianshu.com/p/95a0d10eb881

### 索引

#### 数据结构

B树结构：

![image-20210530220819598](https://raw.githubusercontent.com/jjames567/picture/main/image-20210530220819598.png)

**注意**：键值是指索引字段

缺点：

1. 范围查询每次都要从头开始找，效率低。
2. 每页所存储的数据很少，因为存的是一整行的数据，因此每次io所获取到的数据量很少。

B+树：

![image-20210530221130280](https://raw.githubusercontent.com/jjames567/picture/main/image-20210530221130280.png)

优势：

1. 除叶子节点外都没有存数据，增加每次io效率，同时使得树变得更矮。
2. 叶子节点之间为双向链表，方便进行范围查询。

#### MyIsam

索引实现：B+树

叶子节点存的是数据的内存地址，主键索引和辅助索引都是这样。

![image-20210530222011138](https://raw.githubusercontent.com/jjames567/picture/main/image-20210530222011138.png)

#### InnoDB

##### 主键索引

跟上面说的B+树一样，叶子节点存的是整行数据。

![image-20210530222147435](https://raw.githubusercontent.com/jjames567/picture/main/image-20210530222147435.png)

##### 辅助索引

也是B+树，但叶子节点的数据是主键id的值。

![image-20210530222258053](https://raw.githubusercontent.com/jjames567/picture/main/image-20210530222258053.png)

因此想要获取完整的数据需要重新走一遍主键索引，这个过程叫做**回表**。

##### 组合索引

多个字段组合成索引key，可以看到是以左边的值优先排序。

![image-20210530222458026](https://raw.githubusercontent.com/jjames567/picture/main/image-20210530222458026.png)

因此在查询时，左边的会优先匹配，这叫做**最左匹配原则**。

假如是范围查询，会在范围查询的字段停止，后面的字段不再走索引，因此我们要尽量把要范围查询的字段放在索引的最后。

同时可以发现，组合索引虽然没保存整行记录，但它保存了索引中的key，因此当我们只需要查询索引中存在的字段时，就可以以select a,b,c from xxx where ....，这样在走索引时就可以直接获取到这些值，不需要回表，这就叫**覆盖索引**。



##### 唯一索引&普通索引

从业务层面来说，假如需要值的唯一性，那么毋庸置疑会选择唯一索引，在两者都合适的情况下，该使用哪一个呢？

查询角度：

唯一索引在查到后会立即返回，普通索引则会找出所有满足的条件，但因为索引是有序的，因此普通索引大概率也能在同一页(64k)查出符合的数据，因此**效率差别不大**。

更新角度：

页在内存（buffer pool）中：

1. 唯一索引会判断页中是否已经存在再更新。
2. 普通索引会直接更新页中的数据，因此两者**效率差距不大**。

页不在内存（buffer pool）中：

1. 唯一索引需要将数据页读到内存，判断唯一性。
2. 普通索引会使用 **change buffer** 记录下对该数据页的修改，等下次读到该页时进行写入，写入过程叫做 **merge** ，注意此时因为内存的数据与磁盘的数据不一样，因此该页也称为**脏页**。



##### 前缀索引

对大文本的数据建立索引是非常耗内存的，效率也很低，因此可以通过**截取一部分长度**来充当索引，这就是前缀索引。

```mysql
ALTER TABLE table_name ADD KEY(column_name(prefix_length));
```

可以参照**索引选择性**判断合适的长度，索引选择性就是不重复的个数与总个数的比值，因此比值越接近1区分度越明显。

缺点：**order by**、**group by**、**覆盖索引**均不能使用前缀索引。



##### 索引下推（ICP）

在MySQL5.6后推出，目的是为了优化非主键索引的查询过程。

```mysql
select * from tuser where name like '张 %' and age=10 and ismale=1;
```

此语句在没有使用ICP前，会先匹配name索引，因为不是覆盖索引，所以会导致回表，所以name是找到了4条记录，都进行了回表。

ICP优化后会同时判断age的值是否符合，最后找到了2条记录，少了2次回表。

![image-20210530224159564](https://raw.githubusercontent.com/jjames567/picture/main/image-20210530224159564.png)



### change buffer

顾名思义，修改的缓冲区，占用的是 **buffer pool** 的内存空间。

因此在针对写多读少的业务上，**change buffer** 所记录的数据越多，性价比就越高。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210531120201226.png" alt="image-20210531120201226" style="zoom: 50%;" />

上图可以看到除了change buffer 记录数据之外，还有 redo log ，那 redo log 是什么呢？

### redo log

想要修改记录是需要把对应的页读取到内存，然后修改内存中的数据，但不可能每次修改后都写回到磁盘，这样是效率很低的，因此在修改完内存后，会把操作记录写入到 redo log 中，而 redo log 是顺序写入的，顺序io效率会高很多。

redo log 也是跟 change buffer 一样，记录着哪一页的数据做了什么修改（注意是所有的修改操作都会记录，包括 change buffer 的修改的记录，可以参照上面的图）。那跟 change buffer 有什么联系呢？

刚刚说了，是先修改内存中的数据，假如是用到了 change buffer ，意味着也是先记录到 change buffer ，再把所有的操作写入到 redo log。所以假如机器突然断电了，change buffer 中的数据会丢失，但是我们还有 redo log 保存着对页的修改操作呢，所以可以直接使用 redo log 重新**持久化**数据到磁盘。

那数据的备份又是怎么做的呢？

### binlog（属于Server层）

注意啊，redo log 是基于 InnoDB（引擎层）做的，而 binlog 是基于**服务层**做的，就是说其他引擎也是用 binlog 进行备份的。

而 binlog 记录的内容是 sql 语句（逻辑修改），不像 redo log 记录的是物理修改，同时 binlog 写入时机是事务提交，而 redo log 是在事务执行过程不断写入。

那 binlog 和 redo log 之间是怎么配合的呢？

![5148507-1a29473c24f0c5b7](https://raw.githubusercontent.com/jjames567/picture/main/5148507-1a29473c24f0c5b7.png)

流程如下：

1. 写入 redo log ，状态置为 **prepare**.......（可能有多条操作）
2. 可以提交事务了
3. 写入 binlog ，成功则把 redo log 状态置为 **commit**，表明事务提交成功。

上面的流程也被称为**二阶段提交**。

那么在断电后该怎么判断上次事务是否能提交呢？

1. 在 binlog 完整的情况下，是直接可以提交的。

2. 在 binlog 不完整的情况下，判断 redo log 状态是否为 **commit** ，若是则进行提交，否则进行**回滚**。

回滚？那回滚又是根据什么呢？

### undo log

在事务的执行的过程中，每一条修改的 sql 执行后都会写一条**相反**的 sql ，比如 insert 语句就对应着 delete  语句，update 新值语句就对应着 update 旧值语句，当事务被提交时会清空 undo log 的内容。

你还记得在 InnoDB 的特性吗，是不是有一个 MVCC 多版本并发控制，里面也用到了 undo log， 下面讲一下它的原理。

### MVCC

先说一个比较常见的问题，A事务在写入操作时，假如B事务也想进行写操作，那么在A事务提交前，B事务肯定是会阻塞的，就相当于给该资源进行了加锁。那假如是A事务在进行读操作时，B事务要进行写操作呢？假如也进行加锁的话，是不是会导致并发度非常低？

我们都知道，InnoDB 有4种隔离级别，想一想其中的 **读已提交** 和 **可重复读** 是不是跟上面的情况有所关联呢？

所以 MVCC 的作用有以下两点：

1. Innodb的MVCC能防止幻读的发生（可重复读）
2. 实现了多个事务并发下，读操作的非阻塞。

先介绍一下一些名词的概念：

**当前读**：为当前资源进行加锁，事务提交前其他事务不能对其进行写操作。

**快照读**：不进行加锁，使用MVCC处理并发问题。

**undo log**：保存当前事务的修改记录、row_id、事务id、回滚指针。**注意这里的row_id在有主键id的情况下是没有的**。

![image-20210531151422009](https://raw.githubusercontent.com/jjames567/picture/main/image-20210531151422009.png)

也就是说当有多个事务在对同一行记录进行修改时，undo log 就会增加一行记录，情况如下：

注意哦，undo log 是有 insert undo log 和 update undo log 的，这里的回滚指针为 null 的就是 insert undo log。

![image-20210531151722668](https://raw.githubusercontent.com/jjames567/picture/main/image-20210531151722668.png)

回滚指针会指向之前的事务记录，并且事务id会一直递增。

**read-view**：保存当前活跃事务id集合、当前活跃事务最小id、当前活跃事务最大id、本事务id

![image-20210531152056380](https://raw.githubusercontent.com/jjames567/picture/main/image-20210531152056380.png)

在了解完上面的概念后，理解起来就很容易了。

实现**可重复读**：

![image-20210531152902139](https://raw.githubusercontent.com/jjames567/picture/main/image-20210531152902139.png)

前提假设：

- 事务 A 开始前，只有一个活跃的事务，ID = 2，
- 已提交的事务也就是插入数据的事务 ID = 1
- 事务 A、B、C 的事务 ID 分别是 3、4、5

从事务A的角度看，在 T5 时，因为是可重复读，所以应该要读到 age = 22。

先把A的 read-view 抽出来，当前活跃事务id有【2,3】，最大事务id为3+1，遍历 undo log，发现 id 为4和5都不符合（因为比当前活跃事务最大 id 都要大，说明事务是后来才创建的），然后找到 id = 1，比当前活跃最小id要小（说明是在当前事务创建前就已经提交了），该版本对事务A可见，因此查到 age = 22。

再从事务B的角度看，拿出事务B的 read-view ，当前活跃事务id有【2,3,4】，最大事务id为4+1，因为查到 id = 4 是自己，因此 age = 24。

实现**读已提交**：

![image-20210531155300877](https://raw.githubusercontent.com/jjames567/picture/main/image-20210531155300877.png)

从事务A的角度来看，拿出 read-view ，当前活跃事务id有【2,3,4】，最大事务id为5+1，查到 id = 4，但因为4在【2,3,4】中，因此不可见，再往上，查到5，也是比最大事务id小，同时不在数组中，因此 age = 23。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210531160229060.png" alt="image-20210531160229060" style="zoom:50%;" />

**（提醒，最大事务id = 创建视图时的最大事务id+1）**

其实可以发现规律：

1. 低水位以下，也就是 id < 最小事务id && 不在活跃事务数组中 ，说明在创建视图前已经提交，直接可见。

2. 高水位以上，也就是 id >= 最大事务id，说明是在事务创建后才提交的，不可见。

3. 两者之间：

   在数组里：再判断是否是自己的事务id，是则可见，否则不可见。（没理由我自己改的我自己还看不见吧。。）

   不在数组里：可见。

咦？那我读已提交，先创建了视图，后面的新来的事务提交的东西我岂不是看不见？？因为它们都在高水位以上啊。

这你就粗心了，请再看一次 **读已提交** 创建视图的时机。

![image-20210531155300877](https://raw.githubusercontent.com/jjames567/picture/main/image-20210531155300877.png)

总之别管这么多，带公式就好，因为代码的逻辑也是这样的嘛。



### 锁机制

上面的 mvcc 是为了实现事务隔离级别为 **读已提交** 和 **可重复读** ，也就是解决了**脏读**、**不可重复读** 的问题。。咦不对呀？**可重复度** 明明也解决 **幻读** 的啊，可重复读的意思是无论读多少次，我所读到的数据是一样的，假如是读一行，那这一行的数据肯定是不会变的，那假如是读多行呢？我来个范围查询，第一次读到2行，第二次读直接返回3行，那岂不是乱套？这时候就需要锁大哥就出场了！

先说一下概念，读锁和读锁之间是不会冲突的，写锁和读锁、写锁和写锁之间是会冲突的。

在mysql中，查询语句可以在末尾加 **lock in share mode** 主动加上读锁，在末尾加  **for update** 主动加上写锁，那么在遇到冲突时，后面来的事务将会 **阻塞**。

#### 锁的种类

1. **next-key lock** ：锁住左开右闭区间，即 (1,5] 。
2. **gap**：间隙锁，锁住左右封闭区间，即 (1,5) 。
3. **行锁**：只锁住一行。
4. **共享锁**：也就是读锁。
5. **排他锁**：也就是写锁。
6. **表锁**：锁住整个表，**InnoDB** 在查询时 **没有走索引** 就会 **锁表** 。
7. **意向锁**：A事务在表table中的一行获取了 排他锁 ，意向锁会帮助A事务同时给table加上**意向排他锁**，此时B事务想获取table的表锁就会阻塞，因此意向锁也是表锁。

先上公式：

1. where中符合条件的先上**next-key lock**。
2. 若是 **唯一索引** ，则优化成 **行锁**。
3. 若向右遍历时发现与条件 **不相等** 时（age < xxx，或者 age <= xxx 时 xxx 不存在），则优化成 **间隙锁**。

#### 等值查询

我们在进行等值查询时，会有两种情况，一种是会出来1行数据（唯一索引），另一种是出来多行数据（普通索引）。下面分别说一下他们的加锁过程。

##### 唯一索引

```mysql
select * from user where id = 5 for update;
```

按照唯一索引的性质，不能添加字段已经存在的值，因此这种情况下直接使用 **行锁** 即可。

##### 普通索引

``` mysql
select * from user where age = '22' lock in share mode;
```

这种情况下可能存在多个age字段值相同的行，为了 **避免幻读**，应该使用 **next-key lock** + **gap** ，即锁住 ( **比22小** 的第一个索引key , 22] 和 (22 ,  **比22大** 的第一个索引key)。**PS**：假设索引key的排列为【20->22->22->25】，就锁 (20,22] 和 (22, 25) 。

有没有留意到为什么上面写的是 **lock in share mode** 而不是 **for update** ？因为锁的 **依据** 其实是 **索引** ，普通索引需要再一次 **回表** 遍历主键索引，因此也会把主键索引所对应的行给锁上！结果就可能不是上面举例那样了。

那假如该值不存在呢？

刚说到 **唯一索引** 用到的是 **行锁** ，但这种情况下只能退化成 **间隙锁** 了，假如 id索引集为【3->4->6->7->8】，这时查 id = 5，就会锁住 (4,6)，假如查 id = 9，就会锁住(8,+∞)，同理，查 id = 2，锁住(-∞,3)。

那普通索引又是怎么样呢？

~~或许需要记一下，假如查age = 21，会锁住左闭右开区间，即[20,22)。~~ 觉得不太合理，以后修正。

#### 范围查询

研究一段时间后决定放弃了，这东西有些不能套公式，会让笔记造成混乱，按实际情况来判断吧。



## Redis

Redis 是以 key - value 的形式存储数据的，数据类型大概有以下这几种：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601205858779.png" alt="image-20210601205858779" style="zoom:50%; margin-left: -10px;" />

但是实际在 redis 中，这些数据类型是以对象的形式存在的。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601205955696.png" alt="image-20210601205955696" style="zoom: 33%; margin-left: -10px;" />

redis 使用一个 redisObject 来存储 key 和 value 的，使用 type 代表数据类型，encoding 代表编码格式，ptr 指向底层数据结构。

同时一种对象类型会有多种编码，那这样会有什么优势呢？

### 数据结构

![image-20210601205549162](https://raw.githubusercontent.com/jjames567/picture/main/image-20210601205549162.png)

#### 数据类型

##### STRING

INT： 当 value 为 long 类型时则使用该编码。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601210817212.png" alt="image-20210601210817212" style="zoom: 50%; margin-left: -10px" /> 

EMBSTR：当 value 长度 <= 44时使用，只需要分配一次内存(空间连续)来创建 redisObject + sdshdr，同时回收内存时也只需要一次，数据不能进行修改，否则会变成RAW。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601211701992.png" alt="image-20210601211701992" style="zoom:50%; margin-left: -10px" />

RAW：当 value 长度 > 44时使用，需要分配两次内存来创建 redisObject 和 sdshdr。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601211957261.png" alt="image-20210601211957261" style="zoom: 50%; margin-left: -10px;" />

sdshdr：简单动态字符串

```c
struct sdshdr{

    // 字节数组，用于保存字符串
    char buf[];

    // 记录buf数组中已使用的字节数量，也是字符串的长度
    int len;

    // 记录buf数组未使用的字节数量
    int free;
}
```

1. **直接获取长度**：对比 c 语言本身获取字符长度需要O(n)，sds只需要 **O(1)** ，即通过 len 属性就能直接获取。

2. **减少内存分配次数**：即内存预分配，分配内存是比较耗时的，因此当sds发现缓冲区(buf)不够时，会分配**多一倍**的空间给buf，假如buf长度开始是4，现在需要9，buf则会扩展到18，同时free从0变成9。注意当字符串 **大于1mb** 时则需要多少分配多少。
3. **惰性空间释放**：free记录的是空余空间，会在后期需要释放时释放。
4. **二进制兼容**：c 语言的字符串遇到空格时会认为是一个新字符串，导致二进制数据不能存储，但sds是可以兼容的。

##### LIST

ZIPLIST：压缩列表，当列表总长度小于64字节，且列表元素少于512个时使用，否则使用双向链表。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601214554508.png" alt="image-20210601214554508" style="zoom:50%; margin-left:-10px" />

LINKEDLIST：双向链表

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601214658856.png" alt="image-20210601214658856" style="zoom:50%; margin-left:-10px" />

分析：双向链表有两个指针，当存的数据很小时，数据甚至没有指针占用内存大，并且压缩列表在内存中的是连续的，有的类似数组，里面的每个元素大小可以不同。

##### HASH

ZIPLIST：压缩列表，当 key 和 value 的长度全部小于46字节，同时元素个数少于512个时使用。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601221121864.png" alt="image-20210601221121864" style="zoom:50%; margin-left:-10px" />

HASHTABLE：使用了 dict 字典结构实现

dict 字典中有两个哈希表，ht[0] 和 ht[1]，前者存 **真实数据** ，后者用于 **扩容** 。

```c
typedef struct dict {

    //类型特定函数
    dictType *type;

    //私有数据
    void *privdata;

    //哈希表
    dictht ht[2];

    //rehash索引
    //当rehash不进行时，值为-1
    int rehashidx;  

}dict;
```

哈希表结构：

```c
    typedef struct dictht{

        //哈希表数组
        dictEntry **table;  

        //哈希表大小
        unsigned long size;    

        //哈希表大小掩码，用于计算索引值
        //总是等于size-1
        unsigned long sizemark;     

        //哈希表已有节点数量
        unsigned long used;

    }dictht
```

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601221627155.png" alt="image-20210601221627155" style="zoom:50%; margin-left:-10px" />

跟 Java 一样，有一个 dictEntry 数组，专门存 key-value 数据，当遇到 **哈希冲突** 时，采用 **头插法** 。

dictEntry 结构：

```c
    typedef struct dictEntry {

        //键
        void *key;

        //值
        union {
            void *value;
            uint64_tu64;
            int64_ts64;
        }v;    

        //指向下个哈希节点，组成链表
        struct dictEntry *next;

    }dictEntry;
```

rehash ：采用 **渐进式** 方式来完成

1. 进行rehash时，设置 dist 对象的 rehashidx 为0。
2. 以 rehashidx 为下标，把 ht[0] 的 dictEntry 对象移动到 ht[1] ，然后rehashidx++。
3. 在此期间，查询操作会先查 ht[0] ，找不到再查 ht[1]，新增操作一律保存到 ht[1] 。
4. rehash 完成后把 rehashidx 设置为 -1。

##### SET

INTSET：保存的元素都是整数，且总数量少于512个。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601223351654.png" alt="image-20210601223351654" style="zoom:50%; margin-left:-10px" />

HASHTABLE：跟上面的 HASH 一样，只是 dictEntry 的 value 为 null，就不上图了。

##### ZSET

ZIPLIST：元素长度小于64，且总数量少于128时使用。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601230622836.png" alt="image-20210601230622836" style="zoom:50%; margin-left:-10px" />

SKIPLIST：跳跃表，插入时间复杂度为 O(logn)，查找时间复杂度为 O(1) 。典型的空间换时间。

![image-20210601230831031](https://raw.githubusercontent.com/jjames567/picture/main/image-20210601230831031.png)

##### BITMAP

也称作位图，使用二进制数组实现，

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210603201824525.png" alt="image-20210603201824525" style="zoom: 33%; margin-left: -10px;" />

假如我们要记录用户是否有登录，就可以使用用户id作为 key ，数组下标作为天数，置1代表已经登录，类似下面这样：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210603203607133.png" alt="image-20210603203607133" style="zoom:50%; margin-left:-10px" />

除了能获取用户当天是否有登录，还能统计用户在一定范围内为1的个数，统计登录次数。

##### HyperLogLog

基数统计，可以用于统计UV，即同一个用户访问多次，仍然被记作一次访问。

同时还能合并不同的 key ，对数据进行去重，比如统计这两天的访问用户。

```ini
> pfadd user mango
(integer) 1
> pfadd user zhangsan
(integer) 1
> pfadd user lisi
(integer) 1
> pfadd user mango     #重复则不计数
(integer) 0
> pfcount user
(integer) 3

> pfadd paper mango
(integer) 1
> pfadd paper zhangsan
(integer) 1
> pfmerge uv user paper    #合并
OK
> pfcount uv
(integer) 3
```



### 	过期策略

我们可以通过 **expire key ttl** 来设置一个 key 的过期时间为 ttl 秒。

那 redis 是怎么存过期时间的呢？

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210601233243548.png" alt="image-20210601233243548" style="zoom: 33%; margin-left: -10px" />

可以看到在 redisDb 对象中有一个 expires 属性，里面存了所有 key 对应的 过期时间。

注意，这里 redisDb中的 dict 并不是 HASH 的字典，而是 redisDb 中的 dict，结构如下：

``` c
typedef struct redisDb {
    // ...
    
    // 数据库键空间，保存着数据库中的所有键值对
    dict *dict;
    
    // ...
} redisDb;
```

那对于过期的键，redis 是怎么删除的呢？

**惰性删除**：每次取 key 的时候判断是否过期，是则删除。

**定期删除**：每隔一段时间去删除过期的键。

如果 redis 内存快耗尽了，上面两种方法都不管用的情况下，就要使用**内存淘汰机制**。

- noeviction：新写入操作会报错。
- allkeys-lru：移除最近最少使用的key（这个是最常用的）
- allkeys-random：在键空间中，随机移除某个key。
- volatile-lru：在设置了过期时间的键空间中，移除最近最少使用的key。
- volatile-random：在设置了过期时间的键空间中，随机移除某个key
- volatile-ttl：在设置了过期时间的键空间中，有更早过期时间的key优先移除。

### 事务

redis 单条命令保证原子性，但整个事务不保证原子性。

1. multi 开启事务
2. 一系列命令
3. exec 执行队列里的命令 / discard 取消事务

redis **没有隔离级别** 的概念，因为事务中的命令并不会执行，只有exec时才会一次性按序执行。

redis **能检测到命令的错误**，但 **不能保证运行时不会遇到错误** ，事务中遇到错误的操作会 **执行失败** ，其他则运行成功，因此事务 **没有回滚机制** 。

**watch** 命令：可以监视一个 key 是否被修改。类似乐观锁，在事务提交时假如发现该 key 被修改了，事务队列将 **不会执行** 。



### 持久化策略

##### RDB

将内存中的数据以快照的方式写入到 **二进制** 文件中，文件名默认为 **dump.rdb** 。

redis 有4种方式触发 rdb 保存：

1. **SAVE命令**：**阻塞**当前 redis 进程，直到数据写入完成。

2. **BGSAVE**：通过fork()创建一个子进程来将数据写入 RDB 文件。(注意在fork时是**阻塞的**)

   默认触发条件：

   ```ini
   save 900 1       #在900秒(15分钟)之后，至少有1个key发生变化
   save 300 10      #在300秒(5分钟)之后，至少有10个key发生变化
   save 60 10000    #在60秒(1分钟)之后，至少有10000个key发生变化
   ```

3. 执行 **flushall** 命令。
4. 客户端进行 **shutdown** 。

为什么是创建子进程而不是线程？

主要是出于 Redis 性能的考虑，我们知道 Redis 对客户端响应请求的工作模型是单进程和单线程的，如果在主进程内启动一个线程，这样会造成对数据的 **竞争条件** 。所以为了避免使用锁降低性能，Redis 选择启动新的子进程。

**持久化流程**：

​	子进程与父进程 **共享同一块内存**，同时把这块内存设置为 **只读**，子进程负责把这块内存的数据保存到 dump.rdb 中，**这时候假如进行了新的写入数据**，就会触发 **copy-on-write** 策略，会对原来的数据复制一份，对这个 **副本** 进行修改，因此持久化后的 RDB 文件所保存的数据是 **fork那一刻** 的数据。所以说，写时复制机制在读多写少的情况下是可以避免用到2倍内存空间的，因为只要不产生写操作，就不会复制副本，也避免了内存溢出。

优点：

1. 全量备份，适合大规模数据恢复。
2. 恢复速度比 AOF 要快。

缺点：

1. 可能会丢失一次备份后的所有修改。
2. 可能会因为fork()的执行导致redis阻塞。

##### AOF

以日志的形式记录每个**写操作**，并且是 **追加写**，没有 **随机磁盘io** 那样的开销。

因为 redis 是基于内存的，因此重启会根据日志文件将写指令从头到尾执行一次来恢复数据。当 AOF 文件有错误时，会启动失败，不过可以尝试使用 **redis-check-aof --fix appendonly.aof** 来修复 AOF 文件。

假如不小心 **flushall** 了，也可以手动删除 aof 的最后的清空命令重启来恢复数据。

**持久化流程**：

1. 把写命令写入 aof_buf 缓冲区。

2. 调用 flushAppendOnlyFile 函数，判断是否将缓冲区数据写入 AOF 文件。

   ```ini
   appendfsync always     # 每次有数据修改发生时都会写入AOF文件。
   appendfsync everysec   # 每秒钟同步一次，该策略为AOF的默认策略。
   appendfsync no         # 从不同步。高效但是数据不会被持久化。
   ```

3. 根据上面的设置，符合则写入到文件中。

**AOF重写**：

相关配置部分：

```ini
auto-aof-rewrite-percentage 100 # 在当前aof文件的体积超过上次aof文件的体积的100%时，写新文件
auto-aof-rewrite-min-size 64mb # 最开始的aof文件体积至少达到60M时才重写
```

重写的意义在于，同一个key的覆盖操作，假如把所有的指令都保存下来，会十分浪费内存，重写可以使得key**只保留最新的那一次操作**。当符合上面的条件时，就会触发重写策略，节省内存。

**AOF后台重写**：

跟 rdb 类似，会执行 **BGWRITEAOF** 命令来创建一个子进程来完成重写 AOF 操作。

此时假如执行了写操作，可能会导致AOF和数据库 **数据不一致** 的问题。因此在创建子进程后，会创建一个 **AOF 重写缓冲区** 来保存这个过程的写入操作。等到子进程备份完成后，会通知父进程将 **AOF 重写缓冲区** 的数据写到 **新的AOF文件中**。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210602225134835.png" alt="image-20210602225134835" style="zoom:50%;" />

针对于过期键，持久化又会有怎样的策略呢？

RDB：

1. 执行 SAVE 或者 BGSAVE 时会对过期键进行检查，已过期的键不会保留在 RDB 文件中。
2. 在载入 RDB 文件时，也会检查，过期的键会直接忽略。

AOF：

1. 对于 **已经过期** 的键且该键没有被 **惰性或者定期删除** 时，写入 AOF 文件时没有任何影响，当删除之后，会追加一条 **DEL** 记录该键被删除。
2. 重写 AOF 文件时，会检查过期键，已过期的键不会被写入。

##### 使用建议

两者并不互斥，可以同时使用。

RDB 文件体积小，恢复数据快，但可能会丢失最后一次未持久化的数据。

AOF 文件体积大，恢复数据慢，默认只会丢失一秒的数据。

在同时开启两者持久化时，会优先使用 AOF 文件来恢复数据。



### 主从复制

一台服务器内存有限，并且能接受的并发量也是有限的，因此可以通过其他服务器来分担压力。

由 **主服务器** 来负责 **写请求** ，**从服务器** 来负责 **读请求** 。

那该怎么保证主从服务器的数据一致呢？

#### 全量复制

1. 从服务器发送 **SYNC** 命令。
2. 主服务器收到命令后执行 **BGSAVE** 命令生成 RDB 文件，同时创建缓冲区记录之后的写记录。
3. 生成 RDB 文件完成后，向从服务器发送 RDB 文件。
4. 从服务器丢弃旧数据，载入 RDB 文件。
5. 主服务器向从服务器发送缓冲区中的写记录。
6. 从服务器接收写命令并执行。

#### 增量复制

在经过全量复制之后，主服务器又进行了写操作，导致主从数据不一致，这时通过 **命令传播** (**command propagate**) 将主服务器的写命令发送给从服务器。

但是，假如从服务器不小心断线了，一部分数据需要重新同步，但是在 Redis2.8 以前，从服务器是需要发送 SYNC 命令来进行全量复制的，显然十分低效。

因此在之后的版本中使用 **PSYNC** 代替 SYNC 命令，同时增加了 **复制积压缓冲区** 。

**PSYNC <runid> <offset>**  代表 <主服务器id> <从服务器复制偏移量>

- 在全量复制部分，PSYNC 和 SYNC 区别不大。在进行全量复制之后，主从服务器就会进入 **命令传播阶段** 。
- 主从服务器会有自己的 **复制偏移量** ，主服务器发送N个字节时，就会在复制偏移量上也加上N，从服务器也一样。
- 主服务器在发送写指令给从服务器时，会在 **复制积压缓冲区** 也写一份数据。
- 当发现偏移量不一致时，会从 **复制积压缓冲区** 找到对应偏移量的写操作，发送给从服务器。
- 从服务器会每秒发送自己的偏移量给主服务器（检测网络状态、检测数据不一致）。
- 若 run id 与主服务器不一致时，会进行 **全量复制** 。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210603003122032.png" alt="image-20210603003122032" style="zoom: 33%; margin-left: -10px;" />

**引入个 发布订阅模式 小插曲，便于后面的知识**

发布订阅模式可以看这篇文章：https://zhuanlan.zhihu.com/p/353505620

其实模式就是用来匹配频道的，比如 student.1 频道，我可以订阅 student.* 模式，就能同时涵盖多个频道。它的底层实际上是一个字典，即一个频道对应一个链表，存的是已经订阅了该频道的客户端。订阅模式也是一个链表，节点存的是客户端和模式。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210625164552679.png" alt="image-20210625164552679" style="zoom:33%; margin-left:-5px" />

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210625164621464.png" alt="image-20210625164621464" style="zoom:33%; margin-left:-5px" />

### 主备切换

从服务器是用来分担主服务器的读操作的，保证了主服务器的 **可用性** 。但假如很不幸地，主服务器还是挂了，那就需要主备切换来保证 redis 服务的 **健壮性**。

redis 提供了 **哨兵模式** 来处理上面的情况。

Sentinel 本身也是一个 redis 服务器，但是它不具备主从服务器的功能，它的功能是 **监视** 服务器的状态。

流程是这样的：

1. 配置需要监听的主服务器，初始化 Sentinel。
2. 发送 **INFO** 命令向主服务器获取 主服务器 和 从服务器 的信息（从服务器ID，从服务器与主服务器的连接状态，从服务器的优先级，从服务器的复制偏移）。
5. 之后会 **每10秒** 发送一次 **INFO** 命令来更新信息。
4. 订阅 **sentinel_:hello 频道**，与其他 Sentinel 保持通信。

**主观下线**：

​	Sentinel 每秒向与它建立连接的服务器发送 **PING** 命令，通过返回判断是否在线，假如 **主服务器** 在 **down-after-milliseconds** 无响应，则当前 Sentinel 主观认为该 主服务器 已经下线。

**客观下线**：

​	在 Sentinel 认定一个服务器已经下线后，会询问 **其他** 监视该服务器的 **Sentinel** ，看它们是否也认为已经下线，若有 **足够多** 的 Sentinel 认为该服务器已经下线，则会升级为 **客观下线** ，那此时就会执行 **故障转移** 。注意：客观下线后，向从服务器发送 **INFO** 命令会从每10秒变为 **每秒** ，时刻保证从服务器的状态。

为什么会有客观下线？

主管下线有可能是因为 **网络阻塞** 导致的响应超时，当有 **N** 个哨兵时，最好有 **N/2 +1** 个实例判断为 **主观下线** ，最最终认定为 **客观下线**。

**故障转移**：

先选举出一个 Sentinel ，对下线的主服务器进行故障转移。

会 **挑选** 从服务器升级为主服务器，当主服务器重新上线时，会直接成为从服务器。

**挑选策略**：

1. 根据配置的优先级。
2. 偏移量较大的，也就是同步数据最多的。
3. 若上面都相同，则选择 id 号最小的。

那故障转移时，redis 还能提供服务吗？

读操作是可以的，但写操作会请求失败，失败的持续时间 = **哨兵切换主从的时间 + 客户端感知到新主库**。对于返回值不敏感的场景，可以选择使用 **消息中间件** ，在写入异常时把写操作保存下来，等到故障转移完成之后进行消费，执行写操作。

那客户端是怎么感知新的主服务器的呢？

从上面的流程可以看出，Sentinel 经出现一个关键词 **订阅** ，其实这也是 redis 的一个功能 **pub/sub 发布订阅模式**。

Sentinel 通常是以集群来部署的，但在配置文件里并没有配置其他 Sentinel 实例的消息，Sentinel 在跟主服务器发送 INFO 获取服务器信息时，主服务器通过订阅相关频道，Sentinel 就能把自己的 ip 发送到主服务器，那么一来一回，Sentinel 实例之间就能知道相互的地址了。

回归到刚刚的问题，**客户端** 也可以通过 **订阅** 相关频道，Sentinel 在完成故障转移之后会在这个频道发送最新的主服务器ip，那么客户端就可以进行写操作了。

到此为止，**主从架构** + **哨兵集群** 已经达到了高可用了，但 redis 还是会出现数据丢失的情况的。

**异步复制**：主服务器在持久化数据的时候挂了，这时候数据还没同步到从服务器。

**脑裂**：哨兵们认为主服务器挂了，但实际上活着，这时候从服务器升级成主服务器，但还没发布消息通知客户端，于是客户端把写操作请求发到之前的主服务器上，此时重新感知到主服务器上线，但立即成为从服务器全量复制新主服务器的数据，那这个过程的写操作就丢失了。

### 集群

上面提到 **主从架构** + **哨兵集群** 已经达到了高可用了，但细心的小伙伴会注意到哨兵进行故障转移的时候会造成短时间的写请求不可用，那有没有办法解决这个问题呢？

主服务器崩了的原因肯定是因为 **写请求太多了** ，我们可以把主服务器也搞个 **集群** 呀，可以 **分摊一下写的压力** ，同时也可以 **分摊数据的占用内存** ，因为主节点内存设置过大会导致 **同步数据很慢** ，搞集群后效率可用性也大大增加了。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210603234049201.png" alt="image-20210603234049201" style="zoom: 33%; margin-left:-10px" />

redis 会把数据划分为 **16384** 个槽位slot，相当于把内存数据分片到各个主节点。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210604001306507.png" alt="image-20210604001306507" style="zoom:33%; margin-left:-10px" />

当客户端想查找某个 key 时，会对 key 进行 hash 得到整数值，而这个整数值就对应着槽位。

**HASH_SLOT = CRC16(key) % 16384** 

客户端在请求数据时，当前槽位可能不是该数据的槽位，因此会进行一次重定位。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210604001501497.png" alt="image-20210604001501497" style="zoom: 50%;margin-left:-10px" />

有没有发现上面的 redis 集群并没有 Sentinel 的身影，原因是 redis 集群会自己进行选举，

当某个节点失联时间超过 **cluster-­node-­timeout** 时，就会执行故障转移：

1. 多个从节点发现 master 状态变为 fail，便开始竞争成为主节点。
2. 从节点给其余的主节点发送信息。
3. 主节点给最先发给自己的从节点回复 ACK。
4. 收到 ACK **超过半数** 的从节点选举成功。（这也是为什么集群主节点至少为3个的原因，且最好为奇数）

假如其中一个主节点和它的从节点都挂了，那 redis 还能提供服务吗？

可以通过设置 **cluster-require-full-coverage** ，YES 则表示不可用，NO 表示仍然可用。



### 缓存穿透

通常情况下查询数据会先走缓存，假如查找不到则查数据库，数据库会把数据写入缓存，之后的查询就会走缓存，减少io操作。但假如从数据库查不到数据，则无法写入缓存，这样就问题大了啊？那一直请求这个不存在的 key ，就会一直请求数据库，并发量大的情况下，自然就崩了。

**解决方案**：

1. 利用 BITMAP 实现 **布隆过滤器** ，先对数据库中的数据 key 经过 **多次哈希** 写入到二进制数组中，当请求过来时，对这个 key 也进行多次哈希，假如发现二进制数组中有存在0的情况，则说明这个数据一定不存在，因此直接可以在控制层进行拦截。
2. **缓存空数据**，即使从数据库查询为空，也进行缓存，但过期时间可以设置短一点。

### 缓存击穿

缓存通常都会有过期时间，虽然缓存过期了，查数据库又会写入缓存，但在过期的那一刻假如并发量很大，多个线程会同时查数据库，也是会导致宕机的。

**解决方案**：

1. 设置 key 永不过期，有点治标不治本。
2. 设置互斥锁，比如利用 setnx ，设置成功则查数据库并设置到缓存， setnx 失败的线程则 sleep 一段时间再尝试查缓存。

### 缓存雪崩

缓存中多个 key 在 **同一时刻** 过期，这时候多这些 key 的并发量很大，就会有宕机的风险。

**解决方案**：

1. 使 redis 高可用，即 **主从复制 + 哨兵集群** 。
2. **设置互斥锁** ，参照缓存击穿的第二种方案，但会导致用户体验差，因此获取不到锁时可以进行服务降级。
3. **服务预热** ，在并发来之前先把数据存到缓存。（没缓存的情况下的并发跟雪崩没区别）

### 限流

限流主要作用是为服务器减轻压力，防止并发量过大，一般有以下措施：

1. **固定窗口计数器算法**：将时间划分为多个窗口，每个窗口内有一次请求计数器+1，超过限制则丢弃请求。但这种算法会有 **双倍流量** 的风险。
2. **滑动窗口计数器算法**：也是将时间划分为多个窗口，当有第一个请求过来时开始占据多个时间区间，这样动态性就更强，不会有上面的隐患。
3. **漏桶算法**：将每个请求视作"水滴"放入"漏桶"进行存储，“漏桶"以固定速率向外"漏"出请求来执行如果"漏桶"空了则停止"漏水”，如果"漏桶"满了则多余的"水滴"会被直接丢弃。通常使用 **队列** 实现，但这样会导致请求先到队列中，再被消费，**有一定的延迟**，同时队列能够把请求保存下来，可以等待一段时间再处理请求，可以采取不丢弃请求。
4. **令牌桶算法**：令牌以固定速率生成，生成的令牌放入令牌桶中存放，如果令牌桶满了则多余的令牌会直接丢弃，当请求到达时，会尝试从令牌桶中取令牌，取到了令牌的请求可以执行，如果桶空了，那么尝试取令牌的请求会被直接丢弃。

这边主要实现的是令牌桶算法，思路是这样的：

与其针对服务器限流，不如说针对 api 限流，即针对 url 限流，这跟 redis 有什么关联呢？我们是不是可以为 **每个 url 生成一个令牌桶**，当请求过来时，根据 **url** 作为 **key** 来获取令牌桶信息，再判断是否能获取令牌。

令牌桶信息：(总令牌数, 当前令牌数, 生成速率, 上次获取令牌时间戳)。使用 redis 中的 **哈希表** 进行保存。

分析下为什么需要存上面这些，首先令牌的生成速率是固定的，因此我们需要计算一个时间段内生成了多少令牌，即令牌数 = ((now() - 上次获取令牌时间戳) * 速率) 。这样就很简单了，每次获取令牌时，都把上次获取令牌的时间戳更新，这样数据就正确了。同时用 redis 实现还是分布式的，扩展性很强。

### 秒杀

因为 redis 是单线程的，因此不会出现线程安全的情况，可以利用这点来实现扣减库存。

把需要秒杀的商品预先查数据库，把库存写进 redis 中。

开始秒杀时，利用脚本保证原子性，先查询库存，满足则扣减并返回库存数，随后封装用户和商品信息，发送到 MQ ，返回抢购成功。

那怎么保证该商品在抢购时间内呢？

我感觉直接在网关层调用 redis 的 time 命令直接就能判断出来了吧，毕竟抢购时间都是固定的。

### 提醒

用户预约了一件抢购商品，怎么实现提醒功能呢？

先获取商品信息，包括商品id和抢购时间。

基于zset可以进行分数范围获取，因此我们可以把时间作为分数，获取该时间区间的用户。

当用户预约时，利用抢购时间年月日作为 key ，时分作为 score，然后 value 为 用户id 和 商品id。

利用定时任务，提前十分钟获取十分钟后的 score 区间（可能会出现误差，因此得加点容错），利用当天计算年月日key，再调用 rangeByScore 获取到对应的用户和商品id，最后发送到 MQ 进行处理。





## JVM

JVM 是运行在操作系统上的软件，可以在不同系统上运行经过编译后的 class 二进制文件。

那编译完成后做了些什么呢？

### 类加载器

为了执行 class 文件，会由类加载器先对文件进行处理。

1. **加载**：把class文件加载到 **内存** ，将静态数据结构转化成方法区数据的访问入口。
2. **链接**：进行安全检查，为 **静态变量** 分配内存并 **设置默认值** ，把符号引用转化为 **直接引用** 。注意：转化为直接引用的只限于编译时可见的，比如类中的方法，全局对象等。**此过程也叫静态解析**。
3. **初始化**：先为 **静态变量** 进行 **赋值** ，再执行静态代码块的代码。
4. **卸载**： 类的回收会提到（注意类和对象的区别）

类加载器类型：

1.  BootStrap ClassLoader：rt.jar
2.  Extension ClassLoader: 加载扩展的jar包
3.  App ClassLoader：指定的classpath下面的jar包
4.  Custom ClassLoader：自定义的类加载器

当一个类被加载时，是会先委派给父类去加载，因此最终会委派到 BootStrap 类加载器，假如父类 **找不到** 该类，才会给子类去加载。这就是所谓的 **双亲委派机制** 。

这样做能够避免我们创建一个与 jdk 冲突的类，假如创建了 String.java ，去执行某些方法，此文件编译后会先由 BootStrap 加载器去加载，而在 rt.jar 中也有 String.class ，但是发现加载到的 String 中并没有该方法，因此就会报错。

Tomcat 如何破坏双亲委派？

要解决的问题：

1. 要部署多个应用，不同应用可能依赖第三方类库的不同版本，因此要保证每个应用程序之间相互隔离。

   默认情况下，按双亲委派机制，只要全限定名一样，肯定只有一个结果，因此无法满足。

2. 不同应用之间共享同一个 jdk 的核心 jar 包。

   默认情况下，双亲委派机制能满足，因为核心 jar 包会优先加载。

3. tomcat 的 lib 目录下应该与程序的类库隔离，保证安全性。

   与第一个问题一样，需要产生隔离作用。

解决方法：

当tomcat启动时，会创建几种类加载器：

1. **Bootstrap 引导类加载器**：加载 JVM 启动所需的类(rt.jar)，以及标准扩展类（位于jre/lib/ext下）

2. **System 系统类加载器**：加载tomcat启动的类，比如 bootstrap.jar，通常在 catalina.bat 或者 catalina.sh 中指定。位于`CATALINA_HOME/bin`下

   <img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210807212850226.png" alt="image-20210807212850226" style="zoom:33%; margin-left:-5px" />

3. **WebApp 应用类加载器**：每个应用在部署后，都会创建一个唯一的类加载器。该类加载器会加载位于 `WEB-INF/lib`和 `WEB-INF/classes`下的文件。
4. **Common 通用类加载器**：加载tomcat使用以及应用通用的一些类，位于`CATALINA_HOME/lib`下，比如servlet-api.jar

默认情况下就是一个递归调用，不断递归给父级加载器，直至为 null (代表是 Bootstrap 类加载器)，判断 Bootstrap 类加载器 是否已经加载过了，没有的话自己尝试去加载，加载失败则返回 null ，由子级继续尝试加载。。。

```java
public abstract class ClassLoader {

    //每个类加载器都有个父加载器
    private final ClassLoader parent;
    
    public Class<?> loadClass(String name) {
  
        //查找一下这个类是不是已经加载过了
        Class<?> c = findLoadedClass(name);
        
        //如果没有加载过
        if( c == null ){
          //先委托给父加载器去加载，注意这是个递归调用
          if (parent != null) {
              c = parent.loadClass(name);
          }else {
              // 如果父加载器为空，查找Bootstrap加载器是不是加载过了
              c = findBootstrapClassOrNull(name);
          }
        }
        // 如果父加载器没加载成功，调用自己的findClass去加载
        if (c == null) {
            c = findClass(name);
        }
        
        return c；
    }
    
    protected Class<?> findClass(String name){
       //1. 根据传入的类名name，到在特定目录下去寻找类文件，把.class文件读入内存
          ...
          
       //2. 调用defineClass将字节数组转成Class对象
       return defineClass(buf, off, len)；
    }
    
    // 将字节码数组解析成一个Class对象，用native方法实现
    protected final Class<?> defineClass(byte[] b, int off, int len){
       ...
    }
}

```

有两个比较重要的方法：

1. findClass：在规定目录下寻找class文件。
2. loadClass：涉及到类加载器加载的顺序。

Tomcat 的 loadClass 是这样做的：

1. 本地 Cache 查找是否加载过。
2. 没加载成功则扔给 ExtClassLoader 去加载，这时该加载器会扔给 Bootstrap 去加载，因此会把 jdk 自带的类给加载进来。
3. 没加载成功则使用 WebApp 类加载器加载自己应用程序下的 WEB-INF/lib 和 WEB-INF/classes 目录下的类，失败则会委托 Share ClassLoader 去加载不同应用程序之间共用的类，无非就是加载共享目录，这样做可以节省资源。
4. 还失败则委托 Common 类加载器去加载，还会委托 Catalina ClassLoader 去加载 tomcat 自身的类。最后则抛出 ClassNotFind。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210807220929751.png" alt="image-20210807220929751" style="zoom:33%; margin-left:-5px" />

另外，类加载器有一个规范就是假如这个类是由A类加载器来加载的，那这个类的依赖肯定也是由A类加载器来加载，但 java.sql 下有 DriverManager 类，但真正调用 getConnection 方法时得到的是厂商的实现，这是因为 DriverManager 在初始化时得到 **线程上下文** 类加载器，而实际上就是 App ClassLoader，因此可以找到对应添加进来的厂商实现类，所以 JDBC 有着是否破坏双亲委派的争议，实际上是没有的。





### JIT 编译器

经过编译后的二进制字节码，是利用 **解释器** 来执行的，但是解释运行效率其实是不高的，因此引入了即时编译器JIT。

class 文件在经过解释后，会把其发给 JIT ，JIT 会把字节码编译成机器码，并且保存起来，那么再下次执行时效率就非常高了。因此 Java 也叫做 **半解释半编译** 语言。注意：JVM 发现某方法或者某代码块运行得 **特别频繁** 时才会对其进行编译。

**下面的优化都是在编译器进行的。**

#### 逃逸分析

你是不是以为对象实例都是存在堆中呢？其实不然，我们在运行方法时，在方法中新建了一个对象，执行完方法后这个对象就不再使用了，于是就由 GC 来回收。仔细一想，这个对象完全可以在运行完方法之后直接回收呀，于是就有了 **逃逸分析** 。基于逃逸分析，有了下面的优化手段。

##### 栈上分配

通过判断方法中的对象不会通过 return 返回出去，即不会被外部访问，这个对象就可以随出栈而销毁，减少堆内存的占用和 GC 的负担。

##### 标量替换

同样经过逃逸分析，发现对象只在栈内使用，会把该对象的属性进行 **拆分** ，在栈上分配这些属性所需空间，因此也不需要一次性 **分配连续的空间** 给该对象了。

##### 锁消除

通过扫描去除不存在竞争的锁。

```java
public static String createStringBuffer(String str1, String str2) {
    StringBuffer sBuf = new StringBuffer();
    sBuf.append(str1);// append方法是同步操作
    sBuf.append(str2);
    return sBuf.toString();
}
```

这里的 StringBuffer 中的 append 是同步方法，但每个实例对象都在方法中创建，因此多个线程调用这个方法时就不存在锁竞争，因此编译器会将锁消除。

##### 锁粗化

下面每次循环都要进行加锁，而加解锁会影响一定的性能。

```java
for(int i=0;i<size;i++){
    synchronized(lock){
    }
}
```

经过优化后的代码

```java
synchronized(lock){
    for(int i=0;i<size;i++){
    }
}
```



### 常量池的区分

在学习 JVM 之前，得先搞懂每个常量池的作用，不然容易混乱。

#### 字符常量池

在 1.7 前位于方法区，1.7 后转移到了堆中。其实就是存字符串 (String) 的缓存池，下面讲堆会详细测试提到。

#### 运行时常量池

位于方法区中，当类加载完成后，类的元信息会保存到运行时常量池中。

#### 静态常量池

是最容易被忽略的，与运行时常量池相比，运行时常量池就像是一个 **全局池** ，但静态常量池是 **保存在 class 字节码文件中的** ，存放着需要用到的各种 **字面量** 和 **符号引用** 。下面直接上例子！！！

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606154915784.png" alt="image-20210606154915784" style="zoom:50%; margin-left:-10px" />

上面这样一段代码，引用了不少类，那该怎么才能找到这些类的信息呢？

查看该类生成的 class 字节码文件中的静态常量池：

HashMap 类的 **符号引用**

![image-20210606155123672](https://raw.githubusercontent.com/jjames567/picture/main/image-20210606155123672.png)

Map 接口中 **方法** 的 **符号引用** ，因为对象类型是 Map 接口。

![image-20210606155408765](https://raw.githubusercontent.com/jjames567/picture/main/image-20210606155408765.png)

在经过类的加载后，会将这些信息转化到 **运行时常量池**，那么其他类就可以通过其来访问该类的信息。**注意：静态常量池会在栈帧中的动态链接产生作用。**



### 内存区域（运行时数据区）

#### 方法区

我们都知道，方法区是一种规范，存储着各种元信息，在 1.8 之前，方法区的实现叫做 **永久代** ，虽然永久代和堆是隔离的，但永久代和堆的 **物理内存是连续的** ，当永久代的数据超过设置值，就会造成内存溢出。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210605135546698.png" alt="image-20210605135546698" style="zoom:33%; margin-left:-10px" />

在 1.8 后把方法区的实现改成了 **元空间** ，**防止动态生成过多的类导致OOM**，其使用占用的不再是 JVM 进程的内存，而是机器的物理内存，因此就能加载到更多的类信息了。

此时的元空间只剩下类的 **运行时常量池** ，而 **静态变量** 和 **字符串常量池** 是在 **堆** 中。

注意：在 **1.7** 的时候其实已经把 **字符串常量池** 转移到了堆中。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210605135615240.png" alt="image-20210605135615240" style="zoom:33%; margin-left:-10px" />

#### 栈

栈的结构如下：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606002909885.png" alt="image-20210606002909885" style="zoom: 33%; margin-left: -10px;" />

##### 局部变量表

用于存放方法参数和方法内部所定义的局部变量，它的容量是 **以Slot为最小单位** ，一个slot可以存放 **32位以内的数据类型** 。**除了long、double占据两个slot以外，其它的占用一个slot槽** 。虚拟机通过 **索引定位** 的方式使用局部变量表，范围为 [0,局部变量表的slot的数量] 。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606132646439.png" alt="image-20210606132646439" style="zoom:33%; margin-left:-10px" />

为了节省栈帧的空间，这些 slot **是可以复用的**，当方法的执行位置超过了某个变量，这个变量的 slot 就可以被其他变量复用。与此同时，slot 的复用也影响了垃圾回收的行为。比如看下面的代码：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606134930474.png" alt="image-20210606134930474" style="zoom: 33%; margin-left:-10px" />

能看到 bytes 变量并没有被垃圾回收，因为该变量 **还在作用域内** ，那我们稍微把代码改一下。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606135039251.png" alt="image-20210606135039251" style="zoom:33%; margin-left:-10px" />

可以看到即使加了代码块使得 byte 变量超出作用域，但仍未被回收，我们再尝试改一下代码。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606135217992.png" alt="image-20210606135217992" style="zoom:33%; margin-left:-10px" />

可以看到垃圾回收器把 bytes 变量回收了，原因是 **a 变量复用了 bytes 的 slot** ，使得 bytes 变量失去了 GC ROOTS 的关联。

还需要注意一点，非静态方法是可以引用 this 对象的，原因是因为默认会在索引为0的 slot 上添加 this 对象，因此在方法中能引用。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606135725524.png" alt="image-20210606135725524" style="zoom: 50%; margin-left:-10px" />

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606135713017.png" alt="image-20210606135713017" style="zoom: 33%; margin-left:-10px" />

##### 操作数栈

当一个方法刚开始执行时，其操作数栈是空的，随着方法执行和字节码指令的执行，会从局部变量表或对象实例的字段中复制常量或变量写入到操作数栈，再随着计算的进行将栈中元素 **出栈到局部变量表(也就是赋值给变量)** 或者 **返回给方法调用者(返回该值)** ，也就是出栈/入栈操作。一个完整的方法执行期间往往包含多个这样出栈/入栈的过程。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606142616225.png" alt="image-20210606142616225" style="zoom: 50%; margin-left:-10px" />

对应的操作栈如下：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606142659332.png" alt="image-20210606142659332" style="zoom:50%; margin-left:-10px" />

1. 将 0 压入栈，出栈到局部变量表索引 slot 为 1 的位置，即赋值给 a 。
2. 将 1 压入栈，出栈到局部变量表索引 slot 为 2 的位置，即赋值给 b 。
3. 将局部变量表中索引为1的 slot 压入栈顶。
4. 将局部变量表中索引为2的 slot 压入栈顶。
5. 从栈顶弹出 2个进行加法运算。
6. 将相加结果出栈到 局部变量表索引 slot 为 3 的位置，即赋值给 c。
7. 从局部变量表读取索引为 3 的 slot ，返回方法结果。

**还有很多指令暂时不想研究，就先意思意思吧。**

##### 动态链接

把栈帧中的符号引用转化为直接引用。有没有觉得似曾相识？是不是跟 **类加载中的链接** 很相似？这里注意是要针对 **栈帧** ，比如我方法入参中有 Map 接口，但是实际上我会传不同的实现类进去，那这时候就需要动态链接把 HashMap 或者 LinkedMap 之类的通过符号引用转化为直接引用找到 **运行时常量池中的信息** 。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606162627082.png" alt="image-20210606162627082" style="zoom: 33%; margin-left:-10px" />

聪明的人看都不用看，就知道这里的常量池中肯定不会有 HashMap 之类的符号引用了吧。

##### 返回地址

本质是存放调用该方法的 **PC寄存器的值** 。

通常有两种方式返回：

1. 正常结束：当前栈帧出栈，使用 ireturn 把值传递给上层，恢复上层方法的局部变量、操作数栈、设置PC寄存器值。

2. 非正常结束：也就是发生异常，且没有 catch 进行处理，也就是只要在本方法的异常表中没有搜素到匹配的 **异常处理器** ，就会导致方法退出。

后者不会给他的上层调用者产生任何的返回值。



#### 堆

在 JDK 7 版本及 JDK 7 版本之前，堆内存被通常被分为下面三部分：

1. 新生代(Young Generation)
2. 老年代(Old Generation)
3. 永久代(Permanent Generation)

JDK 8 版本之后方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。

上面提到，几乎所有的对象实例都是在堆中创建的，那对象是怎么创建的呢？

##### 对象的创建

1. 当虚拟机遇到一条 **new** 指令时，会检查这个类是否有被加载过，也就是是否找到这个 **类的符号引用** ，若没有会进行类的加载。

2. 为该对象 **分配内存空间** ，其中有 **指针碰撞** 和 **空闲列表** 两种方法。

   - 指针碰撞：在内存空间中，空间是 **规整的** ，分为已分配空间和未分配空间，这因此只需要在未分配内存中移动 对象大小相等 的距离就行。

     <img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210605211709047.png" alt="image-20210605211709047" style="zoom: 33%; margin-left:-10px" />

   - 空闲列表：空间是 **不规整的** ，因此需要维护一个空闲列表来记录内存中哪些地方是可用的，根据这个列表找到一个足够大的空间分配给该对象。

     <img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210605212056840.png" alt="image-20210605212056840" style="zoom:33%; margin-left:-10px" />

   细心的你应该也留意到了，空间是否规整是不是取决于我们的 **垃圾回收器** 有关呢？先别急，后面我记得的话会说。

   同时，对于 **指针碰撞** 来说，当多个线程同时为对象分配内存的时候，是不是会出现 **线程安全问题** 呢，我们可以开启 **TLAB** 来解决这个问题。

   **TLAB（线程本地分配缓存区）**

   在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个空间，如果需要分配内存，就在自己的空间上分配，这样就不存在竞争的情况，可以大大提升分配效率。它的本质是三个指针 start,top,end，其中 start 和 end 是划分当前线程区域，top 指区域大小，当空间不够时会 **再分配** 一个 TLAB 来创建新的对象。这里还有一个优化，就是当这个新的对象大小 **超过最大浪费空间** 时，就会直接在 EDEN 区域分配内存。

   那假如剩余 TLAB 不够怎么办？

   还是需要解决线程安全问题，采用 **CAS+失败重试** 的方式。

3. **初始化零值**：为实例对象的字段初始化为零值（不包括对象头），解释了为什么实例属性能直接引用。

   <img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210605220357165.png" alt="image-20210605220357165" style="zoom: 50%; margin-left:-10px" />

4. **设置对象头**：

   <img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210605221332066.png" alt="image-20210605221332066" style="zoom:33%; margin-left:-10px" />

   - **Mark Word**：Mark Word用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等，占用内存大小与虚拟机位长一致，后面假如提到锁的话会详细说。
   - **Klass Word**：也就是上面的类元信息，确定这个对象属于哪个类。

   顺便介绍一下其他部分：

   - **对象实例数据**：类中的成员变量。
   - **对齐填充**：JVM要求对象占用的空间必须是 8字节 的倍数，方便内存分配（以字节为最小单位分配），因此这部分就是用于填满不够的空间凑数用的。

5. **执行 init 方法**：在这之前，对象中的字段还没进行赋值，在执行完 init 方法之后，字段才赋值完成。

那对象都创建出来了，平时是怎么访问的呢？

##### 对象的访问

每运行一个方法，都会相对应创建一个栈帧，其中会有 **reference 类型的数据** ，就是指向具体对象的，也就是 **对象的引用** ，而访问该对象有两种方式：

1. **句柄**：会在堆中划分一块内存作为 **句柄池** ，reference 指向该句柄池。

   <img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210605224301502.png" alt="image-20210605224301502" style="zoom: 33%;margin-left:-10px" />

   注意其中包含了对象类型信息和实例数据信息。

2. **直接指针**：直接指向堆中的实例数据，指向方法区中的对象类型信息。

   <img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210605224611633.png" alt="image-20210605224611633" style="zoom:33%;margin-left:-10px" />

句柄的优势是：在对象被移动时，只需要改变句柄中的指针信息，reference不需要改。

直接指针的优势是：少了一次定位的开销。

##### 聊一聊String

上面介绍了 **方法区** 和 **堆**，String 刚好可以为两者做一下例子。

在 1.7 是把 **字符串常量池** 搬到了 **堆** 中，那到底什么是字符串常量池呢？

我们都知道，对象实例都是存放在堆中的，但是对字符串的存储有了优化，专门建了一个字符串常量池来存。因为当我们的字符相等时，是完全可以返回同一个实例的，能够节省很多内存，比如下面这一句：

``` java
String s1 = "Java";
String s2 = "Java";
System.out.println(s1 == s2); // 返回true
```

在执行完 s1 之后，字符串常量池已经有了 "Java" 了，因此 s2 并不会创建对象，而是直接指向 **字符串常量池** 中的 "Java"。

那下面这句呢？

```java
String s1 = new String("Java");
String s2 = new String("Java");
System.out.println(s1 == s2); // 返回 false
```

原因是在堆中创建了两个对象，这跟 JVM 的对象创建有关，因为遇到了 new 指令，但是在运行 s1 时，会先在 字符串常量池 创建 "Java"，然后在堆中创建实例对象，再把该实例对象指向 字符串常量池 中的 "Java"。因此上面总共创建了 **3 个对象**。

那字符串的拼接呢？

```java
String s1 = "a";
String s2 = "b";
String s3 = s1 + s2;
String s4 = "ab";
String s5 = "a" + "b";
System.out.println(s3 == s4); // false
System.out.println(s3 == s5); // false
System.out.println(s4 == s5); // true
```

因为 String 对象是不可变的，因此在 s3 是直接 **在堆中** 新建了个对象，而 s4 是直接指向 **字符串常量池**，因此他们两不一样。那为啥 s4 和 s5 又一样呢？因为 JVM 编译器在语句上做了优化，优化成了 String s5 = "ab" 。

再测试下 String 中的 intern 方法

``` java
String s1 = "a";
String s2 = new String("a");
String s3 = s2.intern();
System.out.println(s1 == s3); // true
```

intern 方法是返回该对象对应 **字符串常量池** 的对象，因此返回 true。

##### 聊一聊包装类缓存

Java 基本类型的包装类的大部分都实现了常量池技术，即 Byte,Short,Integer,Long,Character,Boolean；前面 4 种包装类默认创建了数值[-128，127] 的相应类型的缓存数据，Character 创建了数值在[0,127]范围的缓存数据，Boolean 直接返回 True Or False。如果超出对应范围仍然会去创建新的对象。

测试一下 Integer 缓存

```java
Integer i1 = 127;
Integer i2 = 127;
System.out.println(i1 == i2); // true

Integer i3 = 128;
Integer i4 = 128;
System.out.println(i3 == i4); // false
```

其实编译器会把上面的代码优化成 Integer i1 = valueOf(127) 。

看一下它的源码

```java
public static Integer valueOf(int i) {
    if (i >= IntegerCache.low && i <= IntegerCache.high)
        return IntegerCache.cache[i + (-IntegerCache.low)];
    return new Integer(i);
}
```

因此对超出范围的会创建一个新对象返回。

再看看下面的例子

``` java
Integer i1 = 3;
Integer i2 = 1;
Integer i3 = 2;
Integer i4 = i2 + i3;
System.out.println(i1 == i4); //true
```

返回 true 我们并不意外，但这个 + 号是怎么能够用在对象之间呢？其实也是编译器的优化，会调用以下方法，再相加。

```java
public int intValue() {
    return value;
}
```



题外话聊得差不多了，是时候讲讲对象的销毁了。

##### 对象的销毁

上面讲了对象的创建，是需要分配内存的，内存也就是堆内存，我们需要对没用的对象进行回收，防止内存耗尽，恰好 Java 本身就有垃圾回收器对堆中的对象进行回收，没有了手动销毁的烦恼。

先来看看堆长什么样

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606210139391.png" alt="image-20210606210139391" style="zoom: 50%; margin-left:-10px" />

从 jdk 8 开始，方法区的实现已经不在堆中了，因此上图就没有了方法区。

Eden : SurvivorFrom : SurvivorTo 默认比例为 8:1:1

年轻代 : 老年代 默认比例为 1:2

对象首先会在 EDEN 区域分配，当 EDEN 区满了后，会进行 **Minor GC** 将 **EDEN 区 + SurvivorFrom 区** 的无用对象进行回收，把剩下的对象移动到 **SurvivorTo 区** ，再将 SurvivorFrom 区 和 SurvivorTo 区 **指针对换**，保证 SurvivorTo 区 一定是空的。

晋升老年代的条件：

- **长期存活**：对象每存活一次，年龄就会+1，当年龄增长到阈值时 (默认是15) ，会晋升到 **老年代** 。

- **动态年龄判断**：Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 **Survivor区的一半** 时，取这个年龄和 MaxTenuringThreshold 中 **更小的一个值** ，作为新的晋升年龄阈值。
- **大对象** 直接晋升老年代。

**空间担保机制**：假如新生代进行 **Minor GC** 后所有的对象均存活并且达到阈值，就会一并晋升到老年代，因此在进行 **Minor GC** 前，需要先检查这些 对象的总和大小 **是否小于老年代可用空间** ，是则说明本次 **Minor GC** 是安全的，否则会先进行 **Full GC** ，确保老年代空间足够。

这也解释也为什么大对象会直接进入老年代，是为了 **避免触发空间担保机制** 影响效率。

那怎么判断一个对象可以存活呢？

**引用计数法**

给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1。当引用失效，计数器就减 1。**任何时候计数器为 0 的对象就是不可能再被使用的**。但是这种方法无法解决 **循环引用** 的问题。

**可达性分析算法**

**“GC Roots”** 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210606225115833.png" alt="image-20210606225115833" style="zoom:50%; margin-left:-10px" />

可作为 GC Roots 的对象包括下面几种:

- 虚拟机栈(栈帧中的本地变量表)中引用的对象
- 本地方法栈(Native 方法)中引用的对象
- 方法区中类静态属性引用的对象
- 方法区中常量引用的对象
- 所有被同步锁持有的对象

当对象不可达时，会判断对象是否覆盖了 finalize 方法，未覆盖则直接回收，若覆盖且未执行过，则将其放入F-Queue队列，由一个低优先级线程执行该队列中对象的 finalize 方法。执行完会再次判断该对象是否可达，若不可达，则进行回收，否则不进行回收。相当于有一次免死机会。


除了上面两种方式，对象是否存活还跟对象的 **引用类型** 有关。

1. **强引用**：宁愿抛出 **内存溢出异常** 也不会回收该对象。
2. **软引用** SoftReference：空间足够不会回收，不够就回收，**可以用作缓存** 。
3. **弱引用** WeakReference：GC 线程扫描到时就会回收。
4. **虚引用** PhantomReference：直接get是get不到的，需要在回收之后去引用队列（ReferenceQueue）中获取，因为gc这类对象后会放到队列里。

**虚引用** 会在回收之前加入到与之关联的引用队列中，程序通过判断引用队列中是否存在判断该对象是否被回收。

在实际程序设计中一般很少使用弱引用与虚引用，**使用软用的情况较多**，这是因为软引用可以加速JVM对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。

#### 常量的回收

之前我们不是还提到了 **字符串常量池** 嘛，当没有 String 对象引用时，该常量也会被回收的，我们称其为 **废弃常量** 。

#### 类的回收

除了对象回收，其实 class 也是可以回收的，记不记得开始要先对类进行加载，把类的信息加载到 **方法区** 中，这部分也是占用内存的，需要同时满足下面 3 个条件才能被回收：

1. 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。
2. 加载该类的 `ClassLoader` 已经被回收。
3. 该类对应的 `java.lang.Class` 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。



### 垃圾回收算法

上面讲到如何判断一个对象会被销毁，下面讲讲回收这些对象的算法。

#### 标记-清除

- 标记：遍历内存区域，对需要回收的对象打上标记。
- 清除：再次遍历内存，对已经标记过的内存进行回收。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210607100434003.png" alt="image-20210607100434003" style="zoom: 33%;margin-left:-10px" />

但从图中可以看出比较容易产生 **内存碎片** ，导致在为大对象分配空间时无法找到一个连续的空间。

同时效率也是很低的，要 **遍历两次内存** 。

#### 标记-复制

- 遍历内存区域，对需要回收的对象打上标记。
- 把存活的对象复制到另一块内存区域。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210607101440627.png" alt="image-20210607101440627" style="zoom:33%;margin-left:-10px" />

可以看到此算法解决了内存碎片的问题，但是却导致内存利用率不高，只能使用到一半区域。

#### 标记-整理

- 遍历内存区域，对需要回收的对象打上标记。
- 让存活的对象，向内存的一端移动，然后再清理掉没有用的内存。**注意顺序！！先移动再清理！！**

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210607102614994.png" alt="image-20210607102614994" style="zoom: 50%; margin-left: -10px;" />

#### 分代收集

把内存分成 **新生代** 和 **老年代** ，不同内存区域采用不同的垃圾回收算法。

新生代对象存活率较低，因此采用 **标记-复制** ，而老年代存活率较高，使用 **标记-清除** 或 **标记-整理** 会比较合适。

最后对各种 GC 名词做一下区分：

**Minor GC** **&&** **Young GC**：清理年轻代中的 EDEN区 和 SurvivorFrom区。

**Old GC**：清理老年代的对象。

**FullGC && MajorGC**：针对新生代、老年代、永久代的整体内存区域的GC

**MixedGC**：是G1垃圾回收器中特有的GC概念，指一旦老年代占据堆内存的45%，就要触发MixedGC，此时会对新生代、老年代、大对象区域都进行GC。



### 垃圾回收器

回收算法已经说完了，但 Java 本身实现了许多垃圾回收器，要根据它们的特性进行选择。



#### 新生代回收器

Serial

顾名思义：**串行**，只会使用单条线程去完成垃圾收集工作。

在 GC 期间，用户线程会暂停，直到垃圾回收结束。但是也不是没有优点，假如为单核 CPU ，无需与其他线程进行交互，减少了开销，在 Client 模式下简单高效。**它能与 CMS 收集器配合工作**

ParNew

是 **Serial** 的多线程版本 ，主要工作在 Server 模式，在多 CPU 的情况下，由于 ParNew 的多线程回收特性，毫无疑问垃圾收集会更快，也能有效地减少 STW 的时间，提升应用的响应速度。**它能与 CMS 收集器配合工作**

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210607135501056.png" alt="image-20210607135501056" style="zoom: 33%;margin-left:-10px" />

什么是 safe point？

1. 循环的末尾
2. 方法返回前
3. 调用方法的call之后
4. 抛出异常的位置

Parallel Scavenge

也是多线程工作于新生代的垃圾回收器，与 ParNew 不同，该回收器关注的点是达到一个可控制的吞吐量（吞吐量 = 运行用户代码时间 /（运行用户代码时间+垃圾收集时间）），而不是停顿时间尽可能短。



#### 老年代回收器

Serial Old

使用 **标记-整理** 算法，在 Client 模式下与 Serial 配合使用：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210607140548245.png" alt="image-20210607140548245" style="zoom: 50%; margin-left:-10px" />

从上图可以看出，即使在多 CPU 环境下，发生 GC 时也是单线程执行的。

CMS

使用 **标记-清除** 算法，以实现最短 STW 时间为目标的回收器。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210607141400514.png" alt="image-20210607141400514" style="zoom:50%; margin-left:-10px" />

1. 初始标记 ：标记 **老年代 GC Roots 直接引用的对象**、**年轻代引用到老年代的对象**，会导致stw。

   <img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210607144734358.png" alt="image-20210607144734358" style="zoom: 33%; margin-left:-10px" />

2. 并发标记：与用户线程同时运行，采取 **三色标记法** 来标记引用对象。

   其中会有 **漏标** 和 **错标** 的情况发生：

   漏标：

   <img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210805222733150.png" alt="image-20210805222733150" style="zoom: 25%; margin-left:-5px" />

   在当前情况执行A.B = null，但A已经是黑色了，不可能再遍历A的关联对象，同时B已经是灰色了，不会对其进行清除。这里的B对象称之为 **浮动垃圾**。

   错标：

   <img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210805223029147.png" alt="image-20210805223029147" style="zoom: 33%; margin-left: -5px;" />

   在当前情况下执行B.D = null; A.D = D; 就会导致D没有被标记到，最终被回收器清除。

   漏标的话等待下次扫描就能标记了，但错标的后果是非常严重的，因此有以下解决办法：

   注意！！只有上面两种条件同时存在才会导致错标，因此只要破坏其中一种就行了

   1. **写屏障 + 原始快照**

      当执行B.D = null 时，将这条引用关系记录下来，也就是保存断开前的视图，并按照保存的视图标记，这样 D 就不会被清除了。

   2. **写屏障 + 增量更新**

      当执行A.D = D 时，将这条引用关系记录下来，等扫描结束后，以 黑色A 开始再扫描一次，此时 D 就能置灰。

   3. **读屏障**

      因为代码流程肯定是这样的：

      1. D d = b.d;
      2. b.d = null;
      3. a.d = d;

      前面一定是先记录了d，后面才能关联上a，因此第一行代码是读操作，因此可以添加读屏障，也就是记录下所读取的对象。

   CMS 采用的时 **写屏障 + 增量更新** 实现的。

   G1 采取的是 **写屏障 + 原始快照** 实现的。

   <img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210607145016669.png" alt="image-20210607145016669" style="zoom:33%; margin-left:-10px" />

3. 并发预处理：

   1. 遍历新生代对象，因为有可能在并发过程中有对象引用了老年代，有可能在这个过程出发 Minor GC。

   2. 扫描Dirty Card，重新标记那些在并发标记阶段引用被更新的对象。

4. 重新标记（一般CMS的GC耗时80%都在remark阶段，为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录）：

   1. 遍历新生代对象，重新标记
   2. 根据GC Roots，重新标记
   3. 遍历老年代的Dirty Card，重新标记（这里的Dirty Card大部分已经在clean阶段处理过）

5. 并发清除：清除不再使用的对象，与用户线程同时运行。

6. 并发重置：重置 CMD 内部数据结构，与用户线程同时运行。

CMS在并发标记阶段，应用线程和GC线程是并发执行的，因此 **可能产生新的对象或对象关系发生变化**，例如：

- 新生代的对象晋升到老年代；
- 直接在老年代分配对象；
- 老年代对象的引用关系发生变更；
- 等等。

对于这些对象，需要重新标记以防止被遗漏。为了提高重新标记的效率，**并发标记阶段会把这些发生变化的对象所在的Card标识为Dirty**，这样后续阶段就只需要扫描这些Dirty Card的对象，从而避免扫描整个老年代。

缺点总结：

1. 需要牺牲用户线程来作为回收线程。
2. 无法在并发清除时处理期间产生的无用对象。
3. 标记-清除 算法产生内存碎片。
4. 有可能会晋升失败，在进行 Minor GC 时，由于空间担保机制，会判断老年代是否有足够空间保存将要晋升的对象，但可能老年代的空间是碎片化的，导致晋升失败，这时候就会使用备用方案 Serial Old 来进行空间整理。

更好的补充：https://juejin.cn/post/6844903922872614925



Parallel Old

使用 **标记-整理** 算法，是 Parallel Scavenge 的老年代版本，两者配合使用，实现吞吐量优先的目标。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210607151048733.png" alt="image-20210607151048733" style="zoom:33%; margin-left:-10px" />



#### G1 回收器

G1 收集器是面向服务端的垃圾收集器，被称为驾驭一切的垃圾回收器。

从 **整体** 看采用的是 **标记-整理** 算法，从 **局部** 的两个 Region 上看采用的是 **标记-复制** 算法，因此不像 CMS 那样存在内存碎片。在 stw 上建立了 **可预测的停顿时间模型** ，基于**衰减平均值**的理论基础，G1 会把停顿时间控制在用户设置的时间以内。

**G1结构**：

G1抛弃了之前的分代收集的方式，面向整个堆内存进行回收，把内存划分为多个大小相等的独立区域Region。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210607152207083.png" alt="image-20210607152207083" style="zoom:33%; margin-left:-10px" />

一共有4种Region：

1. 自由分区Free Region
2. 年轻代分区Young Region，年轻代还是会存在Eden和Survivor的区分
3. 老年代分区Old Region
4. 大对象分区Humongous Region

对G1来说，超过一个Region一半大小的对象都被认为大对象，将会被放入Humongous Region，而对于超过整个Region的大对象，则用几个连续的Humongous来存储。

**GC 触发条件**：

相对于之前我们存在分代概念的GC来说，G1其实也是类似的过程，总体可以分为这两种：

1. 年轻代GC，年轻代Region在超过我们默认设置的最大大小之后就会触发GC，还是用的我们熟悉的复制算法，Eden和Survivor来回倒腾，这里不再赘述。
2. Mixed GC 混合回收，混合回收类似于之前我们的Full GC概念，既会回收年轻代的Region，也会回收老年代的Region，还有我们新的Humongous大对象区域。触发规则根据参数`-XX:InitiatingHeapOccupancyPercent`(默认45%)值，也就是说老年代Region达到整个堆内存的45%时触发Mixed GC。

**回收过程**：

G1的回收过程分为以下四个步骤：

1. 初始标记：标记GC ROOT能关联到的对象，需要STW
2. 并发标记：从GCRoots的直接关联对象开始遍历整个对象图的过程，扫描完成后还会重新处理并发标记过程中产生变动的对象
3. 最终标记：短暂暂停用户线程，再处理一次，需要STW
4. 筛选回收：更新Region的统计数据，对每个Region的回收价值和成本排序，根据用户设置的停顿时间制定回收计划。再把需要回收的Region中存活对象复制到空的Region，同时清理旧的Region。需要STW。

总的来说这是一个偏向记忆的回收过程，知道就行了。

相对于之前我们存在分代概念的GC来说，G1其实也是类似的过程，总体可以分为这两种：

1. 年轻代GC，年轻代Region在超过我们默认设置的最大大小之后就会触发GC，还是用的我们熟悉的复制算法，Eden和Survivor来回倒腾，这里不再赘述。
2. Mixed GC混合回收，混合回收类似于之前我们的Full GC概念，既会回收年轻代的Region，也会回收老年代的Region，还有我们新的Humongous大对象区域。触发规则根据参数`-XX:InitiatingHeapOccupancyPercent`(默认45%)值，也就是说老年代Region达到整个堆内存的45%时触发Mixed GC。

**RSet**

为了避免GC时扫描整个堆内存，用来标志哪些区域存在跨代引用。每个Region中都存在一个Hash Table结构的记忆集，Key为其他Region的起始地址，Value是其他Card Table卡表的索引集合。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210809231908999.png" alt="image-20210809231908999" style="zoom:33%;margin-left:-5px" />

对于年轻代的 Region，它的 RSet 只保存了来自老年代的引用，这是因为年轻代的回收是针对所有年轻代 Region 的，没必要画蛇添足。所以说年轻代 Region 的 RSet 有可能是空的。

而对于老年代的 Region 来说，它的 RSet 也只会保存老年代对它的引用。这是因为老年代回收之前，会先对年轻代进行回收。这时，Eden 区变空了，而在回收过程中会扫描 Survivor 分区，所以也没必要保存来自年轻代的引用。

**原始快照**

在三色标记中我们也提到过，并发标记用户线程和收集线程一起工作会产生问题，解决方案CMS使用的是 写屏障 + 增量更新，G1则是用 写屏障 + 原始快照。

**具体我也搞不太懂，就意思意思它的思想差不多得了。**

建议：

如果是运行在桌面环境处于 Client 模式的，则用 Serial + Serial Old 收集器绰绰有余，如果需要响应时间快，用户体验好的，则用 ParNew + CMS 的搭配模式。

最后来张总结图：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210607161214377.png" alt="image-20210607161214377" style="zoom:50%; margin-left:-10px" />

问：young gc 需不需要扫描老年代呢？

答：需要，因为有可能老年代存在对象引用了年轻代的对象，而单纯地遍历年轻代的 GC Roots 是关联不到的，因此需要扫描老年代，但不可能扫面整个老年代，而是采取了空间换时间的做法，利用卡表数组去记录老年代有那些对象引用了年轻代的对象，并且把对应的卡表标记为脏，然后只要遍历该卡表中的对象就能找到年轻代关联对象了。注意，在并发清除的时候当一个对象产生改变时(增量更新)，也是把对应的卡表标记为脏。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210805214542618.png" alt="image-20210805214542618" style="zoom:50%; margin-left:-5px" />

问：那 old gc 需不需要扫描年轻代呢？

答：也需要，但年轻代并不大，因此扫描一次耗时并不长。



## Java

### 内存模型

先科普一下计算机的知识，我们的 CPU 在处理数据的时候并不会在内存中操作，而是会先把内存中的数据读取到 **CPU 缓存** ，甚至是内部的 **寄存器** ，再对数据进行处理，最终将结果刷新到缓存，再刷新回主存。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210608110613070.png" alt="image-20210608110613070" style="zoom:50%; margin-left:-10px" />

可以看到啊，假如我们有多个 CPU ，或者 CPU 中有多个核心，会导致 **缓存一致性** 的问题，因为他们共享同一个主存，又有自己的缓存，在处理同一数据，把数据刷新回主存时，又该按照谁的缓存呢？

CPU 厂商提供了两种方案：

1. **总线锁定**：某个 CPU 处理数据时，会锁定系统总线或内存总线，其他 CPU 不具备访问内存的权限，从而保证缓存一致性。
2. **MESI 协议**：缓存一致性协议，四个单词缩写，Modified修改、Exclusive独占、Shared共享、Invalid无效。

下面讲讲 MESI 的流程：

#### MESI

CPU A 需要读取内存中的数据，通过总线读取到自己的缓存中，此时因为只有一个核心读取了该数据，因此会把缓存行 Cache Line 修改成 Exclusive 状态，并监听总线。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210608132545289.png" alt="image-20210608132545289" style="zoom: 25%; margin-left:-10px" />

此时 CPU B 也需要读取该数据，在读取时 CPU A 嗅探到 CPU B 读取了该变量，于是把两边的缓存行设置为 Shared 状态。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210608133124386.png" alt="image-20210608133124386" style="zoom:25%;margin-left:-10px" />

CPU A 对 x 变量计算完成后，将缓存行状态改为 Modified ，同时通知其他缓存了该变量的 CPU，它们会将本地缓存行状态改为 Invalid 。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210608134931938.png" alt="image-20210608134931938" style="zoom: 33%; margin-left:-10px" />

CPU A 确认其他 CPU 设置完成后，将变量刷新到主内存中，再把自己的缓存行设置为 Exclusive 状态。

此时其他 CPU 对应的缓存行状态仍为 Invalid ，当他们要采取 **读缓存** 操作时，必须要从主内存读取（变成 S 或 E 状态）。

当要采取 **写缓存** 操作时，只有在缓存行状态为 M 或 E 时才能被执行，因此它们是需要先读主存，下面也分为 2 种情况：

1. 读完后状态为 E ，此时可以直接执行写缓存操作。
2. 读完后状态为 S ，需要先把自己缓存行状态改为 Modified ，通知其他 CPU 对应缓存行状态，确保都修改成 Invalid 后，才能进行写缓存操作。

#### Store Buffers

但是有没有发现，CPU A 要进行写缓存操作时，是要等待其他  CPU 把缓存行都改成 Invalid 才能执行，因此 **会阻塞处理器** ，效率低下，于是采取一种 **异步** 的思想，引入 **Store Buffers** ，先把要写入主存的值写到 Store Buffers ，然后做其他事情，等收到所有的 ACK 后，再去把该值刷新到主存。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210608151702867.png" alt="image-20210608151702867" style="zoom:33%;margin-left:-10px" />

#### Invalidate Queue

那假如 Store Buffers 被写满了呢？为了配合 Store Buffers ，引入了 **无效队列 Invalidate Queue**，CPU 在收到修改状态指令时，把该通知放到队列中，然后立即返回给发送方，从而提高效率，等当前操作执行完再去修改状态。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210608170439950.png" alt="image-20210608170439950" style="zoom:33%; margin-left:-10px" />

这样就解决了 写缓存 Store Buffers 带来的性能问题了。

但还会出现问题，假如我现在要执行以下代码：

**前提条件**：a 的初始值问 0。

```java
a = 1;
b = a + 1;
```

CPU A 将 a 的值写入 Store Buffers ，然后开始执行 b = a + 1，此时 a 的缓存行已经存在，于是直接以 a = 0作为值进行运算，导致 b = 0 + 1 = 1。

解决问题的方法为实现 **Store Forwarding** 技术，即读取 Store Buffers 的值，保证数据是最新的。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210608153858643.png" alt="image-20210608153858643" style="zoom:33%; margin-left:-10px" />

但这只是针对同一个 CPU 的情况，下面再举一个例子：

**前提条件**： a = 0，b = 0

```java
// 线程A
void a(){
    a = 1;
    b = 1;
}
// 线程B
void b(){
    while (b == 0) continue;
    assert(a == 1);
}
```

1. 线程A 把 a 变量读入缓存，并设置缓存行状态为 Exclusive  。
2. 线程B 因为 b 变量为 0 而不断死循环。
3. 线程A 对 a 变量执行写请求，设置状态为 Modified ，通知其他线程修改状态，同时把 a 变量的值写入 Store Buffers。
4. 线程A 对 b 变量修改 ..... 线程B 读到 b 变量最新值，退出死循环。
5. 线程B 从主存读取 a 变量，但 线程A 还没把新值刷新到主存，导致断言失败。

我们分析一下其中的漏洞，其实就是因为 线程B 缓存中没有 a 变量，因此状态没有修改成 Invalid ，同时 线程A 没有把新值刷新到主存，最终导致读不到最新值。

从 线程B 的角度来看，线程A 的操作是不是变成以下这样：

```java
void a(){
    b = 1;
    a = 1;
}
```

那该怎么办 ！！

#### 内存屏障

**写屏障**

针对上面的问题，我们可以引入在执行 b = 1 语句前加入一个 **写屏障** ，意思是我在执行这个语句前必须把 Store Buffers 中的数据写入到 cache 中，那既然数据能够写入 cache 了，是不是就意味着其余的 CPU 对应的 缓存行 状态都已经修改成 Invalid 了呢？于是问题就解决了。

```java
// 线程A
void a(){
    a = 1;
------------写屏障--------------
    b = 1;
}
// 线程B
void b(){
    while (b == 0) continue;
    assert(a == 1);
}
```

**读屏障**

下面也来一个简单例子

```java
// 线程A
void a(){
    a = 1;
}
// 线程B
void b(){
    b = a + 1;
}
```

因为 线程B 在执行 b = a + 1 之前需要先从主存读 a 的值，假设步骤是这样的：

1. 线程B 从主存读取 a缓存行 到 cache。
2. 线程A 将 a缓存行 写入 Store Buffers，通知其他 CPU 修改状态。
3. 线程B 通过 总线嗅探 收到通知，把该命令写入 失效队列 Invalidate Queue 。
4. 此时 线程B 并没有将 a缓存行 状态设置为 Invalid ，而 cache 中的值是旧值，因此会导致结果不一致。

假如我们现在加上 **读屏障** 。

```java
// 线程A
void a(){
    a = 1;
}
// 线程B
void b(){
------------读屏障--------------
    b = a + 1;
}
```

线程B 会先把 失效队列 中的操作先执行，于是 a缓存行 状态就修改为 Invalid ，需要重新从主存读取，问题也就解决了。

#### JMM

有了上面的知识前提，JMM 内存模型就很容易理解了。

在命令式编程中，线程之间的通信有 **共享内存** 和 **消息传递**。

Java 就是使用共享内存的方式实现线程通信的，在 Java 中，线程之间共享同一个堆，而线程之间的通信由 JMM 进行控制，**注意：本地内存是 JMM 的抽象概念，并不真实存在。**

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210608142625169.png" alt="image-20210608142625169" style="zoom: 25%; margin-left:-10px" />

假如线程想要读取主存中的变量，则必须先将该变量 **拷贝** 到自己的 **工作内存** ，才能对其进行操作，操作完成后再将变量写回主存，同时不同线程是不能够直接访问对方的工作内存的。

那这跟上面谈到的 MESI 有什么联系呢？

MESI 协议解决的是多个CPU对主存中数据访问问题，而 JVM 进程中有多线程的概念，它想实现一套规范，使得线程能够遵循这套规范去操作主存中的数据，因此上面所说的线程自己的 **工作内存是不真实存在的** ，只是因为有了 JMM 内存模型，才有这套规范，它们之间的关系可以表达为下面这幅图：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210609000104827.png" alt="image-20210609000104827" style="zoom: 50%; margin-left:-10px" />

对比之下其实每个线程对应的 **工作内存** 可以理解为是 **CPU 寄存器** 和 **高速缓存** 的抽象描述，每个线程就像是不同的 CPU 去从主存访问数据，它们之间同样也需要解决一些这套规范所带来的问题，下面就一一进行罗列。

##### 原子性

何为原子性，指一个操作不可被中断，一系列操作要么全部成功要么全部失败。在 JMM 中，能够保证 **基本数据类型变量**、**引用类型变量**、**声明为volatile的任何类型变量** 的访问 **读和写** 是具备原子性的，注意啊，long 和 double 因为是 64位 数据，因此在 32位 JVM 中是需要分开两次读的，因此可能会只读到 “半个变量” 的情况。

所谓的原子性操作，其实就是 **读或写** ，那这些操作是怎么保证原子性的呢？JMM 给我们定义了8种操作来完成，**每种都为原子操作**。

1. **read** 读取：作用于主内存，从主存读取变量的值到工作内存。
2. **load** 载入：作用于工作内存，把read操作的值放入工作内存中的变量副本。
3. **use** 使用：作用于工作内存，把工作内存的值传递给执行引擎，每当虚拟机遇到一个需要使用这个变量的指令时候，将会执行这个动作。
4. **assign** 赋值：作用于工作内存，把执行引擎获取到的值赋值给工作内存中的变量，当虚拟机栈遇到给变量赋值的指令，执行该操作。比如 int i = 1;
5. **store** 存储：作用于工作内存，把工作内存中的变量传送到主内存中，为随后的 write 操作使用。
6. **write** 写入：作用于主内存，把 store 传送值写到主内存的变量中。
7. **lock（锁定）** 作用于主内存，把变量标记为线程独占状态。
8. **unlock（解锁）** 作用于主内存，它将释放独占状态。

同时需要满足以下规则：

1. 不允许read和load、store和write操作之一单独出现，保证变量读取后拷贝到工作内存，**注意：必须按序执行，但没有保证必须连续执行**。
2. 不允许执行 assign 后丢弃后面的操作，即对工作内存的变量赋值后必须同步到主存。
3. 不允许没有经过 assign 就同步到主存。
4. 工作内存的变量不能未被初始化，且必须从主存诞生。
5. 一个变量同一时刻只允许一个线程执行 lock 操作，且是可重入的，对应也要执行相同数量的 unlock 才能释放。即 lock 和 unlock 必须成对。
6. 对变量执行 lock 时，必须清空工作内存中此变量的值，意味着要重新获取该变量的副本。
7. 一个变量没被 lock 前不能执行 unlock 操作。
8. 对一个变量执行 unlock 之前，必须把该变量刷新到主存。即执行 store 和 write 操作。

我们来推一下，如果需要读变量，规则1 可以满足原子性。

写变量的话，规则1 + 规则2 可以满足原子性。

那其他规则是什么时候用的呢？？先别急，JMM规范还有可见性问题呢。

##### 可见性

这是一个在多线程环境下，一个线程对共享变量进行修改后，另一个线程能否知道的问题。这 JMM 内存模型中并没有相关的处理，因此仅靠 JMM 是不能够保证线程之间的可见性的。这时候引出一个关键字 **volatile** 。

**volatile**

先说结论， volatile 关键字具备以下功能：

1. 当对volatile变量执行写操作后，JMM会把工作内存中的最新变量值强制刷新到主内存。
2. 写操作会导致其他线程中的工作内存无效。

怎么样，是不是感觉跟 **MESI 缓存一致性协议** 很像了，其实是真的利用到了MESI（在操作系统支持的情况下，不支持则使用总线锁）。

在操作一个 volatile 关键字描述的变量时，把该行代码转成汇编代码，会发现 **lock前缀** 的指令，此指令在多核处理器下会触发以下事情：

1. CPU 将当前变量的缓存行写回到主存中。
2. 使其他 CPU 缓存了该行变量的失效。

所以其实完全能够用 MESI 来解释，在回答时感觉能扯得更深入一点。

##### 有序性

什么是有序性呢？我们都知道代码是从上而下执行的，但谁又能保证呢，在多线程环境里执行以下代码：

```java
int a = 0;
a = 99;
new Thread(()->{
    System.out.print(a);
},"A").start();
```

这里 **主线程** 设置的 a 变量的值，我们会下意识觉得 线程A 打印 a 变量的值一定是 99，因为它是按序从上往下执行的呀，但为什么？还是因为 JMM 内存模型的规范，这次的主角是 **happens-before** 。

**happens-before**

它想表达的意思是 **前一个操作的结果对后续操作是可见的** 。

规则如下：

1. 同一线程中，前面的操作 happens-before 于后面的操作（也被称作 as-if-serial）。

   **即同一线程代码会按序执行。**

2. 对一个锁的解锁，happens-before 于随后对这个锁的加锁。

   ```java
   synchronized (this) { //此处自动加锁
     // x是共享变量,初始值=10
     if (this.x < 12) {
       this.x = 12; 
     }  
   } //此处自动解锁
   ```

   **即在线程A执行完后，线程B才能进入代码块。**

3. 对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。**即上面介绍的 volatile 可见性的情况。**

4. 主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。**即最开始引用的例子。**

5. 如果A happens-before B，且B happens-before C，那么A happens-before C。**即我比你先，你比他先，能推出我比他先。**

6. Thread.join()，直接上代码：

   ```java
   public static void main(String[] args) {
   	ThreadA a = new ThreadA();
   	a.start();
   	a.join();
       // 假设有共享变量a，那么在ThreadA执行完后，其对a变量的修改对于主线程是可见的。
       System.out.print(a);
   }
   ```

7. Thread.interrupted() **打算复习到ReentrantLock时再回来搞**
8. finalize() **懒得查**

我们这里本来讨论的是有序性，但其实有没有发现，happens-before 本质上指的是可见性，无论是单线程还是多线程，只要是 A 比 B 先执行，那么 A 一定对于 B 来说是可见的。

##### 指令重排

计算机在执行程序时，为了提高性能，编译器和处理器的常常会对指令做重排，在 **单线程** 环境下，JVM 可以保证在不改变 **数据依赖关系** 的情况下进行任意排序以提高程序性能。

```java
// 有数据依赖关系，不会进行指令重排
int a = 1;
int b = a + 1;

// 没有数据依赖关系，可能会进行指令重排
int c = 1;
int d = 2;
```

假如在多线程的环境下，进行了指令重排，是可能会导致执行结果改变的。

```java
int a = 0;
boolean flag = false;

public void method01() {
    a = 1;
    flag = true;
}

public void method02() {
    if (flag) {
        a = a + 5;
        System.out.println("a = " + a);
    }
}
```

线程A 执行 method01，线程B 执行 method02，是有可能因为线程A的指令重排导致先执行 flag = true 再执行 a = 1 的，因此线程B是有可能输出 a = 5 的。

因此这里引出 volatile 的另一个功能，**内存屏障** 。

跟之前讲的 MESI 一样，分为 **读屏障** 和 **写屏障**。

**Load Barrier**：在指令前插入读屏障，使工作内存中对应变量失效，需要从主从读取最新数据。

**Store Barrer**：在指令后插入写屏障，使工作内存中的变量写入主存。

volatile 的内存屏障十分严格，规则如下：

- 在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；
- 在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障；

给变量flag加上 volatile 关键字，再分析下代码。

```java
int a = 0;
volatile boolean flag = false;

public void method01() {
    a = 1;
    flag = true;
    // 写屏障，把变量值刷到主存
}

public void method02() {
    // 读屏障，使工作内存变量失效，从主存重新读取最新值
    if (flag) {
        a = a + 5;
        System.out.println("a = " + a);
    }
}
```

上面的代码放在 jdk1.5 前，a可能会是5也可能会是6，但之后有了 happens-before 后，遵守 **传递性** 规则，因此能直接得到 a = 6 这个答案。

### Synchronized

JMM 只为我们保证了部分操作的原子性，也就是类似 i++ 这种操作并不能保证原子性，Java 为我们提供了 Synchronized 关键字，利用 **互斥性** 来保证线程操作的原子性。

那 Synchronize 是怎么诞生的呢？

#### 互斥量

在上面的操作系统部分的线程同步中，互斥量 mutex 能够实现只有一个线程能够占用某个资源，从而实现线程的互斥，mutex 只有 0 和 1 两个值，而且加锁和解锁这个操作必须由同一个线程完成，可以把 mutex 抽象为四种操作：

1. 创建 Create
2. 加锁 Lock
3. 解锁 Unlock
4. 销毁 Destroy

当一个线程成功进入临界区后，其他线程获取不到锁，就会一直尝试获取锁，即一直循环判断 mutex 的值是否为1。就会导致其他线程一直浪费 CPU 资源。

#### 信号量

除了互斥量之外，信号量也是线程同步的一种方式，同时一定程度上解决了互斥量的浪费问题。信号量有以下几类：

1. 二进制信号量：只允许信号量取0或1值，其同时只能被一个线程获取。
2. 整型信号量：信号量取值是整数，它可以被多个线程同时获得，直到信号量的值变为0。
3. 记录型信号量：每个信号量除一个整数值（计数）外，还有一个等待队列List，其中是阻塞在该信号量的各个线程的标识。当信号量被释放一个，值被加一后，系统自动从等待队列中唤醒一个等待中的线程，让其获得信号量，同时信号量再减一。

信号量具有以下操作：

1. 创建 Create
2. 等待 Wait
3. 释放 Post
4. 试图等待 TryWait
5. 销毁 Destroy

与互斥量对比，信号量要灵活不少，因此信号量的用途更广泛，如支持多个线程同时访问一个临界区，线程按序执行等。更关键的是，信号量有一个等待队列，可以使得线程阻塞，即不需要占用 CPU 资源。

但是信号量使用起来比较繁琐，跟互斥量一样，**pv操作必须成对出现**，因此在复杂的情况下大大增加了编程难度。

#### 管程

管程是一种在信号量机制上进行改进的**并发编程模型**。

全称：**管理共享变量以及管理共享变量的操作过程**。

其中的共享变量就相当于互斥量，管程把互斥量和对互斥量的操作进行了封装，就像是一个 **中介** ，管程也被叫做 **Monitor**。

管程模型分为三种，这里只说其中一种(以后填坑也说不定)，因为 Java 就使用这种。

##### MESA

看下图应该就很直观了，功能跟信号量差不多。

![image-20210614144931481](https://raw.githubusercontent.com/jjames567/picture/main/image-20210614144931481.png)

那 Java 的管程模型是怎么实现的呢，下面开始讲原理：

#### 模型实现

先看看管程模型的结构，代码如下：

```c++
ObjectMonitor() {
    _count        = 0;      //记录数
    _recursions   = 0;      //锁的重入次数
    _owner        = NULL;   //指向持有ObjectMonitor对象的线程 
    _WaitSet      = NULL;   //调用wait后，线程会被加入到_WaitSet
    _EntryList    = NULL ;  //等待获取锁的线程，会被加入到该列表
}
```

运行图如下：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210614150034153.png" alt="image-20210614150034153" style="zoom:50%;margin-left:-5px" />

1. 当多个线程同时访问该方法，那么这些线程会先被放进`_EntryList`队列，此时线程处于`blocked`状态
2. 当一个线程获取到了对象的`monitor`后，那么就可以进入`running`状态，执行方法块，此时，`ObjectMonitor`对象的`_owner`指向当前线程，`_count`加1表示当前对象锁被一个线程获取。
3. 当`running`状态的线程调用`wait()`方法，那么当前线程释放`monitor`对象，进入`waiting`状态，`ObjectMonitor`对象的`_owner变为`null，`_count`减1，同时线程进入`_WaitSet`队列，直到有线程调用`notify()`方法唤醒该线程，则该线程进入`_EntryList`队列，竞争到锁再进入`_owner`区。
4. 如果当前线程执行完毕，那么也释放`monitor`对象，`ObjectMonitor`对象的`_owner`变为 null ，`_count`减1。

但是 Java 本身在 1.6 之后对加锁过程进行了优化，并不会一开始就使用上面的 ObjectMonitor 的，因为其底层依赖操作系统的 **Mutex Lock** 实现，**需要从用户态转换到核心态**，因此有锁升级这样一个过程，总共有 4 种锁状态。

在介绍之前，先讲讲 Java 对象头，算是填了之前写的坑。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210614151213913.png" alt="image-20210614151213913" style="zoom:33%; margin-left:-5px" />

Mark Word 是 Java 实现锁的一个很重要的部分，它的结构图如下：

![image-20210614151428141](https://raw.githubusercontent.com/jjames567/picture/main/image-20210614151428141.png)

#### 无锁

锁标志位为01，此时没有该对象所偏向的线程id，也叫做 **匿名偏向状态** 。

#### 偏向锁

锁标志位也是01，但线程id会记录正偏向的线程id。

流程如下：

1. A线程 需要访问代码块并获取锁对象时，会尝试cas写入自己的线程id进 Mark word，假如状态是匿名偏向则写入成功。

2. A线程 再次需要获取锁对象时，会先对比 Mark word 的线程id是否一致，一致则直接获取到锁（不需要经过cas修改 Mark word 的线程id）。

3. B线程 想要获取锁对象，进行cas把自己线程id替换进 Mark word ，但此时并不是匿名偏向状态，因此cas失败。**执行偏向锁撤销**。

**偏向锁撤销**：

当到达全局安全点（safepoint，代表了一个状态，在该状态下所有线程都是暂停的）时，会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着：

- 如果线程不处于活动状态，则将对象头设置成无锁状态（标志位为“01”），然后重新偏向新的线程；
- 如果线程仍然活着，撤销偏向锁后升级到 **轻量级锁** 状态（标志位为“00”），此时轻量级锁由原持有偏向锁的线程持有，在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁记录目前的 **Mark Word的拷贝**（称为Displaced Mark Word），然后cas把对象头的 Mark Word 指向 Displaced Mark Word 地址，标志位修改为00，唤醒原有线程继续执行其同步代码，而正在竞争的线程会进入 **自旋等待** 获得该轻量级锁。 

冷门知识：

- 当一个对象已经计算过identity hash code，它就无法进入偏向锁状态
- 当一个对象当前正处于偏向锁状态，并且需要计算其identity hash code的话，则它的偏向锁会被撤销，并且锁会膨胀为重量锁

因为在偏向锁中，哈希码和线程ID复用同一块空间，HotSpot VM是以**实际上只有很少对象会计算identity hash code**为前提来进行了优化，所以对象没有计算哈希码的时候可以使用偏向锁，一但计算之后，空间被占用则不能再使用偏向锁了。

#### 轻量级锁

获取轻量级锁的过程 (再讲一次吧)：

1. 当前线程的栈中分配锁记录。
2. 拷贝对象头的 Mark Word 到锁记录中。
3. cas操作将 Mark Word 指针指向当前线程的锁记录。

第三步会通过自旋重试，当达到一定次数（默认为10），就会升级为**重量级锁**。

Lock Record 保存在栈帧中，线程能够获取其哈希值、分代年龄等信息，如下图所示：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210614212746708.png" alt="image-20210614212746708" style="zoom:33%; margin-left:-5px" />

#### 重量级锁

当升级为重量级锁后，Mark Word 指向的 Monitor 对象地址。

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210614205125794.png" alt="image-20210614205125794" style="zoom:50%; margin-left:-5px" />

具体流程可以看回上面一开始的介绍。

最后再提一嘴，在线程释放锁时会把工作内存中的变量刷新回主存，**因此 Synchronized 也保证了可见性**。

Synchronized的常见用法和反编译看到的东西就不写了，最后再来个总流程图，掰掰。。。

![synchronize](https://raw.githubusercontent.com/jjames567/picture/main/synchronize.jpg)



### AQS

在 Java 中除了使用 Synchronized 关键字来加锁以外，常见的还有 ReentrantLock ，但是在讲它之前，需要先了解什么是 AQS。

还记得 MESA 管程模型中有多个条件队列吗，但 ObjectMonitor 只有一个同步队列，AQS 也是管程模型的实现，同时其实现了这个多个条件队列，下面先看看它的结构图：

![image-20210616164249823](https://raw.githubusercontent.com/jjames567/picture/main/image-20210616164249823.png)

可以看到，单纯一个 AQS 抽象类就已经实现了管程模型了，下面看看它功能是怎么实现的。

#### 同步队列

##### 入队

```java
public final void acquire(int arg) {
    if (!tryAcquire(arg) && // 尝试获取锁（未实现）
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 加入队列
        selfInterrupt();
}
```

tryAcquire 方法并没有实现，而是直接抛出了一个异常，因此需要它的子类对其重写。

```java
protected boolean tryAcquire(int arg) {
    throw new UnsupportedOperationException();
}
```

addWaiter 方法（加入到同步队列）

```java
private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode); // 封装当前线程的Node，注意mode为Node.EXCLUSIVE
    // 加入到同步队列末尾
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    // 同步队列未初始化，执行enq进行初始化
    enq(node);
    return node;
}
```

acquireQueued 方法（尝试获取同步队列锁）

```java
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            // 获取当前节点的前一个节点
            final Node p = node.predecessor();
            // 判断是否是头节点 || 尝试获取锁（未实现）
            if (p == head && tryAcquire(arg)) {
                // 设置当前节点为头节点，且清除上个头节点的链接，至此当前节点获取到了同步队列锁
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            // 说明当前节点不是老二
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

shouldParkAfterFailedAcquire 方法（先自旋一次修改状态值，准备好阻塞）

```java
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL)
        // SIGNAL代表已经准备好阻塞了
        return true;
    if (ws > 0) {
        // 把状态为CANCELLED的节点跳过，CANCELLED值为1
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus > 0);
        pred.next = node;
    } else {
        // 把状态修改为SIGNAL
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}
```

parkAndCheckInterrupt() 方法（阻塞当前线程，返回停止标记）

```java
private final boolean parkAndCheckInterrupt() {
    LockSupport.park(this);
    return Thread.interrupted();
}
```

小结：先尝试获取锁tryAcquire，拿不到则队列初始化（设置头节点和尾节点）或者封装节点添加到队尾，再执行acquireQueue判断当前节点的前驱是否是head，是则再尝试获取锁tryAcquire，否则自旋一次改变节点状态为SIGNAL，再park线程。

##### 出队

```java
public final boolean release(int arg) {
    if (tryRelease(arg)) { // 尝试释放锁（未实现）
        Node h = head;
        if (h != null && h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}
```

unparkSuccessor 方法（唤醒头节点的下一个节点）

```java
private void unparkSuccessor(Node node) {
    
    int ws = node.waitStatus;
    if (ws < 0)
        compareAndSetWaitStatus(node, ws, 0);
	
    Node s = node.next;
    // 为什么从尾节点开始遍历？https://blog.csdn.net/foxException/article/details/108917338?utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link
    // 大致的意思是，在执行enq方法中，在cas当前节点为尾部前，已经把pre设置好，设置完尾部后才设置next，因此可能会导致next为空，但是pre绝不会为空。
    if (s == null || s.waitStatus > 0) {
        s = null;
        for (Node t = tail; t != null && t != node; t = t.prev)
            if (t.waitStatus <= 0)
                s = t;
    }
    // 唤醒该进程
    if (s != null)
        LockSupport.unpark(s.thread);
}
```

这时候被唤醒的线程就会从下面的代码继续执行

```java
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head && tryAcquire(arg)) {
                setHead(node);
                p.next = null; 
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt()) // 判断为false
                interrupted = true;
            // 唤醒后继续自旋，继续之前的逻辑，尝试获取同步队列锁。
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

小结：假如tryRlease成功，则唤醒头结点的下一个结点的线程，因为acquireQueued是一个死循环，因此唤醒后会再次判断自己的前一个结点是否是头节点，是则尝试获取锁，成功则设置自己为头节点。

#### 条件队列

在讲之前，我们看看 AQS 中节点的设计

```java
static final class Node {
    static final Node SHARED = new Node();
    static final Node EXCLUSIVE = null;
    static final int CANCELLED =  1;
    static final int SIGNAL    = -1;
    static final int CONDITION = -2;
    static final int PROPAGATE = -3;
    volatile int waitStatus;
    volatile Node prev;
    volatile Node next;
    volatile Thread thread;
    Node nextWaiter;
}
```

有没有留意到 nextWaiter 这个变量，而这个变量直接连向了另一个队列的节点。

条件队列结构图

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210616174059803.png" alt="image-20210616174059803" style="zoom:50%;margin-left:-5px" />

##### 入队

```java
public final void await() throws InterruptedException {
    // 标志位出错
    if (Thread.interrupted())
        throw new InterruptedException();
    // 加入到条件队列
    Node node = addConditionWaiter();
    // 释放同步队列锁
    int savedState = fullyRelease(node);
    int interruptMode = 0;
    // 确保不在同步队列中
    while (!isOnSyncQueue(node)) {
        // 阻塞
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    // 被唤醒后，尝试获取锁，此时该线程已经被其他线程加入到同步队列中（流程：先入队->再获取锁）
    if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null) // clean up if cancelled
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}
```

addConditionWaiter 方法

```java
private Node addConditionWaiter() {
    Node t = lastWaiter;
    // 把状态为CANCELLED的尾节点清除
    if (t != null && t.waitStatus != Node.CONDITION) {
        unlinkCancelledWaiters();
        t = lastWaiter;
    }
    Node node = new Node(Thread.currentThread(), Node.CONDITION);
    // 队列未初始化
    if (t == null)
        firstWaiter = node;
    // 入队
    else
        t.nextWaiter = node;
    // 成为尾节点
    lastWaiter = node;
    return node;
}
```

unlinkCancelledWaiters 方法（清理取消等待的线程，看得我头晕，差不多意思得了啊）

```java
private void unlinkCancelledWaiters() {
    Node t = firstWaiter;
    Node trail = null;
    while (t != null) {
        Node next = t.nextWaiter;
        if (t.waitStatus != Node.CONDITION) {
            t.nextWaiter = null;
            if (trail == null)
                firstWaiter = next;
            else
                trail.nextWaiter = next;
            if (next == null)
                lastWaiter = trail;
        }
        else
            trail = t;
        t = next;
    }
}
```

fullyRelease 方法（释放同步队列锁）

```java
final int fullyRelease(Node node) {
    boolean failed = true;
    try {
        int savedState = getState();
        // 同步队列的出队方法
        if (release(savedState)) {
            failed = false;
            return savedState;
        } else {
            throw new IllegalMonitorStateException();
        }
    } finally {
        if (failed)
            node.waitStatus = Node.CANCELLED;
    }
}
```

isOnSyncQueue 方法（是否在同步队列中）

```java
final boolean isOnSyncQueue(Node node) {
    if (node.waitStatus == Node.CONDITION || node.prev == null)
        return false;
    if (node.next != null) // If has successor, it must be on queue
        return true;
    return findNodeFromTail(node); // 从最后往前找
}
```

findNodeFromTail 方法（从同步队列尾节点往前找）

```java
private boolean findNodeFromTail(Node node) {
    // 从尾节点开始往前找
    Node t = tail;
    for (;;) {
        // 是否同一个节点
        if (t == node)
            return true;
        if (t == null)
            return false;
        t = t.prev;
    }
}
```

##### 出队

```java
public final void signal() {
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    Node first = firstWaiter;
    if (first != null)
        doSignal(first);
}
```

doSinal 方法（找到条件队列的下一个节点，然后加入到同步队列，再唤醒对应线程）

```java
private void doSignal(Node first) {
    do {
        // 节点不断往后移
        if ( (firstWaiter = first.nextWaiter) == null)
            lastWaiter = null;
        first.nextWaiter = null;
    } while (!transferForSignal(first) &&
             (first = firstWaiter) != null);
}
```

transferForSignal 方法（线程唤醒后会重新尝试获取同步队列锁）

```java
final boolean transferForSignal(Node node) {
    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
        return false;
	// 加入同步队列
    Node p = enq(node);
    int ws = p.waitStatus;
    if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
        // 唤醒
        LockSupport.unpark(node.thread);
    return true;
}
```

所以 AQS 一定程度上跟 Synchronized 的规定差不多。

Synchronized 只能在代码块内使用 wait 和 notify 方法，ReentrantLock 也是如此，后面会说。

Synchronized 在调用 wait 时，会让出锁；AQS 在加入条件队列前，必须先加入同步队列，在调用 await 时，会先从移出同步队列，也就是让出同步队列锁。

Synchronized 在调用 notify 时，会唤醒其中一个线程；AQS 在调用 signal 时，会把条件队列的下一个节点移出，加入到同步队列中，唤醒线程。

那么接下来看看 AQS 的实现类。

#### ReentrantLock

前面 AQS 都实现了基本功能了，那哪个方法是必须子类实现的呢？比如以下两个方法：

```java
protected boolean tryAcquire(int arg) {
    throw new UnsupportedOperationException();
}
protected boolean tryRelease(int arg) {
    throw new UnsupportedOperationException();
}
```

就是上面说的，尝试获取锁和尝试释放锁。

ReentrantLock 本身是有两种锁模式的，分别是 **公平锁** 和 **非公平锁**。

公平锁实现：

```java
protected final boolean tryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    // 0表示无锁
    if (c == 0) {
        if (!hasQueuedPredecessors() && // 同步队列是否还有节点在等待
            compareAndSetState(0, acquires)) { // 没有则修改锁状态
            setExclusiveOwnerThread(current); // 成功则设置独占锁线程
            return true;
        }
    }
    // 非0表示已被其他线程上锁
    else if (current == getExclusiveOwnerThread()) {
        // 同一线程则进行锁重入
        int nextc = c + acquires;
        if (nextc < 0)
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

非公平锁实现：

```java
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        // 区别在于有没有调用hasQueuedPredecessors方法，该方法是判断同步队列是否有节点在等待
        // 假如有一个线程刚好把锁释放了，此时state为0，但同步队列还有节点，因此这种情况下是有机会能直接抢到锁的，这也是体现那非公平的地方，刚来的线程有机会能直接拿到锁。
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

而它们的释放锁的实现方式都是调用同一个方法，代码如下：

```java
protected final boolean tryRelease(int releases) {
    // 计算重入次数state
    int c = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
        free = true;
        setExclusiveOwnerThread(null);
    }
    setState(c);
    return free;
}
```

除此之外，ReentrantLock 对象是可以创建多个条件队列的

```java
final ConditionObject newCondition() {
    return new ConditionObject();
}
```

有没有感觉很奇妙，这不就是 **MESA管程模型** 吗？

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210616212956682.png" alt="image-20210616212956682" style="zoom:33%; margin-left:-5px" />

不知道你有没有跟我这样的想法，既然一个同步队列对应多个条件队列，那能不能反过来，多个同步队列对应一个条件队列呢？就像下面的代码：

```java
ReentrantLock lock1 = new ReentrantLock(false);
ReentrantLock lock2 = new ReentrantLock(false);
Condition condition = lock2.newCondition();
new Thread(()->{
    lock1.lock();
    System.out.println("A抢到锁了");
    try {
        // 条件队列并不是lock1创建的
        condition.await();
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
    lock1.unlock();
},"ThreadA").start();
```

果然就报错了。。。报错地方如下：

```java
protected final boolean tryRelease(int releases) {
    int c = getState() - releases;
    // 这里会看到独占锁线程为null
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
        free = true;
        setExclusiveOwnerThread(null);
    }
    setState(c);
    return free;
}
```

看看是什么时候设置的独占锁线程

```java
final void lock() {
    if (compareAndSetState(0, 1))
        // 设置独占锁线程
        setExclusiveOwnerThread(Thread.currentThread());
    else
        acquire(1);
}
```

这个参数来自于 AbstractOwnableSynchronizer 类，而 AQS 是其子类，ReentrantLock 的内部类 Sync 又是 AQS 子类，因此每个 ReentrantLock 类都会有自己的独占线程参数，所以 lock2 对象中的独占线程才会为 null。这个测试是不是也证实了 setExclusiveOwnerThread 的作用了呢？

至此 ReentrantLock 告一段落，你以为结束了？

#### 共享模式

请再看一次 Node 结构设计：

```java
static final class Node {
    static final Node SHARED = new Node // 是不是没见过，表示共享模式
    static final Node EXCLUSIVE = null;
    static final int CANCELLED =  1;
    static final int SIGNAL    = -1;
    static final int CONDITION = -2;
    static final int PROPAGATE = -3; // 是不是也没见过，表示节点可传播
    volatile int waitStatus;
    volatile Node prev;
    volatile Node next;
    volatile Thread thread;
    Node nextWaiter;
}
```

是滴，AQS 除了独占模式，还有共享模式，对应有以下内容：

Node 初始化的方式

```java
Node(Thread thread, Node mode) {     // Used by addWaiter
    this.nextWaiter = mode; // mode表明采用哪种模式，有 EXCLUSIVE 和 SHARE
    this.thread = thread;
}
Node(Thread thread, int waitStatus) { // Used by Condition
    this.waitStatus = waitStatus;
    this.thread = thread;
}
```

获取共享锁

```java
public final void acquireShared(int arg) {
    if (tryAcquireShared(arg) < 0) // 尝试获取共享锁（未实现），会返回可用资源
        doAcquireShared(arg); // 获取共享锁
}
```

doAcquireShared 方法（很重要！！先被阻塞，后被唤醒时，**会把头节点设置为自己的后继节点**，**再唤醒头节点**）

```java
private void doAcquireShared(int arg) {
    // 加入同步队列，注意 Node.SHARED 只有一个，充当共享标志，返回的是当前节点
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) {
                // 尝试获取可用资源，arg为获取个数
                int r = tryAcquireShared(arg);
                // 判断可用资源是否大于0
                if (r >= 0) {
                    // 设置当前节点为头节点，更新传递数，并唤醒后面的线程
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    if (interrupted)
                        selfInterrupt();
                    failed = false;
                    return;
                }
            }
            // 跟独占模式一样，自旋+阻塞
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

setHeadAndPropagate 方法

```java
private void setHeadAndPropagate(Node node, int propagate) {
    Node h = head; // 旧的头节点！！
    // node是当前节点
    setHead(node);
    if (propagate > 0 || h == null || h.waitStatus < 0 ||
        (h = head) == null || h.waitStatus < 0) {
        Node s = node.next;
        // 只要当前节点的后继节点不是独占式，就进行唤醒
        if (s == null || s.isShared())
            doReleaseShared();
    }
}
```

doReleaseShared 方法

```java
private void doReleaseShared() {
    for (;;) {
        Node h = head;
        if (h != null && h != tail) {
            int ws = h.waitStatus;
            // 后继节点正阻塞，需要唤醒
            if (ws == Node.SIGNAL) {
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;            // 失败则重新循环，不唤醒
                unparkSuccessor(h);
            }
            else if (ws == 0 &&
                     !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) // 设置为可传递状态
                continue;                
        }
        if (h == head)                   // 头节点没有被修改，则退出循环，意味着只要头节点被修改了，就会帮忙唤醒头节点的后继节点，这就是为什么共享队列的线程会被逐一唤醒
            break;
    }
}
```

释放共享锁

```java
public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) { // 尝试释放共享锁（未实现）
        doReleaseShared(); //看上面
        return true;
    }
    return false;
}
```

再详细地方暂时不深究了，下面看看它的实现类是怎么利用共享模式的，还记得信号量吗，Java 中也有 Semaphore，利用 AQS 的共享模式实现信号量功能。

#### Semaphore

Semaphore 实现的 tryAcquireShared 方法

```java
protected int tryAcquireShared(int acquires) {
    return nonfairTryAcquireShared(acquires);
}
```

nonfairTryAcquireShared 方法（非公平）

```java
final int nonfairTryAcquireShared(int acquires) {
    for (;;) {
        // 获取可用资源
        int available = getState();
        // 运算并修改
        int remaining = available - acquires;
        if (remaining < 0 ||
            compareAndSetState(available, remaining))
            return remaining;
    }
}
```

tryAcquireShared 方法（公平）

```java
protected int tryAcquireShared(int acquires) {
    for (;;) {
        // 多了个同步队列是否有后继节点判断，原理和之前讲的ReentrantLock一样
        if (hasQueuedPredecessors())
            return -1;
        int available = getState();
        int remaining = available - acquires;
        if (remaining < 0 ||
            compareAndSetState(available, remaining))
            return remaining;
    }
}
```

可以发现 Semaphore 中的 state 参数并不是代表重入数量，而是代表可用资源，正如其构造方法：

```java
Sync(int permits) {
    setState(permits);
}
```

Semaphore 实现的 tryReleaseShared 方法

```java
protected final boolean tryReleaseShared(int releases) {
    for (;;) {
        // 获取可用资源
        int current = getState();
        // 相加并修改
        int next = current + releases;
        if (next < current) // overflow
            throw new Error("Maximum permit count exceeded");
        if (compareAndSetState(current, next))
            return true;
    }
}
```

个人感觉东西全给 AQS 做了，可见其强大。

那除了信号量之外，还能玩出什么花样呢？

再重温一下共享锁的获取方式

```java
public final void acquireShared(int arg) {
    if (tryAcquireShared(arg) < 0) // （未实现）
        doAcquireShared(arg); // 加入到共享队列中
}
```

继续重温共享锁的释放方式

```java
public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) { // （未实现）
        doReleaseShared(); // 唤醒共享队列的线程
        return true;
    }
    return false;
}
```

就是说 AQS 本来是希望我们把 arg 当作可用资源的，当可用资源经过相减后为负数就意味着可用资源不足，需要加入到共享队列排队。那我们是不是可以人为把它 **返回负数** ，强制让线程排队阻塞，在一定条件下再返回非负数，唤醒所有的阻塞的线程，这像什么，是不是像同步器，看下面实现吧。

#### CountDownLatch

CountDownLatch 实现的 tryAcquireShared 方法

```java
protected int tryAcquireShared(int acquires) {
    return (getState() == 0) ? 1 : -1;
}
```

直到 state 为 0 时才会返回非负数，即在 state 不为 0 前，线程最终会排队阻塞。

CountDownLatch 实现的 tryReleaseShared 方法

```java
protected boolean tryReleaseShared(int releases) {
    for (;;) {
        int c = getState();
        if (c == 0)
            return false;
        // 每个线程调用-1，直到为0时才会唤醒共享队列线程
        int nextc = c-1;
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}
```

doReleaseShared 方法会在上面的方法返回 true 之后调用

再次强调啊，下面这个自旋真的绝了！！当 state 为 0 时，需要唤醒共享队列中的所有线程。

```java
private void doReleaseShared() {
    for (;;) {
        Node h = head;
        if (h != null && h != tail) {
            int ws = h.waitStatus;
            if (ws == Node.SIGNAL) {
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;            // loop to recheck cases
                unparkSuccessor(h); // 唤醒后继节点线程
            }
            else if (ws == 0 &&
                     !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                continue;                // loop on failed CAS
        }
        if (h == head)                   // 下面的方法会修改头节点，就会导致再自旋一次，再唤醒头节点的下一个节点
            break;
    }
}
```

线程会从下面继续执行

```java
private void doAcquireShared(int arg) {
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            // 线程被唤醒后，把头节点设置为自己，也就是head会从pre变成当前节点
            final Node p = node.predecessor();
            if (p == head) {
                int r = tryAcquireShared(arg);
                if (r >= 0) {
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    if (interrupted)
                        selfInterrupt();
                    failed = false;
                    return;
                }
            }
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

就这样，共享队列的线程会逐一被唤醒，达到同步器的目的。

最后补一个小知识：

- wait&notify 必须要 Object Monitor 一起使用，而 park 与 unpark 不需要
- park&unpark 是以确定的单个线程【堵塞】和【唤醒】线程的，而 notify 是随机唤醒同一把锁对象的线程的
- park不会释放锁资源，wait会释放锁资源
- park&unpark 可以先 unpark (park后直接就唤醒了)，而 wait&notify 不能提前 notify

和一张图：

![image-20210617232738939](https://raw.githubusercontent.com/jjames567/picture/main/image-20210617232738939.png)

暂时就这么多吧，或许以后会补。。。

面试总结：

1. 介绍AQS的结构：Node、ConditionObject、acquire()、release()。
2. Node：独占模式、共享模式，状态：Condition、Signal、Cancell、Propagate，pre、next指针，nextWaiter、Thread。
3. acquire：tryAcquire、入队（队列初始化、自旋、设置Signal、park）。
4. release：tryRelease、unparkSuccessor。
5. 共享模式：state代表可用资源，在获取到资源后会调用setHeadPropagate方法，里面会执行head传播，并且唤醒head的下一个节点。在释放资源的时候，会有一个自旋，除了会把资源回收到可用资源外，还会通过判断头节点是否被改变来继续自旋来继续唤醒head的下一个节点。

### 线程池

线程池主要的作用是避免线程频繁创建与销毁所造成的开销，同时对线程资源作统一管理，下面直接源码走起吧。

execute 执行任务

```java
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    int c = ctl.get();
    // 少于核心线程数，添加worker
    if (workerCountOf(c) < corePoolSize) {
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
    // 多于核心线程数，添加进队列
    if (isRunning(c) && workQueue.offer(command)) {
        int recheck = ctl.get();
        if (! isRunning(recheck) && remove(command))
            reject(command);
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    // 队列已满，添加worker，里面假如大于最大线程数则会返回false，则执行拒绝策略
    else if (!addWorker(command, false))
        reject(command);
}
```

addWorker

```java
private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    for (;;) {
		// 省略部分代码.....根据状态判断是否可以接收任务
        
        for (;;) {
            // 超过最大线程数则返回false执行拒绝策略
            int wc = workerCountOf(c);
            if (wc >= CAPACITY ||
                wc >= (core ? corePoolSize : maximumPoolSize))
                return false;
            // 设置worker数量，成功则break
            if (compareAndIncrementWorkerCount(c))
                break retry;
            c = ctl.get();  // Re-read ctl
            if (runStateOf(c) != rs)
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }

    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        // 把任务封装成Worker，里面会新建线程进行绑定
        w = new Worker(firstTask);
        // 获取对应线程
        final Thread t = w.thread;
        if (t != null) {
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int rs = runStateOf(ctl.get());

                if (rs < SHUTDOWN ||
                    (rs == SHUTDOWN && firstTask == null)) {
                    if (t.isAlive()) // precheck that t is startable
                        throw new IllegalThreadStateException();
                    // 添加到保存workers的Set集合
                    workers.add(w);
                    int s = workers.size();
                    if (s > largestPoolSize)
                        largestPoolSize = s;
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) {
                // 这里其实执行的是包含线程的worker的run方法，也就是调用了runWorker(this)方法
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        if (! workerStarted)
            addWorkerFailed(w);
    }
    // 正常则返回true
    return workerStarted;
}
```

然后就是来到了线程执行任务的过程

上面说到的Worker继承了AQS类，也实现了Runnable接口，下面看看它的构造方法

```java
Worker(Runnable firstTask) {
    setState(-1); // 在调用runWorker前,禁止中断
    this.firstTask = firstTask;
    this.thread = getThreadFactory().newThread(this);
}
```

中断是通过下面这个方法，因此在-1的时候worker不可被中断

```java
void interruptIfStarted() {
    Thread t;
    // 判断state
    if (getState() >= 0 && (t = thread) != null && !t.isInterrupted()) {
        try {
            t.interrupt();
        } catch (SecurityException ignore) {
        }
    }
}
```

runWorker

```java
final void runWorker(Worker w) {
    Thread wt = Thread.currentThread();
    Runnable task = w.firstTask;
    w.firstTask = null;
    // 允许被打断，注意state设置为0而不是+1
    w.unlock(); 
    boolean completedAbruptly = true;
    try {
        // 当任务队列为空且当前任务为空，停止循环
        while (task != null || (task = getTask()) != null) {
            // 加锁，注意是不可重入的，每次state都是0->1
            // 作用：
            // 1.可以防止在shutdown()时终止正在运行的worker：因为shutdown()中设置中断需要先tryLock()
            // 2.解决并发
            w.lock();
            // 根据状态判断中断
            if ((runStateAtLeast(ctl.get(), STOP) ||
                 (Thread.interrupted() &&
                  runStateAtLeast(ctl.get(), STOP))) &&
                !wt.isInterrupted())
                wt.interrupt();
            try {
                // 空方法，由子类实现
                beforeExecute(wt, task);
                Throwable thrown = null;
                try {
                    // 执行任务
                    task.run();
                } catch (RuntimeException x) {
                    thrown = x; throw x;
                } catch (Error x) {
                    thrown = x; throw x;
                } catch (Throwable x) {
                    thrown = x; throw new Error(x);
                } finally {
                    // 空方法，由子类实现
                    afterExecute(task, thrown);
                }
            } finally {
                task = null;
                // 完成任务数+1
                w.completedTasks++;
                // 释放锁
                w.unlock();
            }
        }
        // 表明正常退出，传入下面的方法
        completedAbruptly = false;
    } finally {
        // 当task返回null时，处理worker退出
        processWorkerExit(w, completedAbruptly);
    }
}
```

关键点在于 getTask 和 processWorkerExit ，决定了线程的复用和多余线程的销毁，下面先看getTask方法

```java
private Runnable getTask() {
    // timeOut：表示从任务队列中取任务时是否超时
    boolean timedOut = false;

    for (;;) {
        int c = ctl.get();
        int rs = runStateOf(c);

        // 如果线程池为`Shutdown`状态且任务队列为空，线程-1并且返回null表明不再接收新任务
        if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {
            decrementWorkerCount();
            return null;
        }

        // 当前线程数
        int wc = workerCountOf(c);

        // 是否需要超时控制(即减少线程数)，可以手动设置允许 || 当前线程大于核心线程数
        boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;

        // 大于核心线程数 || (需要控制 && 从队列取任务超时) && (wc > 1 && 队列为空)
        if ((wc > maximumPoolSize || (timed && timedOut))
            && (wc > 1 || workQueue.isEmpty())) {
            // 线程数-1并返回null
            if (compareAndDecrementWorkerCount(c))
                return null;
            continue;
        }

        try {
            // 一般poll()用于普通线程、take()用于核心线程
            // 需要控制 则 在keepAliveTime时间内获取队列中的任务，没获取到则返回null
            Runnable r = timed ?
                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
            // 不需要控制则进行阻塞
            workQueue.take();
            if (r != null)
                return r;
            // 标记从队列获取任务超时
            timedOut = true;
        } catch (InterruptedException retry) {
            timedOut = false;
        }
    }
}
```

再看看worker退出的方法吧

```java
private void processWorkerExit(Worker w, boolean completedAbruptly) {
    // 为true则表明之前出现了异常，需要手动-1
    if (completedAbruptly)
        decrementWorkerCount();

    // 从线程set集合中移除工作线程，该过程需要加锁
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        // 统计完成的任务数
        completedTaskCount += w.completedTasks;
        // 从HashSet<Worker>中移除该worker
        workers.remove(w);
    } finally {
        mainLock.unlock();
    }
	// 根据线程池状态进行判断是否结束线程池
    tryTerminate();

    int c = ctl.get();
    // 当线程池是RUNNING或SHUTDOWN状态时
    if (runStateLessThan(c, STOP)) {
        // 如果worker不是异常结束
        if (!completedAbruptly) {
            int min = allowCoreThreadTimeOut ? 0 : corePoolSize;
            // 如果allowCoreThreadTimeOut=true，并且等待队列有任务，至少保留一个worker来处理任务
            if (min == 0 && ! workQueue.isEmpty())
                min = 1;
            // 如果allowCoreThreadTimeOut=false，且workerCount不少于corePoolSize，那就直接返回
            if (workerCountOf(c) >= min)
                return;
        }
        // 如果worker是异常结束，那么会直接addWorker重新创建线程
        addWorker(null, false);
    }
}
```

好像还没解释复用是怎么个复用法，记得 getTask 方法中的 workQueue.take() 吗，这个方法里面是这样的，以 ArrayBlockingQueue 为例子：

```java
public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        // 任务队列为空，则阻塞
        while (count == 0)
            notEmpty.await();
        return dequeue();
    } finally {
        lock.unlock();
    }
}
```

再看看 当前线程数 > 核心线程 时的代码

```java
// 这里有一个入队的操作
if (isRunning(c) && workQueue.offer(command)) {
    int recheck = ctl.get();
    if (! isRunning(recheck) && remove(command))
        reject(command);
    else if (workerCountOf(recheck) == 0)
        addWorker(null, false);
}
```

看看入队代码

```java
public boolean offer(E e) {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        // 超过容量则返回false，外面会判断是否达到最大线程数来进一步操作
        if (count == items.length)
            return false;
        else {
            // 入队
            enqueue(e);
            return true;
        }
    } finally {
        lock.unlock();
    }
}
```

接着往里面看

```java
private void enqueue(E x) {
    // assert lock.getHoldCount() == 1;
    // assert items[putIndex] == null;
    final Object[] items = this.items;
    items[putIndex] = x;
    if (++putIndex == items.length)
        putIndex = 0;
    count++;
    // 唤醒其中一个线程，这里能够唤醒之前的线程，拿到最新的task来执行
    notEmpty.signal();
}
```

另外提一点，阻塞队列有两个 condition 变量，我猜测应该是生产者消费者模式，但上面的方法只体现了其中一个 condition ，之后可能会研究阻塞队列这个类的实现。

线程池可以执行一个 Runnable 的实现，也可以执行一个 Callable 实现，下面上例子：

1/0 在编译期并不能发现，只会在执行时抛出异常，实际执行也会如常抛出

```java
poolExecutor.execute(new Runnable() {
    @Override
    public void run() {
        System.out.println("hello");
        int a = 1/0;
    }
});
```

再看看 Callable，实际执行是不会抛出异常的，原因是内部被吞了，注意 submit 是父类 AbstractExecutorService 的方法

```java
Future<Integer> result = poolExecutor.submit(() -> {
    int a = 1/0;
    return 2;
});
```

看看 Callable 的源码部分，它的实现类是 FutureTask，注意看下面的 catch 部分

```java
public void run() {
    if (state != NEW ||
        !UNSAFE.compareAndSwapObject(this, runnerOffset,
                                     null, Thread.currentThread()))
        return;
    try {
        Callable<V> c = callable;
        if (c != null && state == NEW) {
            V result;
            boolean ran;
            try {
                result = c.call();
                ran = true;
            } catch (Throwable ex) {
                result = null;
                ran = false;
                // 捕获异常并设置
                setException(ex);
            }
            if (ran)
                set(result);
        }
    } finally {
        // runner must be non-null until state is settled to
        // prevent concurrent calls to run()
        runner = null;
        // state must be re-read after nulling runner to prevent
        // leaked interrupts
        int s = state;
        if (s >= INTERRUPTING)
            handlePossibleCancellationInterrupt(s);
    }
}
```

看看 setException 方法

```java
protected void setException(Throwable t) {
    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {
        // 会把异常赋值到 outcome 变量中
        outcome = t;
        UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state
        finishCompletion();
    }
}
```

其实这个 outcome 就是 FutrueTask 的 get 方法的返回值

```java
public V get() throws InterruptedException, ExecutionException {
    int s = state;
    if (s <= COMPLETING)
        s = awaitDone(false, 0L);
    return report(s);
}
```

继续往 report 方法看，可以看到下面的 throw new ExecutionException((Throwable)x);

```java
private V report(int s) throws ExecutionException {
    // 赋值给x并返回
    Object x = outcome;
    if (s == NORMAL)
        return (V)x;
    if (s >= CANCELLED)
        throw new CancellationException();
    // 抛异常
    throw new ExecutionException((Throwable)x);
}
```

因此我们 **不执行 get 方法的话，这个异常就捕获不到了** ，可以通过重写 afterExecute 方法来补偿

```java
@Override
protected void afterExecute(Runnable r, Throwable t) {
    super.afterExecute(r, t);
    if (t == null && r instanceof Future<?>) {
        try {
            // 调用 get 方法使得异常被下面 catch 捕获，然后再封装处理
            Object result = ((Future<?>) r).get();
        } catch (CancellationException ce) {
            t = ce;
        } catch (ExecutionException ee) {
            t = ee.getCause();
        } catch (InterruptedException ie) {
            Thread.currentThread().interrupt(); // ignore/reset
        }
    }
    if (t != null){
        //异常处理
        t.printStackTrace();
    }
}
```

网上有些是利用 setUncaughtExceptionHandler 来解决的，但我这边测试没成功，具体不知道什么原因。。。

最后看一下线程池的一些状态：

<img src="https://raw.githubusercontent.com/jjames567/picture/main/image-20210703162735384.png" alt="image-20210703162735384" style="zoom: 33%; margin-left:-5px" />

1. RUNNING：该状态的线程池会接收新任务，并处理任务队列中的任务。

   调用线程池的shutdown()方法，可以切换到SHUTDOWN状态；
   调用线程池的shutdownNow()方法，可以切换到STOP状态；

2. SHUTDOWN:该状态的线程池不会接收新任务，但会处理任务队列中的任务。

   任务队列为空，并且线程池中执行的任务也为空，进入TIDYING状态；

3. STOP：该状态的线程不会接收新任务，也不会处理任务队列中的任务，而且会中断正在运行的任务。

   线程池中执行的任务为空，进入TIDYING状态；

4. TIDYING：该状态表明所有的任务已经运行终止，记录的任务数量为0；

   terminated()执行完毕，进入TERMINATED状态；

5. TERMINATED：该状态表示线程池彻底终止；









## RocketMQ

先上一张整体架构图

![image-20210626160909034](https://raw.githubusercontent.com/jjames567/picture/main/image-20210626160909034.png)

### 角色

#### Producer

负责生产消息，一般由业务系统负责生产消息。一个消息生产者会把业务应用系统里产生的消息发送到 Broker 服务器。

那消息一般有哪些呢？

##### 

集群部署：

#### Consumer

负责消费消息，一般是后台系统负责异步消费。一个消息消费者会从 Broker 服务器拉取消息、并将其提供给应用程序。从用户应用的角度而言提供了两种消费形式：拉取式消费、推动式消费。

#### Broker

消息中转角色，负责存储消息、转发消息。代理服务器在 RocketMQ 系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备。代理服务器也存储消息相关的元数据，包括消费者组、消费进度偏移和主题和队列消息等。

#### Namesrv

名称服务充当路由消息的提供者。生产者或消费者能够通过名字服务查找各主题相应的 Broker IP 列表。多个 Namesrv 实例组成集群，但 **相互独立，没有信息交换** 。

#### Topic

表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是 RocketMQ 进行消息订阅的基本单位。



## Spring源码分析

### IOC

这里先分析 xml 的方式进行初始化，调用 ClassPathXmlApplicationContext 的构造方法：

```java
public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent)
    throws BeansException {

    super(parent);
    // 根据提供的路径，处理成配置文件数组(以分号、逗号、空格、tab、换行符分割)
    setConfigLocations(configLocations);
    if (refresh) {
        // 可以是初始化容器，也可以是重建容器
        refresh();
    }
}
```

看看 refresh 方法有哪些步骤：

```java
@Override
public void refresh() throws BeansException, IllegalStateException {
    synchronized (this.startupShutdownMonitor) {
        // 刷新前的预处理
        prepareRefresh();

        // 获取beanFactory
        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();

        // beanFactory进行初始化后的设置
        prepareBeanFactory(beanFactory);

        try {
            // beanFactory准备工作完成后进行后置处理工作
            postProcessBeanFactory(beanFactory);

            // 调用beanFactory后置处理器
            invokeBeanFactoryPostProcessors(beanFactory);

            // 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别
         	// 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization
         	// 两个方法分别在 Bean 初始化之前和初始化之后得到执行。这里仅仅是注册，之后会看到回调这两方法的时机
            registerBeanPostProcessors(beanFactory);

            // 初始化MessageSource组件（国际化、消息绑定、消息解析）
            initMessageSource();

            // 初始化事件分发器
            initApplicationEventMulticaster();

            // 自定义容器刷新逻辑，留给子类实现
            onRefresh();

            // 将所有项目里的ApplicationListener注册进来
            registerListeners();

            // 实例化单例bean
            finishBeanFactoryInitialization(beanFactory);

            // 完成BeanFactory的初始化创建工作
            finishRefresh();
        }

        // catch........finally............
    }
}
```



#### prepareRefresh()

```java
// 准备工作，记录下容器的启动时间、标记“已启动”状态、处理配置文件中的占位符
protected void prepareRefresh() {
    // 记录启动时间，
   	// 将 active 属性设置为 true，closed 属性设置为 false，它们都是 AtomicBoolean 类型
    this.startupDate = System.currentTimeMillis();
    this.closed.set(false);
    this.active.set(true);

    if (logger.isInfoEnabled()) {
        logger.info("Refreshing " + this);
    }

    // Initialize any placeholder property sources in the context environment
    initPropertySources();

    // 校验 xml 配置文件
    getEnvironment().validateRequiredProperties();

    // Allow for the collection of early ApplicationEvents,
    // to be published once the multicaster is available...
    this.earlyApplicationEvents = new LinkedHashSet<ApplicationEvent>();
}
```

#### obtainFreshBeanFactory()

```java
// 配置文件就会解析成一个个 Bean 定义，注册到 BeanFactory 中，但Bean 还没有初始化，只是配置信息都提取出来了
protected ConfigurableListableBeanFactory obtainFreshBeanFactory() {
    // 关闭旧的 BeanFactory (如果有)，创建新的 BeanFactory，加载 Bean 定义、注册 Bean 等等
    refreshBeanFactory();
    // 返回刚刚创建的 BeanFactory，类型为DefaultListableBeanFactory(大佬)
    ConfigurableListableBeanFactory beanFactory = getBeanFactory();
    if (logger.isDebugEnabled()) {
        logger.debug("Bean factory for " + getDisplayName() + ": " + beanFactory);
    }
    return beanFactory;
}
```

##### refreshBeanFactory()

```java
@Override
protected final void refreshBeanFactory() throws BeansException {
    /** 如果 ApplicationContext 中已经加载过 BeanFactory 了，销毁所有 Bean，关闭 BeanFactory
   	  * 注意，应用中 BeanFactory 本来就是可以多个的，这里可不是说应用全局是否有 BeanFactory，而是当前
  	  * ApplicationContext 是否有 BeanFactory
    **/
    if (hasBeanFactory()) {
        destroyBeans();
        closeBeanFactory();
    }
    try {
        // 初始化一个 DefaultListableBeanFactory
        DefaultListableBeanFactory beanFactory = createBeanFactory();
        // 用于 BeanFactory 的序列化
        beanFactory.setSerializationId(getId());
        // 设置 BeanFactory 的两个配置属性：是否允许 Bean 覆盖、是否允许循环引用
        customizeBeanFactory(beanFactory);
        // 加载 Bean 到 BeanFactory 中
        loadBeanDefinitions(beanFactory);
        synchronized (this.beanFactoryMonitor) {
            this.beanFactory = beanFactory;
        }
    }
    catch (IOException ex) {
        throw new ApplicationContextException("I/O error parsing bean definition source for " + getDisplayName(), ex);
    }
}
```

###### customizeBeanFactory(beanFactory)

```java
protected void customizeBeanFactory(DefaultListableBeanFactory beanFactory) {
    if (this.allowBeanDefinitionOverriding != null) {
        // 是否允许 Bean 定义覆盖
        // bean 时使用了相同的 id 或 name，假如不配置允许覆盖则会报错
        beanFactory.setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding);
    }
    if (this.allowCircularReferences != null) {
        // 是否允许 Bean 间的循环依赖
        beanFactory.setAllowCircularReferences(this.allowCircularReferences);
    }
}
```

###### loadBeanDefinitions(beanFactory)

```java
// 根据配置，加载各个 Bean，然后放到 BeanFactory 中
@Override
protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException {
    // 实例化配置读取器
    XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory);

    // Configure the bean definition reader with this context's
    // resource loading environment.
    beanDefinitionReader.setEnvironment(this.getEnvironment());
    beanDefinitionReader.setResourceLoader(this);
    beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this));

    // Allow a subclass to provide custom initialization of the reader,
    // then proceed with actually loading the bean definitions.
    initBeanDefinitionReader(beanDefinitionReader);
    // 下面解析这个方法
    loadBeanDefinitions(beanDefinitionReader);
}
```

loadBeanDefinitions(beanDefinitionReader)

A 和 B 都是执行相同的方法

```java
protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException {
    Resource[] configResources = getConfigResources();
    if (configResources != null) {
        // A
        reader.loadBeanDefinitions(configResources);
    }
    String[] configLocations = getConfigLocations();
    if (configLocations != null) {
        // B
        reader.loadBeanDefinitions(configLocations);
    }
}
```

然后就是通过 xml 解析成一个个 BeanDefinition，关键代码如下：

```java
public AbstractBeanDefinition parseBeanDefinitionElement(
      Element ele, String beanName, BeanDefinition containingBean) {

   this.parseState.push(new BeanEntry(beanName));

   String className = null;
   if (ele.hasAttribute(CLASS_ATTRIBUTE)) {
      className = ele.getAttribute(CLASS_ATTRIBUTE).trim();
   }

   try {
      String parent = null;
      if (ele.hasAttribute(PARENT_ATTRIBUTE)) {
         parent = ele.getAttribute(PARENT_ATTRIBUTE);
      }
      // 创建 BeanDefinition，然后设置类信息而已，很简单，就不贴代码了
      AbstractBeanDefinition bd = createBeanDefinition(className, parent);

      // 设置 BeanDefinition 的一堆属性，这些属性定义在 AbstractBeanDefinition 中
      parseBeanDefinitionAttributes(ele, beanName, containingBean, bd);
      bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT));

      /**
       * 下面的一堆是解析 <bean>......</bean> 内部的子元素，
       * 解析出来以后的信息都放到 bd 的属性中
       */

      // 解析 <meta />
      parseMetaElements(ele, bd);
      // 解析 <lookup-method />
      parseLookupOverrideSubElements(ele, bd.getMethodOverrides());
      // 解析 <replaced-method />
      parseReplacedMethodSubElements(ele, bd.getMethodOverrides());
    // 解析 <constructor-arg />
      parseConstructorArgElements(ele, bd);
      // 解析 <property />
      parsePropertyElements(ele, bd);
      // 解析 <qualifier />
      parseQualifierElements(ele, bd);

      bd.setResource(this.readerContext.getResource());
      bd.setSource(extractSource(ele));

      return bd;
   }
}
```

然后就是注册 bean 流程

```java
protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) {
   // 将 <bean /> 节点转换为 BeanDefinitionHolder，就是上面的方法
   BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);
   if (bdHolder != null) {
      // 如果有自定义属性的话，进行相应的解析，先忽略
      bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);
      try {
         // 我们把这步叫做 注册Bean 吧
         BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());
      }
      catch (BeanDefinitionStoreException ex) {
         getReaderContext().error("Failed to register bean definition with name '" +
               bdHolder.getBeanName() + "'", ele, ex);
      }
      // 注册完成后，发送事件，本文不展开说这个
      getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder));
   }
}
```

注册方法

```java
@Override
public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition)
      throws BeanDefinitionStoreException {

   Assert.hasText(beanName, "Bean name must not be empty");
   Assert.notNull(beanDefinition, "BeanDefinition must not be null");

   if (beanDefinition instanceof AbstractBeanDefinition) {
      try {
         ((AbstractBeanDefinition) beanDefinition).validate();
      }
      catch (BeanDefinitionValidationException ex) {
         throw new BeanDefinitionStoreException(...);
      }
   }

   // old? 还记得 “允许 bean 覆盖” 这个配置吗？allowBeanDefinitionOverriding
   BeanDefinition oldBeanDefinition;

   // 之后会看到，所有的 Bean 注册后会放入这个 beanDefinitionMap 中
   oldBeanDefinition = this.beanDefinitionMap.get(beanName);

   // 处理重复名称的 Bean 定义的情况
   if (oldBeanDefinition != null) {
      if (!isAllowBeanDefinitionOverriding()) {
         // 如果不允许覆盖的话，抛异常
         throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription()...
      }
      else if (oldBeanDefinition.getRole() < beanDefinition.getRole()) {
         // log...用框架定义的 Bean 覆盖用户自定义的 Bean 
      }
      else if (!beanDefinition.equals(oldBeanDefinition)) {
         // log...用新的 Bean 覆盖旧的 Bean
      }
      else {
         // log...用同等的 Bean 覆盖旧的 Bean，这里指的是 equals 方法返回 true 的 Bean
      }
      // 覆盖
      this.beanDefinitionMap.put(beanName, beanDefinition);
   }
   else {
      // 判断是否已经有其他的 Bean 开始初始化了.
      // 注意，"注册Bean" 这个动作结束，Bean 依然还没有初始化，我们后面会有大篇幅说初始化过程，
      // 在 Spring 容器启动的最后，会 预初始化 所有的 singleton beans
      if (hasBeanCreationStarted()) {
         // Cannot modify startup-time collection elements anymore (for stable iteration)
         synchronized (this.beanDefinitionMap) {
            this.beanDefinitionMap.put(beanName, beanDefinition);
            List<String> updatedDefinitions = new ArrayList<String>(this.beanDefinitionNames.size() + 1);
            updatedDefinitions.addAll(this.beanDefinitionNames);
            updatedDefinitions.add(beanName);
            this.beanDefinitionNames = updatedDefinitions;
            if (this.manualSingletonNames.contains(beanName)) {
               Set<String> updatedSingletons = new LinkedHashSet<String>(this.manualSingletonNames);
               updatedSingletons.remove(beanName);
               this.manualSingletonNames = updatedSingletons;
            }
         }
      }
      else {
         // 最正常的应该是进到这个分支。

         // 将 BeanDefinition 放到这个 map 中，这个 map 保存了所有的 BeanDefinition
         this.beanDefinitionMap.put(beanName, beanDefinition);
         // 这是个 ArrayList，所以会按照 bean 配置的顺序保存每一个注册的 Bean 的名字
         this.beanDefinitionNames.add(beanName);
         // 这是个 LinkedHashSet，代表的是手动注册的 singleton bean，
         // 注意这里是 remove 方法，到这里的 Bean 当然不是手动注册的
         // 手动指的是通过调用以下方法注册的 bean ：
         //     registerSingleton(String beanName, Object singletonObject)
         // 这不是重点，解释只是为了不让大家疑惑。Spring 会在后面"手动"注册一些 Bean，
         // 如 "environment"、"systemProperties" 等 bean，我们自己也可以在运行时注册 Bean 到容器中的
         this.manualSingletonNames.remove(beanName);
      }
      // 这个不重要，在预初始化的时候会用到，不必管它。
      this.frozenBeanDefinitionNames = null;
   }

   if (oldBeanDefinition != null || containsSingleton(beanName)) {
      resetBeanDefinition(beanName);
   }
}
```

#### prepareBeanFactory(beanFactory)

```java
// 设置 BeanFactory 的类加载器，添加几个 BeanPostProcessor，手动注册几个特殊的 bean
protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) {
   // 设置 BeanFactory 的类加载器，我们知道 BeanFactory 需要加载类，也就需要类加载器，
   // 这里设置为加载当前 ApplicationContext 类的类加载器
   beanFactory.setBeanClassLoader(getClassLoader());

   // 设置 BeanExpressionResolver
   beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader()));
   // 
   beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment()));

   // 添加一个 BeanPostProcessor，这个 processor 比较简单：
   // 实现了 Aware 接口的 beans 在初始化的时候，这个 processor 负责回调，
   // 这个我们很常用，如我们会为了获取 ApplicationContext 而 implement ApplicationContextAware
   // 注意：它不仅仅回调 ApplicationContextAware，
   //   还会负责回调 EnvironmentAware、ResourceLoaderAware 等，看下源码就清楚了
   beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this));

   // 下面几行的意思就是，如果某个 bean 依赖于以下几个接口的实现类，在自动装配的时候忽略它们，
   // Spring 会通过其他方式来处理这些依赖。
   beanFactory.ignoreDependencyInterface(EnvironmentAware.class);
   beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class);
   beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class);
   beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class);
   beanFactory.ignoreDependencyInterface(MessageSourceAware.class);
   beanFactory.ignoreDependencyInterface(ApplicationContextAware.class);

   /**
    * 下面几行就是为特殊的几个 bean 赋值，如果有 bean 依赖了以下几个，会注入这边相应的值，
    * 之前我们说过，"当前 ApplicationContext 持有一个 BeanFactory"，这里解释了第一行。
    * ApplicationContext 还继承了 ResourceLoader、ApplicationEventPublisher、MessageSource
    * 所以对于这几个依赖，可以赋值为 this，注意 this 是一个 ApplicationContext
    * 那这里怎么没看到为 MessageSource 赋值呢？那是因为 MessageSource 被注册成为了一个普通的 bean
    */
   beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory);
   beanFactory.registerResolvableDependency(ResourceLoader.class, this);
   beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this);
   beanFactory.registerResolvableDependency(ApplicationContext.class, this);

   // 这个 BeanPostProcessor 也很简单，在 bean 实例化后，如果是 ApplicationListener 的子类，
   // 那么将其添加到 listener 列表中，可以理解成：注册 事件监听器
   beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this));

   // 这里涉及到特殊的 bean，名为：loadTimeWeaver，这不是我们的重点，忽略它
   // tips: ltw 是 AspectJ 的概念，指的是在运行期进行织入，这个和 Spring AOP 不一样，
   //    感兴趣的读者请参考我写的关于 AspectJ 的另一篇文章 https://www.javadoop.com/post/aspectj
   if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) {
      beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));
      // Set a temporary ClassLoader for type matching.
      beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));
   }

   /**
    * 从下面几行代码我们可以知道，Spring 往往很 "智能" 就是因为它会帮我们默认注册一些有用的 bean，
    * 我们也可以选择覆盖
    */

   // 如果没有定义 "environment" 这个 bean，那么 Spring 会 "手动" 注册一个
   if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) {
      beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment());
   }
   // 如果没有定义 "systemProperties" 这个 bean，那么 Spring 会 "手动" 注册一个
   if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) {
      beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties());
   }
   // 如果没有定义 "systemEnvironment" 这个 bean，那么 Spring 会 "手动" 注册一个
   if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) {
      beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment());
   }
}
```

#### postProcessBeanFactory(beanFactory)

该方法是交给子类重写的,子类通过重写这个方法来在BeanFactory创建并预准备完成以后做进一步的设置

到目前为止，应该说 BeanFactory 已经创建完成，并且所有的实现了 BeanFactoryPostProcessor 接口的 Bean  都已经初始化并且其中的 postProcessBeanFactory(factory) 方法已经得到回调执行了。而且 Spring  已经“手动”注册了一些特殊的 Bean，如 `environment`、`systemProperties` 等。

#### registerBeanPostProcessors(beanFactory)

```txt
// 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别
// 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization
// 两个方法分别在 bean 实例化完成、属性注入完成之后。这里仅仅是注册，之后会看到回调这两方法的时机
一、获取所有的 BeanPostProcessor;后置处理器都默认可以通过PriorityOrdered、Ordered接口来执行优先级
二、先注册PriorityOrdered优先级接口的BeanPostProcessor；
把每一个BeanPostProcessor；添加到BeanFactory中
beanFactory.addBeanPostProcessor(postProcessor);
三、再注册Ordered接口的
四、 最后注册没有实现任何优先级接口的
五、最终注册MergedBeanDefinitionPostProcessor；
六、注册一个ApplicationListenerDetector；来在Bean创建完成后检查是否是ApplicationListener，如果是
applicationContext.addApplicationListener((ApplicationListener<?>) bean);


```



剩下的就是初始化 singleton beans 了，我们知道它们是单例的，如果没有设置懒加载，那么 Spring 会在接下来初始化所有的 singleton beans。

#### finishBeanFactoryInitialization(beanFactory)

```java
// 初始化所有的 singleton beans
protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) {

   // 首先，初始化名字为 conversionService 的 Bean。本着送佛送到西的精神，我在附录中简单介绍了一下 ConversionService，因为这实在太实用了
   // 什么，看代码这里没有初始化 Bean 啊！
   // 注意了，初始化的动作包装在 beanFactory.getBean(...) 中，这里先不说细节，先往下看吧
   if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &&
         beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) {
      beanFactory.setConversionService(
            beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class));
   }

   // Register a default embedded value resolver if no bean post-processor
   // (such as a PropertyPlaceholderConfigurer bean) registered any before:
   // at this point, primarily for resolution in annotation attribute values.
   if (!beanFactory.hasEmbeddedValueResolver()) {
      beanFactory.addEmbeddedValueResolver(new StringValueResolver() {
         @Override
         public String resolveStringValue(String strVal) {
            return getEnvironment().resolvePlaceholders(strVal);
         }
      });
   }

   // 先初始化 LoadTimeWeaverAware 类型的 Bean
   // 之前也说过，这是 AspectJ 相关的内容，放心跳过吧
   String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false);
   for (String weaverAwareName : weaverAwareNames) {
      getBean(weaverAwareName);
   }

   // Stop using the temporary ClassLoader for type matching.
   beanFactory.setTempClassLoader(null);

   // 没什么别的目的，因为到这一步的时候，Spring 已经开始预初始化 singleton beans 了，
   // 肯定不希望这个时候还出现 bean 定义解析、加载、注册。
   beanFactory.freezeConfiguration();

   // 开始初始化
   beanFactory.preInstantiateSingletons();
}
```

##### preInstantiateSingletons()

```java
@Override
public void preInstantiateSingletons() throws BeansException {
   if (this.logger.isDebugEnabled()) {
      this.logger.debug("Pre-instantiating singletons in " + this);
   }
   // this.beanDefinitionNames 保存了所有的 beanNames
   List<String> beanNames = new ArrayList<String>(this.beanDefinitionNames);

   // 下面这个循环，触发所有的非懒加载的 singleton beans 的初始化操作
   for (String beanName : beanNames) {

      // 合并父 Bean 中的配置，注意 <bean id="" class="" parent="" /> 中的 parent，用的不多吧，
      // 考虑到这可能会影响大家的理解，我在附录中解释了一下 "Bean 继承"，不了解的请到附录中看一下
      RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName);

      // 非抽象、非懒加载的 singletons。如果配置了 'abstract = true'，那是不需要初始化的
      if (!bd.isAbstract() && bd.isSingleton() && !bd.isLazyInit()) {
         // 处理 FactoryBean(读者如果不熟悉 FactoryBean，请移步附录区了解)
         if (isFactoryBean(beanName)) {
            // FactoryBean 的话，在 beanName 前面加上 ‘&’ 符号。再调用 getBean，getBean 方法别急
            final FactoryBean<?> factory = (FactoryBean<?>) getBean(FACTORY_BEAN_PREFIX + beanName);
            // 判断当前 FactoryBean 是否是 SmartFactoryBean 的实现，此处忽略，直接跳过
            boolean isEagerInit;
            if (System.getSecurityManager() != null && factory instanceof SmartFactoryBean) {
               isEagerInit = AccessController.doPrivileged(new PrivilegedAction<Boolean>() {
                  @Override
                  public Boolean run() {
                     return ((SmartFactoryBean<?>) factory).isEagerInit();
                  }
               }, getAccessControlContext());
            }
            else {
               isEagerInit = (factory instanceof SmartFactoryBean &&
                     ((SmartFactoryBean<?>) factory).isEagerInit());
            }
            if (isEagerInit) {

               getBean(beanName);
            }
         }
         else {
            // 对于普通的 Bean，只要调用 getBean(beanName) 这个方法就可以进行初始化了
            getBean(beanName);
         }
      }
   }

   // 到这里说明所有的非懒加载的 singleton beans 已经完成了初始化
   // 如果我们定义的 bean 是实现了 SmartInitializingSingleton 接口的，那么在这里得到回调，忽略
   for (String beanName : beanNames) {
      Object singletonInstance = getSingleton(beanName);
      if (singletonInstance instanceof SmartInitializingSingleton) {
         final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance;
         if (System.getSecurityManager() != null) {
            AccessController.doPrivileged(new PrivilegedAction<Object>() {
               @Override
               public Object run() {
                  smartSingleton.afterSingletonsInstantiated();
                  return null;
               }
            }, getAccessControlContext());
         }
         else {
            smartSingleton.afterSingletonsInstantiated();
         }
      }
   }
}
```

###### getBean(beanName)

```java
@Override
public Object getBean(String name) throws BeansException {
   return doGetBean(name, null, null, false);
}

// 我们在剖析初始化 Bean 的过程，但是 getBean 方法我们经常是用来从容器中获取 Bean 用的，注意切换思路，
// 已经初始化过了就从容器中直接返回，否则就先初始化再返回
@SuppressWarnings("unchecked")
protected <T> T doGetBean(
      final String name, final Class<T> requiredType, final Object[] args, boolean typeCheckOnly)
      throws BeansException {
   // 获取一个 “正统的” beanName，处理两种情况，一个是前面说的 FactoryBean(前面带 ‘&’)，
   // 一个是别名问题，因为这个方法是 getBean，获取 Bean 用的，你要是传一个别名进来，是完全可以的
   final String beanName = transformedBeanName(name);

   // 注意跟着这个，这个是返回值
   Object bean; 

   // 检查下是不是已经创建过了
   Object sharedInstance = getSingleton(beanName);

   // 这里说下 args 呗，虽然看上去一点不重要。前面我们一路进来的时候都是 getBean(beanName)，
   // 所以 args 传参其实是 null 的，但是如果 args 不为空的时候，那么意味着调用方不是希望获取 Bean，而是创建 Bean
   if (sharedInstance != null && args == null) {
      if (logger.isDebugEnabled()) {
         if (isSingletonCurrentlyInCreation(beanName)) {
            logger.debug("...");
         }
         else {
            logger.debug("Returning cached instance of singleton bean '" + beanName + "'");
         }
      }
      // 下面这个方法：如果是普通 Bean 的话，直接返回 sharedInstance，
      // 如果是 FactoryBean 的话，返回它创建的那个实例对象
      // (FactoryBean 知识，读者若不清楚请移步附录)
      bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);
   }

   else {
      if (isPrototypeCurrentlyInCreation(beanName)) {
         // 创建过了此 beanName 的 prototype 类型的 bean，那么抛异常，
         // 往往是因为陷入了循环引用
         throw new BeanCurrentlyInCreationException(beanName);
      }

      // 检查一下这个 BeanDefinition 在容器中是否存在
      BeanFactory parentBeanFactory = getParentBeanFactory();
      if (parentBeanFactory != null && !containsBeanDefinition(beanName)) {
         // 如果当前容器不存在这个 BeanDefinition，试试父容器中有没有
         String nameToLookup = originalBeanName(name);
         if (args != null) {
            // 返回父容器的查询结果
            return (T) parentBeanFactory.getBean(nameToLookup, args);
         }
         else {
            // No args -> delegate to standard getBean method.
            return parentBeanFactory.getBean(nameToLookup, requiredType);
         }
      }

      if (!typeCheckOnly) {
         // typeCheckOnly 为 false，将当前 beanName 放入一个 alreadyCreated 的 Set 集合中。
         markBeanAsCreated(beanName);
      }

      /*
       * 稍稍总结一下：
       * 到这里的话，要准备创建 Bean 了，对于 singleton 的 Bean 来说，容器中还没创建过此 Bean；
       * 对于 prototype 的 Bean 来说，本来就是要创建一个新的 Bean。
       */
      try {
         final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);
         checkMergedBeanDefinition(mbd, beanName, args);

         // 先初始化依赖的所有 Bean，这个很好理解。
         // 注意，这里的依赖指的是 depends-on 中定义的依赖
         String[] dependsOn = mbd.getDependsOn();
         if (dependsOn != null) {
            for (String dep : dependsOn) {
               // 检查是不是有循环依赖，这里的循环依赖和我们前面说的循环依赖又不一样，这里肯定是不允许出现的，不然要乱套了，读者想一下就知道了
               if (isDependent(beanName, dep)) {
                  throw new BeanCreationException(mbd.getResourceDescription(), beanName,
                        "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'");
               }
               // 注册一下依赖关系
               registerDependentBean(dep, beanName);
               // 先初始化被依赖项
               getBean(dep);
            }
         }

         // 如果是 singleton scope 的，创建 singleton 的实例
         if (mbd.isSingleton()) {
            sharedInstance = getSingleton(beanName, new ObjectFactory<Object>() {
               @Override
               public Object getObject() throws BeansException {
                  try {
                     // 执行创建 Bean，详情后面再说
                     return createBean(beanName, mbd, args);
                  }
                  catch (BeansException ex) {
                     destroySingleton(beanName);
                     throw ex;
                  }
               }
            });
            bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);
         }

         // 如果是 prototype scope 的，创建 prototype 的实例
         else if (mbd.isPrototype()) {
            // It's a prototype -> create a new instance.
            Object prototypeInstance = null;
            try {
               beforePrototypeCreation(beanName);
               // 执行创建 Bean
               prototypeInstance = createBean(beanName, mbd, args);
            }
            finally {
               afterPrototypeCreation(beanName);
            }
            bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);
         }

         // 如果不是 singleton 和 prototype 的话，需要委托给相应的实现类来处理
         else {
            String scopeName = mbd.getScope();
            final Scope scope = this.scopes.get(scopeName);
            if (scope == null) {
               throw new IllegalStateException("No Scope registered for scope name '" + scopeName + "'");
            }
            try {
               Object scopedInstance = scope.get(beanName, new ObjectFactory<Object>() {
                  @Override
                  public Object getObject() throws BeansException {
                     beforePrototypeCreation(beanName);
                     try {
                        // 执行创建 Bean
                        return createBean(beanName, mbd, args);
                     }
                     finally {
                        afterPrototypeCreation(beanName);
                     }
                  }
               });
               bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd);
            }
            catch (IllegalStateException ex) {
               throw new BeanCreationException(beanName,
                     "Scope '" + scopeName + "' is not active for the current thread; consider " +
                     "defining a scoped proxy for this bean if you intend to refer to it from a singleton",
                     ex);
            }
         }
      }
      catch (BeansException ex) {
         cleanupAfterBeanCreationFailure(beanName);
         throw ex;
      }
   }

   // 最后，检查一下类型对不对，不对的话就抛异常，对的话就返回了
   if (requiredType != null && bean != null && !requiredType.isInstance(bean)) {
      try {
         return getTypeConverter().convertIfNecessary(bean, requiredType);
      }
      catch (TypeMismatchException ex) {
         if (logger.isDebugEnabled()) {
            logger.debug("Failed to convert bean '" + name + "' to required type '" +
                  ClassUtils.getQualifiedName(requiredType) + "'", ex);
         }
         throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());
      }
   }
   return (T) bean;
}
```

其中有一个关键方法 createBean(beanName)

```java
@Override
protected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException {
   if (logger.isDebugEnabled()) {
      logger.debug("Creating instance of bean '" + beanName + "'");
   }
   RootBeanDefinition mbdToUse = mbd;

   // 确保 BeanDefinition 中的 Class 被加载
   Class<?> resolvedClass = resolveBeanClass(mbd, beanName);
   if (resolvedClass != null && !mbd.hasBeanClass() && mbd.getBeanClassName() != null) {
      mbdToUse = new RootBeanDefinition(mbd);
      mbdToUse.setBeanClass(resolvedClass);
   }

   // 准备方法覆写，这里又涉及到一个概念：MethodOverrides，它来自于 bean 定义中的 <lookup-method /> 
   // 和 <replaced-method />，如果读者感兴趣，回到 bean 解析的地方看看对这两个标签的解析。
   // 我在附录中也对这两个标签的相关知识点进行了介绍，读者可以移步去看看
   try {
      mbdToUse.prepareMethodOverrides();
   }
   catch (BeanDefinitionValidationException ex) {
      throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(),
            beanName, "Validation of method overrides failed", ex);
   }

   try {
      // 让 InstantiationAwareBeanPostProcessor 在这一步有机会返回代理，
      // 在 《Spring AOP 源码分析》那篇文章中有解释，这里先跳过
      Object bean = resolveBeforeInstantiation(beanName, mbdToUse);
      if (bean != null) {
         return bean; 
      }
   }
   catch (Throwable ex) {
      throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName,
            "BeanPostProcessor before instantiation of bean failed", ex);
   }
   // 重头戏，创建 bean
   Object beanInstance = doCreateBean(beanName, mbdToUse, args);
   if (logger.isDebugEnabled()) {
      logger.debug("Finished creating instance of bean '" + beanName + "'");
   }
   return beanInstance;
}
```

doCreateBean(beanName, mbdToUse, args) 里的 createBeanInstance(beanName, mbd, args)

```java
protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) {
   // 确保已经加载了此 class
   Class<?> beanClass = resolveBeanClass(mbd, beanName);

   // 校验一下这个类的访问权限
   if (beanClass != null && !Modifier.isPublic(beanClass.getModifiers()) && !mbd.isNonPublicAccessAllowed()) {
      throw new BeanCreationException(mbd.getResourceDescription(), beanName,
            "Bean class isn't public, and non-public access not allowed: " + beanClass.getName());
   }

   if (mbd.getFactoryMethodName() != null)  {
      // 采用工厂方法实例化，不熟悉这个概念的读者请看附录，注意，不是 FactoryBean
      return instantiateUsingFactoryMethod(beanName, mbd, args);
   }

   // 如果不是第一次创建，比如第二次创建 prototype bean。
   // 这种情况下，我们可以从第一次创建知道，采用无参构造函数，还是构造函数依赖注入 来完成实例化
   boolean resolved = false;
   boolean autowireNecessary = false;
   if (args == null) {
      synchronized (mbd.constructorArgumentLock) {
         if (mbd.resolvedConstructorOrFactoryMethod != null) {
            resolved = true;
            autowireNecessary = mbd.constructorArgumentsResolved;
         }
      }
   }
   if (resolved) {
      if (autowireNecessary) {
         // 构造函数依赖注入
         return autowireConstructor(beanName, mbd, null, null);
      }
      else {
         // 无参构造函数
         return instantiateBean(beanName, mbd);
      }
   }

   // 判断是否采用有参构造函数
   Constructor<?>[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);
   if (ctors != null ||
         mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR ||
         mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args))  {
      // 构造函数依赖注入
      return autowireConstructor(beanName, mbd, ctors, args);
   }

   // 调用无参构造函数
   return instantiateBean(beanName, mbd);
}
```

看看无参构造方法 instantiateBean(beanName, mbd)

```java
protected BeanWrapper instantiateBean(final String beanName, final RootBeanDefinition mbd) {
   try {
      Object beanInstance;
      final BeanFactory parent = this;
      if (System.getSecurityManager() != null) {
         beanInstance = AccessController.doPrivileged(new PrivilegedAction<Object>() {
            @Override
            public Object run() {

               return getInstantiationStrategy().instantiate(mbd, beanName, parent);
            }
         }, getAccessControlContext());
      }
      else {
         // 实例化（关键点）
         beanInstance = getInstantiationStrategy().instantiate(mbd, beanName, parent);
      }
      // 包装一下，返回
      BeanWrapper bw = new BeanWrapperImpl(beanInstance);
      initBeanWrapper(bw);
      return bw;
   }
   catch (Throwable ex) {
      throw new BeanCreationException(
            mbd.getResourceDescription(), beanName, "Instantiation of bean failed", ex);
   }
}
```

里面的 getInstantiationStrategy().instantiate(mbd, beanName, parent)

```java
@Override
public Object instantiate(RootBeanDefinition bd, String beanName, BeanFactory owner) {

   // 如果不存在方法覆写，那就使用 java 反射进行实例化，否则使用 CGLIB,
   // 方法覆写 请参见附录"方法注入"中对 lookup-method 和 replaced-method 的介绍
   if (bd.getMethodOverrides().isEmpty()) {
      Constructor<?> constructorToUse;
      synchronized (bd.constructorArgumentLock) {
         constructorToUse = (Constructor<?>) bd.resolvedConstructorOrFactoryMethod;
         if (constructorToUse == null) {
            final Class<?> clazz = bd.getBeanClass();
            if (clazz.isInterface()) {
               throw new BeanInstantiationException(clazz, "Specified class is an interface");
            }
            try {
               if (System.getSecurityManager() != null) {
                  constructorToUse = AccessController.doPrivileged(new PrivilegedExceptionAction<Constructor<?>>() {
                     @Override
                     public Constructor<?> run() throws Exception {
                        return clazz.getDeclaredConstructor((Class[]) null);
                     }
                  });
               }
               else {
                  constructorToUse = clazz.getDeclaredConstructor((Class[]) null);
               }
               bd.resolvedConstructorOrFactoryMethod = constructorToUse;
            }
            catch (Throwable ex) {
               throw new BeanInstantiationException(clazz, "No default constructor found", ex);
            }
         }
      }
      // 利用构造方法进行实例化
      return BeanUtils.instantiateClass(constructorToUse);
   }
   else {
      // 存在方法覆写，利用 CGLIB 来完成实例化，需要依赖于 CGLIB 生成子类，这里就不展开了。
      // tips: 因为如果不使用 CGLIB 的话，存在 override 的情况 JDK 并没有提供相应的实例化支持
      return instantiateWithMethodInjection(bd, beanName, owner);
   }
}
```

至此，一个 bean 已经实例化完成，接下来就是 bean 的属性注入

```java
protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) {
   // bean 实例的所有属性都在这里了
   PropertyValues pvs = mbd.getPropertyValues();

   if (bw == null) {
      if (!pvs.isEmpty()) {
         throw new BeanCreationException(
               mbd.getResourceDescription(), beanName, "Cannot apply property values to null instance");
      }
      else {
         // Skip property population phase for null instance.
         return;
      }
   }

   // 到这步的时候，bean 实例化完成（通过工厂方法或构造方法），但是还没开始属性设值，
   // InstantiationAwareBeanPostProcessor 的实现类可以在这里对 bean 进行状态修改，
   // 我也没找到有实际的使用，所以我们暂且忽略这块吧
   boolean continueWithPropertyPopulation = true;
   if (!mbd.isSynthetic() && hasInstantiationAwareBeanPostProcessors()) {
      for (BeanPostProcessor bp : getBeanPostProcessors()) {
         if (bp instanceof InstantiationAwareBeanPostProcessor) {
            InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;
            // 如果返回 false，代表不需要进行后续的属性设值，也不需要再经过其他的 BeanPostProcessor 的处理
            if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) {
               continueWithPropertyPopulation = false;
               break;
            }
         }
      }
   }

   if (!continueWithPropertyPopulation) {
      return;
   }

   if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME ||
         mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) {
      MutablePropertyValues newPvs = new MutablePropertyValues(pvs);

      // 通过名字找到所有属性值，如果是 bean 依赖，先初始化依赖的 bean。记录依赖关系
      if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) {
         autowireByName(beanName, mbd, bw, newPvs);
      }

      // 通过类型装配。复杂一些
      if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) {
         autowireByType(beanName, mbd, bw, newPvs);
      }

      pvs = newPvs;
   }

   boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors();
   boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE);

   if (hasInstAwareBpps || needsDepCheck) {
      PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);
      if (hasInstAwareBpps) {
         for (BeanPostProcessor bp : getBeanPostProcessors()) {
            if (bp instanceof InstantiationAwareBeanPostProcessor) {
               InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;
               // 这里有个非常有用的 BeanPostProcessor 进到这里: AutowiredAnnotationBeanPostProcessor
               // 对采用 @Autowired、@Value 注解的依赖进行设值，这里的内容也是非常丰富的，不过本文不会展开说了，感兴趣的读者请自行研究
               pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName);
               if (pvs == null) {
                  return;
               }
            }
         }
      }
      if (needsDepCheck) {
         checkDependencies(beanName, mbd, filteredPds, pvs);
      }
   }
   // 设置 bean 实例的属性值
   applyPropertyValues(beanName, mbd, bw, pvs);
}
```

最后会有一个属性注入完成的回调方法 initializeBean()

```java
protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) {
   if (System.getSecurityManager() != null) {
      AccessController.doPrivileged(new PrivilegedAction<Object>() {
         @Override
         public Object run() {
            invokeAwareMethods(beanName, bean);
            return null;
         }
      }, getAccessControlContext());
   }
   else {
      // 如果 bean 实现了 BeanNameAware、BeanClassLoaderAware 或 BeanFactoryAware 接口，回调
      invokeAwareMethods(beanName, bean);
   }

   Object wrappedBean = bean;
   if (mbd == null || !mbd.isSynthetic()) {
      // BeanPostProcessor 的 postProcessBeforeInitialization 回调
      wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);
   }

   try {
      // 处理 bean 中定义的 init-method，
      // 或者如果 bean 实现了 InitializingBean 接口，调用 afterPropertiesSet() 方法
      invokeInitMethods(beanName, wrappedBean, mbd);
   }
   catch (Throwable ex) {
      throw new BeanCreationException(
            (mbd != null ? mbd.getResourceDescription() : null),
            beanName, "Invocation of init method failed", ex);
   }

   if (mbd == null || !mbd.isSynthetic()) {
      // BeanPostProcessor 的 postProcessAfterInitialization 回调
      wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);
   }
   return wrappedBean;
}
```





## 贝贝博客

### 查询文章详情

1. 先查询缓存是否有对应id的文章
   1. 有则直接返回缓存
   2. 没有则查询数据库，并写入缓存

2. 再判断该ip当天是否有访问过该文章，查询缓存记录
   1. 有则返回view
   2. 没有则返回view+1，并通过mq异步同步到数据库

### 更新文章详情

先更新数据库，再删除缓存，在高并发情况下，其他线程会读取旧数据，在本线程执行完删除缓存后写入缓存，造成缓存旧数据的情况。



缓存一致性解决方案

1. 删除缓存，更新数据库：会被其他线程在更新数据库前把旧数据写入缓存。
2. 更新数据库，删除缓存：缓存不存在时，会被其他线程把旧数据写入缓存。
3. 更新缓存，更新数据库：更新数据库失败则造成缓存脏数据。
4. 更新数据库，更新缓存：会出现事务丢失的情况。

